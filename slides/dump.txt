L01.pdf:       EDAN65:	Compilers	
Introduc8on	and	Overview	
          Görel	Hedin	
         Revised:	2016-08-29	

L01.pdf:                    Course	registra8on	
•  Conﬁrm	by	signing	the	Registra8on	Form	
•  Prerequisites	
     –  Object-oriented	programming	and	Java	
     –  Algorithms	and	data	structures	
          (recursion,	trees,	lists,	hash	tables,	…)	
EDAN65,	Lecture	01	
                                                     2	

L01.pdf:                    Student	representa8ves	
•  2	students	
•  Par8cipate	in	post	course	CEQ	discussion		
    (Course	Experience	Ques8onnaire)	
EDAN65,	Lecture	01	
                                              3	

L01.pdf:                         Course	informa8on	
•  Web	page:	http://cs.lth.se/edan65	
     –  will	be	updated	during	the	course	
•  Read	http://cs.lth.se/edan65/week-by-week	
     –  to	see	what	to	do	each	week	
•  Literature	
     –  Course	material,	will	be	made	available	on	the	web	site	
             •  Lectures,	ar8cles,	assignments,	exercises	
             •  Not	handed	out	–	print	yourself.	
     –  Textbook	
             •  A.	W.	Appel,	Jens	Palsberg:	Modern	Compiler	Implementa8on	in	Java,	2nd	Edi8on,	
                 Cambridge	University	Press,	2002,	ISBN:	0-521-82060-X	
             •  Available	as	an	on-line	e-book	through	Lund	University	
             •  Only	part	of	the	book	is	used.	Covers	only	part	of	the	course.	
•  Forum	(Q&A)	using	the	Piazza	system.	
•  Quizzes	using	the	Moodle	system.	
EDAN65,	Lecture	01	
                                                                                                4	

L01.pdf:                        Course	structure	
•  14	lectures,	Mon	13-15,	Tue	10-12,	varying	lecture	halls	
•  Assignment	0,	for	freshing	up	on	Java	and	Unix.	Do	on	your	own.	
•  Assignment	1-6.	Mandatory.	
     –    Work	in	pairs.	Use	the	lecture	break	or	the	forum	to	form	pairs.	
     –    Heavy.	Get	approved	and	get	help	at	Lab	sessions.	
     –    Thu	13-15,	Thu	15-17,	or	Fri	10-12.	Sign	up	by	Thursday	Sept	1	
     –    Lab	sessions	start	next	week	(but	start	this	week	on	your	work)	
     –    Assignments	prerequisite	for	doing	exam	
•  Lecture	quizzes	
     –  Do	on	your	own.	
•  Exercises	
     –  Do	on	your	own.	
•  Exam	–	sign	up	in	advance	through	LTH	system	
     –  Exam:	Friday,	Oct	28,	2016	
     –  Re-exam:	Wednesday	Dec	21,	2016	
EDAN65,	Lecture	01	
                                                                            5	

L01.pdf:                 More	on	the	assignments	
•  Work	together	with	your	partner	on	all	parts	
     –  pair	programming,	switch	frequently	who	is	typing	
     –  you	need	hands-on	experience	from	all	parts	
•  If	you	get	stuck	
     –  ask	on	the	Piazza	forum	
     –  you	are	encouraged	to	give	answers	to	other	students	on	the	forum	
          (for	general	advice,	not	solu8ons)	
•  Both	of	you	should	be	able	to	explain	all	parts	of	your	solu8on.	
•  Want	to	use	a	git	repo?	Make	it	private!	Free	on	BitBucket.	
EDAN65,	Lecture	01	
                                                                           6	

L01.pdf:Es8mated	typical	eﬀort	for	assignments	
               A0:	Unix	and	Java	     0-2	hours	 recommended	
               A1:	Scanning	          5	hours	   mandatory	
               A2:	Parsing	           15	hours	  mandatory	
               A3:	Visitors,	aspects	 12	hours	  mandatory	
               A4:	Seman8c	analysis	 18	hours	   mandatory	
               A5:	Interpreter	       15	hours	  mandatory	
               A6:	Code	generator	    12	hours	  mandatory	
EDAN65,	Lecture	01	
                                                              7	

L01.pdf:                      Instructors	
•  Lectures	
     –  Prof.	Görel	Hedin	
•  Programming	assignments	and	lab	sessions	
     –  Ph.	D.	student	Jesper	Öqvist	
     –  Ph.	D.	student	Alfred	Åkesson	
EDAN65,	Lecture	01	
                                             8	

L01.pdf:EDAN65,	Lecture	01	
                    9	

L01.pdf:  Why	learn	compiler	construc8on?	
•  Very	useful	in	prac8ce	
     –  Languages	are	everywhere	
     –  Your	next	project	might	need	a	small	language	
•  Interes8ng	
     –  Compiler	theory:	fundamental	to	computer	science	
     –  Essen8al	for	understanding	programming	languages	
EDAN65,	Lecture	01	
                                                          10	

L01.pdf:A	tradi8onal	compiler	
          source	                      assembly	
                      compiler	
           code
                         code

  EXAMPLE:	                     								.data	
                                a:						.long			0	
                                b:						.long			0	
                                csum:			.long			0	
                                	
  ...	                          								.code	
  csum	=	a	+	b	+	1;	  compiler	 								...	
  ...	
                                								movl				a,	%eax	
                                								addl				b,	%eax	
                                								addl				$1,	%eax	
                                								movl				%eax,	csum	
  EDAN65,	Lecture	01	           								...

                                                            11	

L01.pdf:What	happens	aoer	compila8on?	memory	
   source	                           assembly	             activation
                       compiler	                                      stack	
    code
                               code
                records	
                        object	                executable	
 assembler	                            linker	               objects	 heap	
                         code
                    code

                        library	
                      object	code
                                    static
                                                            ...        data	
                                                            0000 0001
                                                            0176 0024
                                                            0024 7050
  •  object	code	contains	global	symbols	                   2530 0000
     and	relocatable	addresses	                             0000 0010  code	
                                                 loader	    2444 5512
                                                            0000 0010
  •  in	executable	code	global	symbols	and	                 ...
     relocatable	addresses	have	been	
     replaced	by	absolute	addresses	
                                                            machine
  EDAN65,	Lecture	01	
                                                                         12	

L01.pdf:What	about	Java?	
                       javac	
      A.java
                                A.class

                     compiler	
                                            class	ﬁle	
                                        (java	bytecode)	
   EXAMPLE:	                                           ...	
                                                       iload_1	
                                                       iload_2	
   ...	
                                 javac	                iadd	
   csum	=	a	+	b	+	1;	
                               compiler	               iconst_1	
   ...	
                                                       iadd	
                                                       istore_3	
                                                       ...	
 EDAN65,	Lecture	01	
                                                                 13	

L01.pdf:Running	Java	code?	                                              memory	
                                                                activation
                            javac	                                             stack	
       A.java
                            A.class
               records	
                          compiler	
                                                                  objects	
                                                                  op8mized	
                                                                   machine	    optimize	
                                                    load
                                                                     code

                                                    and verify	
                                                                   machine	     heap	
                                                                     code

The	java	program	contains	a	java	virtual	machine	(jvm).	           A-object

It	can:	                                                          bytecode

                                                                                JIT	
•  load	bytecode	to	the	heap	
•  interpret	bytecode	                                           class	loader	
•  compile	bytecode	into	machine	code	during	execu@on	
                                                                                code
    (JIT	–	Just-In-Time	Compila@on)	                                java	        and
•  op@mize	the	machine	code	                                         VM	
                                                                                data	
•  garbage	collect	the	heap	
                                                                 machine
   EDAN65,	Lecture	01	
                                                                                      14	

L01.pdf:                                          Each	phase	converts	the	program	
     Inside	the	compiler:	                from	one	representa7on	to	another	
                                             source	code	(text)	
                        Lexical	analysis	
                           (scanning)	
                                             tokens	
                      Syntac8c	analysis	
            Analysis	       (parsing)	
                                             AST	(Abstract	syntax	tree)	
                      Seman8c	analysis	
                                             Apributed	AST	
                         Intermediate	
                       code	genera8on	
                                             intermediate	code	
          Synthesis	     Op8miza8on	
                                             intermediate	code	
                          Target	code	
                          genera8on	
EDAN65,	Lecture	01	                          target	code	                    15	

L01.pdf:     Front	and	back	end:	
                                                      source	code	(text)	
                                    Lexical	analysis	
                                       (scanning)	
                                                      tokens	
                                  Syntac8c	analysis	
                                        (parsing)	
             Front	end	                               AST	(Abstract	syntax	tree)	
(independent	on	target	language)	
                                  Seman8c	analysis	
                                                      Apributed	AST	
                                     Intermediate	
                                   code	genera8on	
                                                      intermediate	code	
            Middle	end	
                                     Op8miza8on	
      (independent	on	both)	
                                                      intermediate	code	
             Back	end	                Target	code	
(independent	on	source	language)	     genera8on	
           EDAN65,	Lecture	01	                        target	code	              16	

L01.pdf:Several	front	and	back	ends:	
            C-Frontend	            L-Frontend	         ...	
                                                                       intermediate	code	
   Intel-Backend	          MIPS-Backend	    Interpreter	      ...	
              Why?	
              •  It	is	more	ra8onal	to	implement	m	front	ends	+	n	back	ends	
                   than	m	*	n	compilers.	
              •  Many	op8miza8ons	are		best	performed	on	intermediate	code.	
              •  It	may	be	easier	to	debug	the	front	end	using	an	interpreter	
                   than	a	target	machine	
  EDAN65,	Lecture	01	
                                                                                          17	

L01.pdf:Example:	
                         Eclipse	           Scala	
       javac	                                           Jython	       ...	
                      Java	compiler	     compiler	
                                                                           Java	bytecode	
                                     Jikes	
       HotSpot	JVM	                                    dx	       ...	
                                 Research	VM	
                                                                Dalvik	bytecode	
                                                   Dalvik	VM	
                                                   (Android)	
  EDAN65,	Lecture	01	
                                                                                          18	

L01.pdf:                      Some	terminology	
•  A	compiler	translates	a	high-level	program	to	low-level	code.	
•  An	interpreter	is	sooware	that	executes	a	high/low	level	program,	ooen	by	
    calling	one	procedure	for	each	program	construct.	
•  In	the	context	of	compiler	construc8on,	a	virtual	machine	(VM)	is	an	
    interpreter	that	executes	low-level,	usually	platorm-independent	code.	
    (In	other	contexts,	virtual	machine	can	mean	system	virtualiza8on.)	
•  Platorm-independent	low-level	code,	designed	to	be	executed	by	a	VM,	was	
    originally	called	p-code	(portable	code),	but	is	now	usually	called	bytecode.	
•  An	interpreter	or	VM	may	use	a	JIT	(“just	in	8me”)	compiler	to	compile	all	or	
    parts	of	the	program	into	machine	code	during	execu8on.	
EDAN65,	Lecture	01	
                                                                                   19	

L01.pdf:               Some	historical	anecdotes	
•  The	ﬁrst	compiler	was	developed	by	Grace	Hopper	in	1952.	
•  John	McCarthy	used	JIT	compila8on	in	his	LISP	interpreter	in	1960.	
    This	was	called	"Compile	and	Go".	The	term	JIT	came	later,	and	was	
    popularized	with	Java.	
•  The	Pascal-P	system,	developed	by	Niklaus	Wirth	in	1972,	used	
    portable	code	called	"p-code".	The	interpreter	was	easy	to	port	to	
    diﬀerent	machines.	The	language	spread	quickly,	and	became	a	
    popular	language	taught	at	many	universi8es.	
•  Smalltalk-80	used	bytecode,	and	pioneered	several	run8me	
    compila8on	and	op8miza8on	techniques	for	object-oriented	
    languages.	
EDAN65,	Lecture	01	
                                                                        20	

L01.pdf: Compiler	phases	and	program	representa8ons:	
                                        source	code	(text)	
                      Lexical	analysis	
                         (scanning)	
                                        tokens	
                    Syntac8c	analysis	
                          (parsing)	
                                        AST	(Abstract	syntax	tree)	
                    Seman8c	analysis	
                                        Apributed	AST	
                       Intermediate	
                     code	genera8on	
                                        intermediate	code	
                       Op8miza8on	
                                        intermediate	code	
                        Target	code	
                        genera8on	
EDAN65,	Lecture	01	                     target	code	                21	

L01.pdf:                Lexical	analysis	(scanning)	
 Source	text									Tokens	
 while	(k<=n)	{	             WHILE	LPAR	ID(k)	LEQ	ID(n)	RPAR	LBRA	
 		sum=sum+k;	               ID(sum)	EQ	ID(sum)	PLUS	ID(k)	SEMI	
 		k=k+1;	                   ID(k)	EQ	ID(k)	PLUS	INT(1)	SEMI	
 }	                          RBRA	
 A	token	is	a	symbolic	name,	some8mes	with	an	apribute.	
 A	lexeme	is	a	string	corresponding	to	a	token.	
EDAN65,	Lecture	01	
                                                                   22	

L01.pdf: Compiler	phases	and	program	representa8ons:	
                                        source	code	(text)	
                      Lexical	analysis	
                         (scanning)	
                                        tokens	
                    Syntac8c	analysis	
                          (parsing)	
                                        AST	(Abstract	syntax	tree)	
                    Seman8c	analysis	
                                        Apributed	AST	
                       Intermediate	
                     code	genera8on	
                                        intermediate	code	
                       Op8miza8on	
                                        intermediate	code	
                        Target	code	
                        genera8on	
EDAN65,	Lecture	01	                     target	code	                23	

L01.pdf:                Syntac8c	analysis	(parsing)	
                          WhileStmt	                   parse	tree	–	spans	all	tokens	
                                             CompoundStmt	
                                AssignStmt	            AssignStmt	
               LessEqual	               Add	                   Add	
WHILE	LPAR	ID	LEQ	ID	RPAR	LBRA	ID	EQ	ID	PLUS	ID	SEMI	ID	EQ	ID	PLUS	INT	SEMI	RBRA	
while	(	k	<=	n	)	{	sum	=	sum	+	k	;	k	=	k	+	1	;	}	
  EDAN65,	Lecture	01	
                                                                                   24	

L01.pdf:                  Abstract	syntax	tree	(AST)	
                          WhileStmt	                   AST	–	a	tree	with	only	the	
                                                       essen8al	structure	and	tokens	
                                             CompoundStmt	
                                AssignStmt	             AssignStmt	
               LessEqual	               Add	                    Add	
WHILE	LPAR	ID	LEQ	ID	RPAR	LBRA	ID	EQ	ID	PLUS	ID	SEMI	ID	EQ	ID	PLUS	INT	SEMI	RBRA	
while	(	k	<=	n	)	{	sum	=	sum	+	k	;	k	=	k	+	1	;	}	
  EDAN65,	Lecture	01	
                                                                                   25	

L01.pdf:                    Abstract	syntax	trees	
•  Used	inside	the	compiler	for	represen8ng	the	program	
•  Very	similar	to	the	parse	tree,	but	
     –  contains	only	essen8al	tokens	
     –  has	a	simpler	more	natural	structure	
•  Ooen	represented	by	a	typed	object-oriented	model	
     –  abstract	classes	(Stmt,	Expr,	Decl,	...)	
     –  concrete	classes	(WhileStmt,	IfStmt,	Add,	Sub,	...)	
EDAN65,	Lecture	01	
                                                             26	

L01.pdf:                    Designing	an	AST	model	
                       (class	hierarchy)	
•  What	abstract	constructs	are	there	in	the	language	
     –  Make	them	abstract	types	
•  What	concrete	constructs	are	there?	
     –  Make	them	subtypes	
•  What	parts	do	the	concrete	constructs	have?	
     –  Add	gepers	for	them,	so	the	AST	can	be	traversed	
EDAN65,	Lecture	01	
                                                          27	

L01.pdf:              Example	AST	class	hierarchy	
                      Stmt
                                       Expr

WhileStmt
        CompoundStmt
 AssignStmt
    Add
      LessEqual
       Id
      Int

getExpr()
       getStmts()
    getId()
    getExpr1()
 getExpr1()
    getID()
 getINT()

getStmt()
                      getExpr()
  getExpr2()
 getExpr2()

  EDAN65,	Lecture	01	
                                                                                        28	

L01.pdf: Compiler	phases	and	program	representa8ons:	
                                        source	code	(text)	
                      Lexical	analysis	
                         (scanning)	
                                        tokens	
                    Syntac8c	analysis	
                          (parsing)	
                                        AST	(Abstract	syntax	tree)	
                    Seman8c	analysis	
                                        Apributed	AST	
                       Intermediate	
                     code	genera8on	
                                        intermediate	code	
                       Op8miza8on	
                                        intermediate	code	
                        Target	code	
                        genera8on	
EDAN65,	Lecture	01	                     target	code	                29	

L01.pdf:                    Seman8c	analysis	
Analyze	the	AST,	for	example,	
•  Which	declara8on	corresponds	to	a	variable?	
•  What	is	the	type	of	an	expression?	
•  Are	there	compile	8me	errors	in	the	program?	
	
Analysis	aided	by	adding	aIributes	to	the	AST	
(proper8es	of	AST	nodes)	
EDAN65,	Lecture	01	
                                                 30	

L01.pdf:                           Example	apributes	
                                              Decl

                                                                          Expr

                      Stmt
          VarDecl
       MethodDecl
        type()

                                   ...
          ...

WhileStmt
        CompoundStmt
 AssignStmt
           Add
       LessEqual
       Id
      Int

getExpr()
       getStmts()
    getId()
         getExpr1()
    getExpr1()
    getID()
 getINT()

getStmt()
                      getExpr()
       getExpr2()
    getExpr2()
    decl()

 Each	Expr	has	a	type()	apribute,	indica8ng	if	the	expression	is	integer,	boolean,	etc.	
 Each	Id	has	a	decl()	apribute,	referring	to	the	appropriate	declara8on	node.	
  EDAN65,	Lecture	01	
                                                                                                31	

L01.pdf: Compiler	phases	and	program	representa8ons:	
                                        source	code	(text)	
                      Lexical	analysis	
                         (scanning)	
                                        tokens	
                    Syntac8c	analysis	
                          (parsing)	
                                        AST	(Abstract	syntax	tree)	
                    Seman8c	analysis	
                                        Apributed	AST	
                       Intermediate	
                     code	genera8on	
                                        intermediate	code	
                       Op8miza8on	
                                        intermediate	code	
                        Target	code	
                        genera8on	
EDAN65,	Lecture	01	                     target	code	                32	

L01.pdf:         Intermediate	code	genera8on	
Intermediate	code:	
•  independent	of	source	language	
•  independent	of	target	machine	
•  usually	assembly-like	
     –  but	simpler,	without	many	instruc8on	variants	
     –  and	with	an	unlimited	number	of	registers	
          (or	uses	a	stack	instead	of	registers)	
	
EDAN65,	Lecture	01	
                                                       33	

L01.pdf:     Compiler	phases	and	program	representa8ons:	
                                              source	code	(text)	
                            Lexical	analysis	
                               (scanning)	
                                              tokens	
                          Syntac8c	analysis	
                                (parsing)	
                                              AST	(Abstract	syntax	tree)	
                          Seman8c	analysis	
                                              Apributed	AST	
                             Intermediate	
                           code	genera8on	
                                              intermediate	code	
                             Op8miza8on	
See	the	course	Op8mizing	
                                              intermediate	code	
Compilers,	EDA230	
                              Target	code	
                              genera8on	
   EDAN65,	Lecture	01	                        target	code	               34	

L01.pdf: Genera8ng	the	compiler:	
  Regular	                                      Lexical	analyzer	
                           Scanner	generator	
expressions
                                       (scanner)	
Context-free	                    Parser	       Syntac8c	analyzer	
 grammar
                      generator	           (parser)	
 Apribute	                 Apribute	evaluator	
                                               Seman8c	analyzer	
 grammar
                      generator	
                                                 Intermediate	
                                                code	generator	
                                Reusable	
                               algoritms,	         Op8mizer	
                              see	EDA230

                                                  Target	code	
                                                   generator	
       EDAN65,	Lecture	01	
                                                                  35	

L01.pdf: Program	errors	
       Lexical	analysis	         lexical	errors	
          (scanning)	            text	that	cannot	be	interpreted	as	a	token	
    Syntac8c	analysis	           syntac@c	errors	                              compile-7me	
           (parsing)	            tokens	in	the	wrong	order	                    errors	
                                 sta@c-seman@c	errors	
    Seman8c	analysis	            wrong	use	of	names,	types,	...	
                                                       run7me	errors	
                               interpreter/            null	pointer	excep8on,	
      Code	genera8on	
                                 machine               division	by	zero,	
                                                       stack	overﬂow,	...	
     logic	errors	
     Compute	the	wrong	result.	
     Not	caught	by	the	compiler	or	the	machine.	
     Normally	try	to	catch	using	test	cases.	
     Asser8ons	and	program	veriﬁca8on	can	also	help.	
EDAN65,	Lecture	01	
                                                                                        36	

L01.pdf:                      Example	errors	
Lexical	error:	                Run8me	error:	
int	#	square(int	x)	{	         int	p(int	x)	{	
				return	x	*	x;	             				return	x	/	0;	
}	                             }	
Syntac8c	error:	               Logic	error:	
int	double	square(int	x)	{	    int	square(int	x)	{	
				return	x	*	x;	             				return	2	*	x;	
}	                             }	
Sta8c-seman8c	error:	
boolean	square(int	x)	{	
				return	x	*	x;	
}	
EDAN65,	Lecture	01	
                                                    37	

L01.pdf:          Safe	versus	unsafe	languages	
•   Safe	language	
    	
    All	run8me	errors	are	caught	by	the	generated	code	and/or	run8me	system,	and	
    are	reported	in	terms	of	the	language.	
    	
    Examples:	Java,	C#,	Smalltalk,	Python,	...	
•   Unsafe	language	
    	
    Run8me	errors	in	the	generated	code	can	lead	to	undeﬁned	behavior,	for	example	
    an	out	of	bounds	array	access.	In	the	best	case,	this	gives	a	hardware	excep8on	
    soon	aoer	the	real	error,	stopping	the	program	("segmenta8on	fault").	In	the	
    worst	case,	the	execu8on	con8nues,	compu8ng	the	wrong	result	or	giving	a	
    segmenta8on	fault	much	later,	leading	to	bugs	that	can	be	extremely	hard	to	ﬁnd.	
    	
    Examples:	C,	Assembly	
EDAN65,	Lecture	01	
                                                                                      38	

L01.pdf:          Course	overview	
                                                                        runtime system	
                                               source	code	(text)	
    Regular	         A1	     Lexical	analyzer	                             activation
                                                                                         stack	
  expressions
                  (scanner)	                                   records	
                                               tokens	
 Context-free	      A1,	A2	 Syntac8c	analyzer	
                                                                                        garbage
   grammar
                      (parser)	
                                                                                        collection	
                                               AST	(Abstract	syntax	tree)	
   Apribute	        A3,	A4	                                                              heap	
                            Seman8c	analyzer	
   grammar
                                                                  objects	
                                               Apributed	AST	
                              Intermediate	
                                                  A5	                      Interpreter

                             code	generator	
                                               intermediate	code	                         code
                                                                              Virtual	     and
                                Op8mizer	                                    machine
     data	
                                               intermediate	code	
                               Target	code	
                                                  A6	                       machine
                                generator	
EDAN65,	Lecture	01	                              target	code	
                                                                                               39	

L01.pdf:                    Aoer	this	course...	
•  You	will	have	built	a	complete	compiler	
•  You	will	have	seen	new	declara8ve	ways	of	programming	
•  You	will	have	learnt	some	fundamental	computer	science	theory	
•  You	will	have	experience	from	using	several	prac8cal	tools	
•  You	might	be	interested	in	doing	a	compiler	project	in	the	EDAN70	course	
    (Project	in	Computer	Science)	
•  You	might	be	interested	in	doing	a	master's	thesis	project	in	compilers	
    (related	to	research	or	industry)		
EDAN65,	Lecture	01	
                                                                             40	

L01.pdf:  Applica8ons	of	compiler	construc8on	
•  Tradi8onal	compilers	from	source	to	assembly	
•  Source-to-source	translators,	preprocessors	
•  Interpreters	and	virtual	machines	
•  Integrated	programming	environments	
•  Analysis	tools	
•  Refactoring	tools	
•  Domain-speciﬁc	languages	
EDAN65,	Lecture	01	
                                                 41	

L01.pdf:                        Examples	of	
                  Domain-Speciﬁc	Languages	
EDAN65,	Lecture	01	
                                            42	

L01.pdf:                           HTML	
...	
<h3>Lecture	1:	Introduction.	Mon	13-15.	<a	href="http://
fileadmin.cs.lth.se/cs/Education/EDAN65/2016/documents/
EDAN65-map.pdf">M:A</a></h3>	
		<ul>	
				<li><a	href="http://fileadmin.cs.lth.se/cs/Education/
EDAN65/2016/lectures/L01.pdf">Slides</a>	
				<li>Appel	Book:	Ch	1-1.2	
				<li><a	href	="https://moodle2.cs.lth.se/moodle/mod/quiz/
view.php?id=43">Moodle	Quiz</a>	
		</ul>	
...	
EDAN65,	Lecture	01	
                                                             43	

L01.pdf:                                   .gitconﬁg	
[user]	
								name	=	Görel	Hedin	
								email	=	gorel.hedin@cs.lth.se	
[push]	
								default	=	simple	
EDAN65,	Lecture	01	
                                              44	

L01.pdf:                                                  Modelica	
                                              hpp://www.modelica.org	
model	BouncingBall	//A	model	of	a	bouncing	ball	
				parameter	Real	g	=	9.81;	//	Accelera8on	due	to	gravity	
				parameter	Real	e	=	0.9;	//	Elas8city	coeﬃcient	
				Real	pos(start=1);	//	Posi8on	of	the	ball	
				Real	vel(start=0);	//	Velocity	of	the	ball	
equaDon	
				der(pos)	=	vel;	/	/	Newtons	second	law	
				der(vel)	=	-g;	
				when	pos	<=0	then	
								reinit(vel,-e*pre(vel));	//	set	velocity	aoer	bounce	end	when;	
end	BouncingBall;	
                                 1
                                                                            Earth ball
                                                                            Moon ball
                                0.8
                 Position [m]
                                0.6
                                0.4
                                0.2
                                 0
                                      0   1   2     3      4       5    6   7            8
                                                        Time [s]
EDAN65,	Lecture	01	
                                                                                             45	

L01.pdf:                                   Grafchart	
                    hpp://www.control.lth.se/Research/tools/grafchart.html	
                                              	
EDAN65,	Lecture	01	
                                                                            46	

L01.pdf:                    Control	Builder	Diagram	
                           hpp://new.abb.com	
EDAN65,	Lecture	01	
                                              47	

L01.pdf:                    Related	research	at	LTH	
•  Extensible	compiler	tools	(Görel	Hedin)	
•  Real-8me	garbage	collec8on	(Roger	Henriksson)	
•  Code	op8miza8on	for	mul8processors	(Jonas	Skeppstedt)	
•  Natural	language	processing	(Pierre	Nugues)	
•  Constraint	solver	languages	(Krzysztof	Kuchcinski)	
•  Data-ﬂow	languages	(Jörn	Janneck)	
•  Languages	for	pervasive	systems	(Boris	Magnusson)	
•  Languages	for	requirements	modeling	(Björn	Regnell)	
•  Languages	for	simula8on	and	control	(The	control	department)	
EDAN65,	Lecture	01	
                                                                 48	

L01.pdf:                             Summary	ques8ons	
     •  What	are	the	major	compiler	phases?	
     •  What	is	the	diﬀerence	between	the	analysis	and	synthesis	phases?	
     •  Why	do	we	use	intermediate	code?	
     •  What	is	the	advantage	of	separa8ng	the	front	and	back	ends?	
     •  What	is	
             •  a	lexeme?	
             •  a	token?	
             •  a	parse	tree?	
             •  an	abstract	syntax	tree?	
             •  intermediate	code?	
     •  What	is	the	diﬀerence	between	assembly	code,	object	code,	and	
         executable	code?	
     •  What	is	bytecode,	an	interpreter,	a	virtual	machine?	
     •  What	is	a	JIT	compiler?	
     •  What	kind	of	errors	can	be	caught	by	a	compiler?	A	run8me	system?	
     See	http://cs.lth.se/edan65/week-by-week	for	what	to	do	this	week.	
EDAN65,	Lecture	01	
                                                                           49	

L02.pdf:      EDAN65:	Compilers,	Lecture	02	
Regular	expressions	and	scanning	
             Görel	Hedin	
            Revised:	2016-08-29	

L02.pdf:          Course	overview	             This	lecture	
                                                                runtime system	
                                       source	code	(text)	
    Regular	         Lexical	analyzer	                             activation
                                                                                 stack	
  expressions
          (scanner)	                                   records	
                                       tokens	
 Context-free	      SyntacIc	analyzer	
                                                                                garbage
   grammar
              (parser)	
                                                                                collection	
                                       AST	(Abstract	syntax	tree)	
   ARribute	                                                                     heap	
                    SemanIc	analyzer	
   grammar
                                                          objects	
                                       ARributed	AST	
                      Intermediate	
                                                                   Interpreter

                     code	generator	
                                       intermediate	code	                         code
                                                                      Virtual	     and
                        OpImizer	                                    machine
     data	
                                       intermediate	code	
                       Target	code	
                                                                    machine
                        generator	
EDAN65,	Lecture	02	                      target	code	
                                                                                        2	

L02.pdf:                    Analyzing	program	text	
                          AssignStmt	
                                 Exp	
parse tree	
                                    Add	
                                 Exp	    Exp	
tokens	                ID EQ    ID PLUS ID
   This	lecture	
program text	         sum =    sum    +   k

EDAN65,	Lecture	02	
                                                            3	

L02.pdf:  Recall:	GeneraIng	the	compiler:	
                           We	will	use	a	scanner	
                           generator	called	JFlex	                    text	
  Regular	                                          Lexical	analyzer	
                             Scanner	generator	
expressions
                                           (scanner)	
                                                                      tokens	
Context-free	                      Parser	         SyntacIc	analyzer	
 grammar
                        generator	             (parser)	
                                                                      tree	
 ARribute	                   ARribute	evaluator	
                                                   SemanIc	analyzer	
 grammar
                        generator	
       EDAN65,	Lecture	02	
                                                                              4	

L02.pdf:                              Some	typical	tokens	
                       Token	   Example	lexemes	       Regular	expression	
Reserved	words	        IF	      if		                   "if"	
(keywords)	            THEN	    then	                  "then"	
	                      FOR	     for	                   "for"	
IdenIﬁers	             ID	      B			alpha			k10	       [A-Za-z][A-Za-z0-9]*	
Literals	              INT	     123 0			99			2016	     [0-9]+	
	                      FLOAT	   3.1416			0.2	          [0-9]+	"."		[0-9]+	
	                      STRING	  "Hello"			""			"100%"	 \"	[^\"]*	\"	
	                      CHAR	    'A'			'c'			'%'	       \'	[^\']	\'	
Operators	             PLUS	    +	                     "+"	
	                      INCR	    ++	                    "++"	
	                      NE	      !=	                    "!="	
Separators	            SEMI	    ;	                     ";"	
	                      COMMA	   ,	                     ","	
	                      LPAREN	  (	                     "("	
                                                             JFlex	syntax	
   EDAN65,	Lecture	02	
                                                                             5	

L02.pdf:                    Formal	languages	
•  An	alphabet,	Σ,	is	a	set	of	symbols	(nonempty	and	ﬁnite).	
•  A	string	is	a	sequence	of	symbols	(each	string	is	ﬁnite)	
•  A	formal	language,	L,	is	a	set	of	strings	(can	be	inﬁnite).		
•  We	would	like	to	have	rules	or	algorithms	for	deﬁning	a	
    language	–	deciding	if	a	certain	string	over	the	alphabet	
    belongs	to	the	language	or	not.	
EDAN65,	Lecture	02	
                                                                 6	

L02.pdf:  Example:	Languages	over	binary	numbers	
Suppose	we	have	the	alphabet	Σ	=	{0,	1}	
	
Example	languages:	
•  The	set	of	all	possible	combinaIons	of	zeros	and	ones:	
    L0	=	{0,	1,	00,	01,	10,	11,	000,	...}	
•  All	binary	numbers	without	unnecessary	leading	zeros:	
    L1	=	{0,	1,	10,	11,	100,	101,	110,	111,	1000,	...}	
•  All	binary	numbers	with	two	digits:	
    L2	=	{00,	01,	10,	11}	
•  ...	
EDAN65,	Lecture	02	
                                                           7	

L02.pdf:          Example:	Languages	over	UNICODE	
Here,	the	alphabet	Σ	is	the	set	of	UNICODE	characters	
	
	
Example	languages:	
•  All	possible	Java	keywords:	{"class",	"import",	"public",	...}	
•  All	possible	lexemes	corresponding	to	Java	tokens.	
•  All	possible	lexemes	corresponding	to	Java	whitespace.	
•  All	binary	numbers	
•  ...	
EDAN65,	Lecture	02	
                                                                   8	

L02.pdf:       Example:	Languages	over	Java	tokens	
Here,	the	alphabet	Σ	is	the	set	of	Java	tokens	
	
	
Example	languages:	
•  All	syntacIcally	correct	Java	programs	
•  All	that	are	syntacIcally	incorrect	
•  All	that	are	compile-Ime	correct	
•  All	that	terminate	 (But	this	language	cannot	be	
                       computed:	TerminaIon	is	undecidable:	
•  ...	                it	is	not	possible	to	construct	an	
                       algorithm	that	decides	for	any	string,	if	
                       it	is	a	terminaIng	program	or	not.)	
EDAN65,	Lecture	02	
                                                                  9	

L02.pdf:        Deﬁning	languages	using	rules	
Increasingly	powerful:	
•  Regular	expressions	(for	tokens)	
•  Context-free	grammars	(for	syntax	trees)	
•  ARribute	grammars	(context-free	grammar	+	extra	rules	for	
    further	restricIng	the	language)	
EDAN65,	Lecture	02	
                                                              10	

L02.pdf:    Regular	expressions	(core	notaIon)	
RE	                             read	                      is	called	
a	                              a	                         symbol	
M	|	N	                          M	or	N	                    alternaIve	
M	N	                            M	followed	by	N	           concatenaIon	
∊	                              the	empty	string	          epsilon	
M*	                             zero	or	more	M	            repeIIon	(Kleene	star)	
(M)	
where	a	is	a	symbol	in	the	alphabet	(e.g.,	{0,1}	or	UNICODE)	
and	M	and	N	are	regular	expressions	
	
Each	regular	expression	deﬁnes	a	language	over	the	alphabet	
(a	set	of	strings	that	belong	to	the	langauge).	
	
PrioriIes:					M	|	N	P*				means						M	|	(N	(P*))	
EDAN65,	Lecture	02	
                                                                                   11	

L02.pdf:                       Example	
a	|	b	c*	
	
means	
	
{a,	b,	bc,	bcc,	bccc,	...}	
	
EDAN65,	Lecture	02	
                                12	

L02.pdf:         Regular	expressions	(extended	notaIon)	
Core	RE	                 read	                           is	called	
a	                       a	                              symbol	
M	|	N	                   M	or	N	                         alternaIve	
M	N	                     M	followed	by	N	                concatenaIon	
∊	                       the	empty	string	               epsilon	
M*	                      zero	or	more	M	                 repeIIon	(Kleene	star)	
(M)	
Extended	RE	             read	                           means	
M+	                      at	least	one	...	               M	M*	
M?	                      op9onal	...	                    ∊	|	M	
[aou]	                   one	of	...	(a	character	class)	 a	|	o	|	u	
[a-zA-Z]	                                                a	|	b	|	...	|	z	|	A	|	B	|	...	|	Z	
[^0-9]	                  not	...	                        one	character,	but	not	
(Appel	notaIon:	~[0-9])	                                 anyone	of	those	listed	
"a+b"	                   the	string	...	                 a	\+	b	
EDAN65,	Lecture	02	
                                                                                            13	

L02.pdf:                                   Exercise	
Write	a	regular	expression	that	deﬁnes	the	language	of	all	decimal	numbers,	like	
	
			3.14			0.75			4711			0				...	
	
But	not	numbers	lacking	an	integer	part.	And	not	numbers	with	a	decimal	point	but	
lacking	a	fracIonal	part.	So	not	numbers	like	
	
			17.			.236			.	
	
Leading	and	trailing	zeros	are	allowed.	So	the	following	are	ok:	
	
			007			008.00			0.0			1.700	
	
a)     Use	the	extended	notaIon.	
b)     Then	translate	the	expression	to	the	core	notaIon	
c)     Then	write	an	expression	that	disallows	unnecessary	leading	zeros	
       (in	the	extended	notaIon)	
EDAN65,	Lecture	02	
                                                                                   14	

L02.pdf:                             SoluIon	
a)	
			[0-9]+	("."[0-9]+)?	
	
	
b)	
			(0	|...|	9)(0	|...|	9)*	(∊	|	("."((0	|...|	9)(0	|...|	9)*)))	
	
	
c)	
			(0	|	[1-9]	[0-9]*)	("."[0-9]+)?	
	
    EDAN65,	Lecture	02	
                                                                 15	

L02.pdf:                       Escaped	characters	
                    Use	backslash	to	escape	metacharacters	and	
                    non-prinIng	control	characters.	
Metacharacters	              Non-prin=ng	control	characters	
\+	                          \n	                             newline	
\*	                          \r	                             return	
\(	                          \t	                             tab	
\)	                          \f	                             formfeed	
\|	                          ...	
\\	
...	
EDAN65,	Lecture	02	
                                                                       16	

L02.pdf:                          Some	typical	tokens	
Kind	               Name	   Example	lexemes	  Regular	expression	
Reserved	words	 IF	         if		              "if"	
(keywords)	         THEN	   then	             "then"	
                    FOR	    for	              "for"	
IdenIﬁers	          ID	     B			alpha			k10	  [A-Za-z]([A-Za-z0-9])*	
Literals	           INT	    123			0			99	     [0-9]+	
                    FLOAT	  3.1416			0.2	     [0-9]+	"."		[0-9]+	
                    CHAR	   'A'			'c'	        \'	[^\']	\'	
                    STRING	 "Hello"		""		"j"	 \"	[^\"]*	\"	
Operators	          PLUS	   +	                "+"	
                    INCR	   ++	               "++"	
                    NE	     !=	               "!="	
Separators	         SEMI	   ;	                ";"	
                    COMMA	  ,	                ","	
                    LPAREN	 (	                "("	
EDAN65,	Lecture	02	
                                                                      17	

L02.pdf:                       Some	typical	non-tokens	
Non-Token	               Example	lexemes	           Regular	expression	(jﬂex)	
WHITESPACE	              blank			tab			newline	     "	"	|	\t	|	\n	|	\r	
                         return	                    	
ENDOFLINECOMMENT	        //	comment	                "//"	[^\n\r]*	([\n\r])?	
                                                               JFlex	syntax	
  Non-tokens	are	also	recognized	by	the	scanner,	just	like	tokens.	
  But	they	are	not	sent	on	to	the	parser.	
  (The	newline/return	ending	an	end-of-line	comment	is	opIonal	in	order	to	allow	a	
  ﬁle	to	end	with	an	end-of-line	comment,	without	an	extra	newline/return.)	
  EDAN65,	Lecture	02	
                                                                                    18	

L02.pdf:                       JFlex:	A	scanner	generator	
                        GeneraIng	a	scanner	for	a	language	lang	
                                                          Program.lang	
                                                                  characters	
      lang.jﬂex
                    jﬂex.jar	           LangScanner.java	
Scanner	speciﬁcaIon	
 with	regular	exprs
           Scanner	generator	                  tokens	
                                                         LangParser.java	
   EDAN65,	Lecture	02	
                                                                              19	

L02.pdf:                              A	JFlex	speciﬁcaIon	
  package	lang;												//	the	generated	scanner	will	belong	to	the	package	lang	
  import	lang.Token;							//	Our	own	class	for	tokens	
  ...	
  	
  //	ignore	whitespace	
  "	"	|	\t	|	\n	|	\r	|	\f				{	/*	ignore	*/	}	
  	
  //	tokens	
  "if"																{	return	new	Token("IF");	}	
  "="																	{	return	new	Token("ASSIGN");	}	
  "<"																	{	return	new	Token("LT");	}	
  "<="																{	return	new	Token("LE");	}	
  [a-zA-Z]+											{	return	new	Token("ID",	yytext());	}	
  ...	
  Rules	and	lexical	ac=ons	                               What	rules	are	used	when	
  Each	rule	has	the	form:	                                scanning	"a	<	b"?	
  					regular-expression						{	lexical	ac9on	}	
  The	lexical	acIon	consists	of	arbitrary	Java	code.	
  It	is	run	when	a	regular	expression	is	matched.	
  The	method	yytext()	returns	the	lexeme	(the	token	value).	
EDAN65,	Lecture	02	
                                                                                     20	

L02.pdf:                                AmbiguiIes?	
  package	lang;												//	the	generated	scanner	will	belong	to	the	package	lang	
  import	lang.Token;							//	Class	for	tokens	
  ...	
  	
  //	ignore	whitespace	
  "	"	|	\t	|	\n	|	\r	|	\f				{	/*	ignore	*/	}	
  	
  //	tokens	
  "if"																{	return	new	Token("IF");	}	
  "="																	{	return	new	Token("ASSIGN");	}	
  "<"																	{	return	new	Token("LT");	}	
  "<="																{	return	new	Token("LE");	}	
  [a-zA-Z]+											{	return	new	Token("ID",	yytext());	}	
  ...	
                       Are	the	token	deﬁni=ons	ambiguous?	
                       Which	rules	match	"<="?	
                       Which	rules	match	"if"?	
                       Which	rules	match	"iﬀf"?	
                       Which	rules	match	"xyz"?	
EDAN65,	Lecture	02	
                                                                                     21	

L02.pdf:    Extra	rules	for	resolving	ambiguiIes	
Longest	match	
     If	one	rule	can	be	used	to	match	a	token,	but	there	is	another	rule	
     that	will	match	a	longer	token,	the	laRer	rule	will	be	chosen.	This	
     way,	the	scanner	will	match	the	longest	token	possible.	
     	
Rule	priority	
     If	two	rules	can	be	used	to	match	the	same	sequence	of	characters,	
     the	ﬁrst	one	takes	priority.	
EDAN65,	Lecture	02	
                                                                          22	

L02.pdf:            ImplementaIon	of	scanners	
ObservaIon:	
     Regular	expressions	are	equivalent	to	ﬁnite	automata	(ﬁnite-state	machines).	
     (They	can	recognize	the	same	class	of	formal	languages:	the	regular	languages.)	
Overall	approach:	
•  Translate	each	token	regular	expression	to	a	ﬁnite	automaton.	
    Label	the	ﬁnal	state	with	the	token.	
•  Merge	all	the	automata.	
•  The	resulIng	automaton	will	in	general	be	nondeterminis9c	
•  Translate	the	nondeterminisIc	automaton	to	a	determinis9c	automaton.	
•  Implement	the	determinisIc	automaton,	
    either	using	switch	statements	or	a	table.	
A	scanner	generator	automates	this	process.	
EDAN65,	Lecture	02	
                                                                                   23	

L02.pdf:    Construct	an	automaton	for	each	token	
                       i	             f	
    "if"	                                      IF	
                                                      state	
                               0-9	
                     0-9	
  [0-9]+	                             INT	
                                                   a	 transiIon	
                        "	"	          WHITESPACE	
                          \n	
 "	"	|	\n	|	\t	                       WHITESPACE	
                                                      start	state	
                        \t	           WHITESPACE	
                              a-zA-Z	
                                                      ﬁnal	state	
                    a-zA-Z	
   [a-zA-Z]+	                          ID	
EDAN65,	Lecture	02	
                                                                 24	

L02.pdf:     Merge	the	start	states	of	the	automata	
                                               f	
                                                        IF	
                                i	
                                        0-9	
                               0-9	
                                               INT	
                               "	"\n\t	
                                               WHITESPACE	
                           a-zA-Z	     a-zA-Z	
                                                ID	
                    Is	the	new	automaton	determinis=c?	
EDAN65,	Lecture	02	
                                                            25	

L02.pdf:                         DeterminisIc	ﬁnite	automata	
In	a	determinisIc	ﬁnite	automaton	each	transiIon	is	uniquely	determined	by	the	input.	
                  a	     2	     NondeterminisIc,	since	if	we	read	a	when	in	state	1,	
            1	                  we	don't	know	if	we	should	go	to	state	2	or	3.	
                  a	     3	
                      ε	        NondeterminisIc,	since	when	we	are	in	state	1,	we	don't	
              1	          2	    know	if	we	should	stay	there,	or	go	to	state	2	without	
                                reading	any	input.	(Epsilon	denotes	the	empty	string.)	
                    a	    2	
                                DeterminisIc,	since	from	state	1,	the	next	input	
              1	                determines	if	we	go	to	state	2	or	3.	
                    b	    3	
   EDAN65,	Lecture	02	
                                                                                        26	

L02.pdf:                        DFA	versus	NFA	
Determinis=c	Finite	Automaton	(DFA)	
A	ﬁnite	automaton	is	determinisIc	if	
      –  all	outgoing	edges	from	any	given	state	have	disjoint	character	sets	
      –  there	are	no	epsilon	edges	
Can	be	implemented	eﬃciently	
	
	
Non-determinis=c	Finite	Automaton	(NFA)	
An	NFA	may	have	
      –  two	outgoing	edges	with	overlapping	character	sets	
      –  epsilon	edges	
Every	DFA	is	also	an	NFA.	
Every	NFA	can	be	translated	to	an	equivalent	DFA.	
	
	EDAN65,	Lecture	02	                                                           27	

L02.pdf:            TranslaIng	an	NFA	to	a	DFA	
Simulate	the	NFA	
     –  keep	track	of	a	set	of	current	NFA-states	
     –  follow	ε	edges	to	extend	the	current	set	(take	the	closure)	
	
Construct	the	corresponding	DFA	
     –  Each	such	set	of	NFA	states	corresponds	to	one	DFA	state	
     –  If	any	of	the	NFA	states	is	ﬁnal,	the	DFA	state	is	also	ﬁnal,	
          and	is	marked	with	the	corresponding	token.	
     –  If	there	is	more	than	one	token	to	choose	from,	select	the	
          token	that	is	deﬁned	ﬁrst	(rule	priority).	
(Minimize	the	DFA	for	eﬃciency)	
EDAN65,	Lecture	02	
                                                                       28	

L02.pdf:                                      Example	
               NFA	                                 DFA	
                     f	                           ID	         f	
                  2	         3	   IF	                 2,4	            3,4	  IF	
        i	                                     i	
                                                           a-eg-z	
   1	                                      1	
            a-z	                                                          a-z	
                        a-z	                                     a-z	
                                              a-hj-z	
                         4	   ID	                                 4	    ID	
EDAN65,	Lecture	02	
                                                                                29	

L02.pdf:                             Error	handling	
                                           ID	
                                                  f	
                                            2	             3	   IF	
                                    i	
                                               a-eg-z	
                                1	
                                                              a-z	
                                                     a-z	
                                       a-hj-z	
                                                      4	    ID	
                                                        ^a-z	         ^a-z	
                               ^a-z	
                    ^a-z	
                                               0	
                                         ERROR	
               •  Add	a	"dead	state"	(state	0),	corresponding	to	erroneous	input.	
               •  Add	transiIons	to	the	"dead	state"	for	all	erroneous	input.	
               •  Generate	an	"ERROR	token"	when	the	dead	state	is	reached.	
EDAN65,	Lecture	02	
                                                                                   30	

L02.pdf:  ImplementaIon	alternaIves	for	DFAs	
Table-driven	
     –  Represent	the	automaton	by	a	table	
     –  AddiIonal	table	to	keep	track	of	ﬁnal	states	and	token	kinds	
     –  A	global	variable	keeps	track	of	the	current	state	
	
Switch	statements	
     –  Each	state	is	implemented	as	a	switch	statement	
     –  Each	case	implements	a	state	transiIon	as	a	jump	(to	another	switch	
          statement)	
     –  The	current	state	is	represented	by	the	program	counter.	
EDAN65,	Lecture	02	
                                                                             31	

L02.pdf:           Table-driven	implementaIon	
                                        ID	           f	
                                               2	                3	   IF	
                                      i	
                                                   a-eg-z	
                                   1	
                                                                    a-z	
                                                         a-z	
                            +	
                                         a-hj-z	
                                                          4	      ID	
                      PLUS	   5	
     ...	    +	    ...	 a	  ...	 e	   f	    g	    ...	 h	     i	     j	   ...	 z	 ...	 ﬁnal	   kind	
0	    0	     0	     0	  0	   0	  0	   0	    0	     0	    0	   0	     0	    0	  0	  0	 true	  ERROR	
1	    0	     5	     0	  4	   4	  4	   4	    4	     4	    4	   2	     4	    4	  4	  0	 false	
2	    0	     0	     0	  4	   4	  4	   3	    4	     4	    4	   4	     4	    4	  4	  0	 true	  ID	
3	    0	     0	     0	  4	   4	  4	   4	    4	     4	    4	   4	     4	    4	  4	  0	 true	  IF	
4	    0	     0	     0	  4	   4	  4	   4	    4	     4	    4	   4	     4	    4	  4	  0	 true	  ID	
5	    0	     0	     0	  0	   0	  0	   0	    0	     0	    0	   0	     0	    0	  0	  0	 true	  PLUS	
 EDAN65,	Lecture	02	
                                                                                                     32	

L02.pdf:    Scanner	implementaIon,	design	
                                            Token

                                     int kind()

                                     String value()

                               call	                    call	
                    File
                  Scanner
             Parser

              char nextChar()
       Token nextToken()
       

              
                      
                        

EDAN65,	Lecture	02	
                                                                        33	

L02.pdf:     Scanner	implementaIon,	sketch	
   Idea:	Scan	the	next	token	by	
   •  starIng	in	the	start	state	
   •  scan	characters	unIl	we	reach	a	ﬁnal	state	
   •  return	a	new	token	
  Token	nextToken()	{	
  			state	=	1;	//	start	state	
  			while	(!	isFinal[state])	{	
  						ch	=	file.readChar();	
  						state	=	edges[state,	ch];	
  			}	
  			return	new	Token(kind[state]);	
  }	
 Needs	to	be	extended	with	handling	of:	
 •  longest	match	
 •  end	of	ﬁle	
 •  non	tokens	(like	whitespace)	
 •  token	values	(like	the	idenIﬁer	name)	
EDAN65,	Lecture	02	
                                                  34	

L02.pdf:                       Extend	to	longest	match,	design	
                                                            Token

                                                     int kind()

                                                     String value()

      File
                   PushbackFile
                Scanner
               Parser

char readChar()
        char readChar()
             Token nextToken()
         


                       void pushback(String)
       
                          

                        

   Idea:	
   •  When	a	token	is	matched,	don't	stop	scanning.	
   •  When	the	error	state	is	reached,	return	the	last	token	matched.	
   •  Push	read	characters	that	are	unused	back	into	the	ﬁle,	so	they	can	be	scanned	again.	
   •  Use	a	PushbackFile	to	accomplish	this.	
   EDAN65,	Lecture	02	
                                                                                          35	

L02.pdf:      Extend	to	handle	longest	match,	sketch	
•    When	a	token	is	matched	(a	ﬁnal	state	reached),	don’t	stop	scanning.	
•    Keep	track	of	the	currently	scanned	string,	str.	
•    Keep	track	of	the	latest	matched	token	(lastFinalState,	lastTokenValue).	
•    ConInue	scanning	unIl	we	reach	the	error	state.	
•    Restore	the	input	stream	using	PushBackFile.	
•    Return	the	latest	matched	token.	
•    (or	return	the	ERROR	token	if	there	was	no	latest	matched	token)	
   Token	nextToken()	{	
   			state	=	1;	
   			str	=	"";	
   			lastFinalState	=	0;	lastTokenValue	=	"";	
   			while	(state	!=	0)	{	
   						ch	=	pushbackfile.readChar();	
   						str	=	str	+	ch;		          //	In	Java,	StringBuilder	would	be	more	efficient	
   						state	=	edges[state,	ch];	
   						if	(isFinal[state])	{	
   									lastFinalState	=	state;	
   									lastTokenValue	=	str;	
   						}	
   			}	
   			pushbackfile.pushback(str.substring(lastTokenValue.length));	
   			return	new	Token(kind[lastFinalState],	lastTokenValue);	
   }	
EDAN65,	Lecture	02	
                                                                                       36	

L02.pdf:       Handling	End-of-ﬁle	(EOF)	and	non-tokens		
EOF	
     –  construct	an	explicit	EOF	token	when	the	EOF	character	is	read	
	
Non-tokens	(Whitespace	&	Comments)	
     –  view	as	tokens	of	a	special	kind	
     –  scan	them	as	normal	tokens,	but	don’t	create	token	objects	for	them	
     –  loop	in	next()	unIl	a	real	token	has	been	found	
	
Errors	
     –  construct	an	explicit	ERROR	token	to	be	returned	when	no	valid	token	
          can	be	found.	
EDAN65,	Lecture	02	
                                                                              37	

L02.pdf:                  Specifying	EOF	and	ERROR	in	JFlex	
  package	lang;												//	the	generated	scanner	will	belong	to	the	package	lang	
  import	lang.Token;							//	Class	for	tokens	
  ...	
  	
  //	ignore	whitespace	
  "	"	|	\t	|	\n	|	\r	|	\f				{	/*	ignore	*/	}	
  	
  //	tokens	
  "if"																{	return	new	Token("IF");	}	
  "="																	{	return	new	Token("ASSIGN");	}	
  "<"																	{	return	new	Token("LT");	}	
  "<="																{	return	new	Token("LE");	}	
  [a-zA-Z]+											{	return	new	Token("ID",	yytext());	}	
  ...	
  <<EOF>>													{	return	new	Token("EOF");	}	
  [^]																	{	return	new	Token("ERROR");	}	
  <<EOF>>	is	a	special	regular	expression	in	JFlex,	matching	end	of	ﬁle.	
  	
  [^]	means	any	character.	Due	to	rule	priority,	this	will	match	any	character	not	
  matched	by	previous	rules.	
  	
EDAN65,	Lecture	02	
                                                                                     38	

L02.pdf:            Example	scanner	generators	
         tool	             author	              generates	
         lex	              Schmidt,	Lesk.	1975	 C-code	
         ﬂex	("fast	lex")	 Paxon.	1987	         C-code	
         jlex	                                  Java	code	
         jﬂex	                                  Java	code	
         ...	
EDAN65,	Lecture	02	
                                                           39	

L02.pdf:         LimitaIons	of	regular	expressions	
                                 for	scanning	
•  Nested	comments?	
•  Layout-sensiIve	syntax?	
•  Context-sensiIve	token	deﬁniIons?	
    For	example,	mulI-language	documents.	
•  Two	mechanisms	in	scanner	generators	for	workarounds:	
     –  Lexical	ac=ons:	
          do	more	than	create	a	token,	e.g.,	count	nesIng	levels	of	comments.	
     –  Lexical	states:	
          switch	between	diﬀerent	sets	of	token	deﬁniIons.	
  EDAN65,	Lecture	02	
                                                                               40	

L02.pdf:                                 Lexical	states	
 •  Some	tokens	are	diﬃcult	or	impossible	to	deﬁne	with	regular	expressions.	
 •  Lexical	states	(sets	of	token	rules)	give	the	possibility	to	switch	token	sets	
     (DFAs)	during	scanning.	
                      LEXSTATE1	           LEXSTATE2	
                          T1	                  T5	
                          T2	                  T6	
                          T3	                  T7	
                          T4	                 ...	
                         ...	
	
•  Useful	for	mulI-line	comments,	HTML,	scanning	mulI-language	
     documents,	etc.	
•  Supported	by	many	scanner	generators	(including	JFlex)	
   EDAN65,	Lecture	02	
                                                                                    41	

L02.pdf:                    Example:	mulI-line	comments	
   Would	like	to	scan	the	complete	comment	as	one	token:	
     /*	
     int	m()	{	
     			return	15	/	3	*	4	*	2;	
     }	
     */	
   Can	be	solved	easily	with	lexical	states:	
      Default	           ID	                             "*/"	 Token	set	used	
                       "if"			                            [^]	
      token	set	      "then"	
                                                               inside	comment	
                       "/*"	
                        ...	
           WriIng	an	ordinary	regular	expression	for	this	is	diﬃcult:	
                            "/*"((\*+[^/*])|([^*]))*\**"*/"	
   However,	some	scanner	generators,	like	JFlex,	has	the	special	operator	upto	(~)	that	
   can	be	used	instead:	                     "/*"	~"*/"			{	/*	Comment	*/	}	
EDAN65,	Lecture	02	
                                                                                         42	

L02.pdf:          Course	overview	
                                                                     runtime system	
                                            source	code	(text)	
    Regular	        A	1	  Lexical	analyzer	                             activation
                                              This	lecture	                           stack	
  expressions
               (scanner)	                                   records	
                                            tokens	
 Context-free	      A	1	 SyntacIc	analyzer	
                                              Next	lecture	                          garbage
   grammar
                   (parser)	
                                                                                     collection	
                                            AST	(Abstract	syntax	tree)	
   ARribute	                                                                          heap	
                         SemanIc	analyzer	
   grammar
                                                               objects	
                                            ARributed	AST	
                           Intermediate	
                                                                        Interpreter

                          code	generator	
                                            intermediate	code	                         code
                                                                           Virtual	     and
                             OpImizer	                                    machine
     data	
                                            intermediate	code	
                            Target	code	
                                                                         machine
                             generator	
EDAN65,	Lecture	02	                           target	code	
                                                                                            43	

L02.pdf:                          Summary	quesIons	
•  What	is	a	formal	language?	
•  What	is	a	regular	expression?	
•  What	is	meant	by	an	ambiguous	lexical	deﬁniIon?	
•  Give	some	typical	examples	of	ambiguiIes	and	how	they	may	be	resolved.	
•  What	is	a	lexical	acIon?	
•  Give	an	example	of	how	to	construct	an	NFA	for	a	given	lexical	deﬁniIon	
•  Give	an	example	of	how	to	construct	a	DFA	for	a	given	NFA	
•  What	is	the	diﬀerence	between	a	DFA	and	and	NFA?	
•  Give	an	example	of	how	to	implement	a	DFA	in	Java.	
•  How	is	rule	priority	handled	in	the	implementaIon?	Longest	match?	EOF?	
   Whitespace?	Errors?	
•  What	are	lexical	states?	When	are	they	useful?	
You	can	start	on	Assignment	1	now.	But	you	will	have	to	wait	unIl	the	next	lecture	
for	the	parts	about	parsing.	
EDAN65,	Lecture	02	
                                                                                    44	

L03.pdf:  EDAN65:	Compilers,	Lecture	03	
Context-free	grammars,	
introduc@on	to	parsing	
         Görel	Hedin	
        Revised:	2016-09-05	

L03.pdf:     Course	overview	
                                                          runtime system	
                                 source	code	(text)	
  Regular	     Lexical	analyzer	                             activation
                                                                           stack	
expressions
      (scanner)	                                   records	
                                 tokens	
Context-free	 Syntac@c	analyzer	
                                   This	lecture	                          garbage
 grammar
          (parser)	
                                                                          collection	
                                 AST	(Abstract	syntax	tree)	
 ARribute	                                                                 heap	
              Seman@c	analyzer	
 grammar
                                                      objects	
                                 ARributed	AST	
                Intermediate	
                                                             Interpreter

               code	generator	
                                 intermediate	code	                         code
                                                                Virtual	     and
                  Op@mizer	                                    machine
     data	
                                 intermediate	code	
                 Target	code	
                                                              machine
                  generator	
                                   target	code	
                                                                                  2	

L03.pdf:            Analyzing	program	text	
                    AssignStmt	
                          Exp	
parse	tree	
                             Add	
                          Exp	   Exp	
tokens	        ID				EQ				ID		PLUS		ID		SEMI	
program	text	 sum				=				sum				+				k				;	
                                               3	

L03.pdf:  Recall:	Genera@ng	the	compiler:	
                                                                        text	
  Regular	               Scanner	generator	           Lexical	analyzer	
expressions
                    JFlex	                    (scanner)	
                                                                        tokens	
Context-free	             Parser	generator	          Syntac@c	analyzer	
 grammar
                      Beaver	                     (parser)	
                                                                        tree	
 ARribute	               ARribute	evaluator	
                                                     Seman@c	analyzer	
 grammar
                     generator	
            We	will	use	a	parser	generator	called	Beaver	
                                                                                4	

L03.pdf:Context-Free	Grammars	
                       5	

L03.pdf:  Regular	Expressions	vs	Context-Free	Grammars	
Example	REs:	                Example	CFG:	
WHILE	=	"while"	             Stmt	–>	WhileStmt	
ID	=	[a-z][a-z0-9]*	         Stmt	–>	AssignStmt	
LPAR	=	"("	                  WhileStmt	–>	WHILE	LPAR	Exp	RPAR	Stmt	
RPAR	=	")"	                  Exp	–>	ID	
PLUS	=	"+"	                  Exp	–>	Exp	PLUS	Exp	
...	                         ...	
                          An	RE	can	have	itera'on	
                                          	
                      A	CFG	can	also	have	recursion	
            (it	is	possible	to	derive	a	symbol,	e.g.,	Stmt,	from	itself)	
                                                                          6	

L03.pdf:    Elements	of	a	Context-Free	Grammar	
            Example	CFG:	
            Stmt	–>	WhileStmt	
            Stmt	–>	AssignStmt	
            WhileStmt	–>	WHILE	LPAR	Exp	RPAR	Stmt	
            AssignStmt	–>	ID	EQ	Exp	SEMIC	
            …	
                          Produc'on	rules:	
                        X	–>	s1	s2	…	sn	
              where	sk	is	a	symbol	(terminal	or	nonterminal)	
                                     	
                      Nonterminal	symbols	
                                     	
                   Terminal	symbols	(tokens)	
                                     	
                             Start	symbol	
(one	of	the	nonterminals,	usually	the	le]-hand	side	of	the	ﬁrst	produc@on)	
                                                                            7	

L03.pdf:Shorthand	for	alterna@ves	
      Stmt	–>	WhileStmt	
      Stmt	–>	AssignStmt	
        is	equivalent	to	
 Stmt	–>	WhileStmt	|	AssignStmt	
                                 8	

L03.pdf:                        Exercise	
Construct	a	grammar	covering	this	program	and	similar	ones:	
      Example	program:	
      while	(k	<=	n)	{sum	=	sum	+	k;	k	=	k+1;}		
      	
      CFG:	
      Stmt	–>	WhileStmt	|	AssignStmt	|	CompoundStmt	
      WhileStmt	–>	"while"	"("	Exp	")"	Stmt	
      AssignStmt	–>	ID	"="	Exp	";"	
      CompoundStmt	–>	...	
      Exp	–>	...	
      LessEq	–>	...	
      Add	–>	...	
      	
      	
  (O]en,	simple	tokens	are	wriRen	directly	as	text	strings)	
                                                             9	

L03.pdf:                        Solu@on	
Construct	a	grammar	covering	this	program	and	similar	ones:	
      Example	program:	
      while	(k	<=	n)	{sum	=	sum	+	k;	k	=	k+1;}		
      

      CFG:	
      Stmt	–>	WhileStmt	|	AssignStmt	|	CompoundStmt	
      WhileStmt	–>	"while"	"("	Exp	")"	Stmt	
      AssignStmt	–>	ID	"="	Exp	";"	
      CompoundStmt	–>	"{"	Stmt*	"}"	
      Exp	–>	LessEq	|	Add	|	ID	|	INT	
      LessEq	–>	Exp	"<="	Exp	
      Add	–>	Exp	"+"	Exp	
      

      	
                                                             10	

L03.pdf:                          Parsing	
         Use	the	grammar	to	derive	a	tree	for	a	program:	
                         Stmt		             Start	symbol	
Example	program:	
sum	=	sum	+	k;	


                   sum		=		sum		+		k		;	                  11	

L03.pdf:                                   Parse	tree	
         Use	the	grammar	to	derive	a	parse	tree	for	a	program:	
                                   Stmt		         Start	symbol	
Example	program:	
sum	=	sum	+	k;	


                                AssignStmt	
                                                 Nonterminals	are	
  A	parse	tree	includes	all	          Exp	          inner	nodes	
  the	tokens	as	leafs.	
                                         Add	
                                      Exp	 Exp	
                             sum		=		sum		+		k		;	Terminals	are	leafs	 12	

L03.pdf:          Corresponding	abstract	syntax	tree	
                (will	be	discussed	in	later	lecture)		
                           AssignStmt		
Example	program:	
sum	=	sum	+	k;	


                                             An	abstract	syntax	tree	is	similar	
                                             to	a	parse	tree,	but	simpler.	
                                             	
                                             It	does	not	include	all	the	tokens.	
                                  Add	
                   IdExp	 IdExp	 IdExp	
                  sum		=		sum		+		k		;	                                       13	

L03.pdf:                 EBNF	vs	Canonical	Form	
                                   (Extended)	Backus-Naur	Form:	
EBNF:	                             •  Compact,	easy	to	read	and	write	
Stmt	–>	AssignStmt	|	CompoundStmt	 •  EBNF	has	alterna@ves,	repe@@on,	
AssignStmt	–>	ID	"="	Exp	";"	         op@onals,	parentheses	(like	REs)	
CompoundStmt	–>	"{"	Stmt*	"}"	     •  Common	nota@on	for	prac@cal	use	
Exp	–>	Add	|	ID	
Add	–>	Exp	"+"	Exp	
                                   Canonical	form:	
Canonical	form:	                   •  Core	formalism	for	CFGs	
Stmt	–>	ID	"="	Exp	";"	            •  Useful	for	proving	proper@es	and	
Stmt	–>	"{"	Stmts	"}"	                explaining	algorithms	
Stmts	–>	ε	
Stmts	–>	Stmt	Stmts	
Exp	–>	Exp	"+"	Exp	
Exp	–>	ID	
                                                                        14	

L03.pdf:                         Real	world	example:	
                The	Java	Language	Speciﬁca@on	
            Compila@onUnit:	
            			[PackageDeclara@on]	{ImportDeclara@on}	{TypeDeclara@on}	
            	
            PackageDeclara@on:	
            			{PackageModiﬁer}	package	Iden@ﬁer	{.	Iden@ﬁer}	;	
            	
            PackageModiﬁer:	
            			Annota@on	
            	
            …	
See	http://docs.oracle.com/javase/specs/jls/se8/html/index.html	
•  See	Chapter	2	about	the	Java	grammar	nota@on.	
•  Look	at	some	other	chapters	to	see	other	syntax	examples.	
                                                                        15	

L03.pdf:Formal	deﬁni@on	of	CFGs	
                         16	

L03.pdf:Formal	deﬁni@on	of	CFGs	(canonical	form)	
 A	context-free	grammar	G	=	(N,	T,	P,	S),	where	
 N	–	the	set	of	nonterminal	symbols	
 T	–	the	set	of	terminal	symbols	
 P	–	the	set	of	produc@on	rules,	each	with	the	form	
 										X	–>	Y1	Y2	…	Yn		
 						where	X	∈	N,	n	≥	0,	and	Yk	∈	N	∪	T	
 S	–	the	start	symbol	(one	of	the	nonterminals).	I.e.,	S	∈	N	
 So,	the	le:-hand	side	X	of	a	rule	is	a	nonterminal.	
 	
 And	the	right-hand	side	Y1	Y2	…	Yn		is	a	sequence	of	nonterminals	
 and	terminals.	
 	
 If	the	rhs	for	a	produc@on	is	empty,	i.e.,	n	=	0,	we	write	
 										X	–>	ε	
                                                                    17	

L03.pdf:   A	grammar	G	deﬁnes	a	language	L(G)	
A context-free	grammar	G	=	(N,	T,	P,	S),	where	
N	–	the	set	of	nonterminal	symbols	
T	–	the	set	of	terminal	symbols	
P	–	the	set	of	produc@on	rules,	each	with	the	form	
										X	–>	Y1	Y2	…	Yn		
						where	X	∈	N,	n	≥	0,	and	Yk	∈	N	∪	T	
S	–	the	start	symbol	(one	of	the	nonterminals).	I.e.,	S	∈	N	
G	deﬁnes	a	language	L(G)	over	the	alphabet	T	
	
T*	is	the	set	of	all	possible	sequences	of	T	symbols.	
	
L(G)	is	the	subset	of	T*	that	can	be	derived	from	the	start	symbol	
S,	by	following	the	produc@on	rules	P.	
                                                                    18	

L03.pdf:                           Exercise	
G	=	(N,	T,	P,	S)	             L(G)	=	{	
	                             	
P	=	{	                        	
		Stmt	–>	ID	"="	Exp	";",	    	
		Stmt	–>	"{"	Stmts	"}"	,	    	
		Stmts	–>	ε	,	               	
		Stmts	–>	Stmt	Stmts	,	      	
		Exp	–>	Exp	"+"	Exp	,	       	
		Exp	–>	ID	                  	
}	                            	
	                             	
N	=	{																					}	  	
	                             	
T	=	{																					}	  	
	                             	
S	=	                          }	
                                        19	

L03.pdf:                            Solu@on	
G	=	(N,	T,	P,	S)	                    L(G)	=	{	
	                                    	"{"	"}",	
P	=	{	                               	"{"	"{"	"}"	"}",	
		Stmt	–>	ID	"="	Exp	";",	           	ID	"="	ID	";",	
		Stmt	–>	"{"	Stmts	"}"	,	           	"{"	ID	"="	ID	";"	"}",	
		Stmts	–>	ε	,	                      	ID	"="	ID	"+"	ID	";",	
		Stmts	–>	Stmt	Stmts	,	             	"{"	"{"	"}"	"{"	"}"	"}",	
		Exp	–>	Exp	"+"	Exp	,	              	"{"	"{"	"{"	"}"	"}"	"}",	
		Exp	–>	ID	                         	"{"	ID	"="	ID	"+"	ID	";"	"}",	
}	                                   	ID	"="	ID	"+"	ID	"+"	ID	";",	
	                                    	...	
N	=	{Stmt,	Exp,	Stmts}	              			
	                                    	
T	=	{ID,	"=",	"{",	"}",	";",	"+"}	   	
	                                    	
S	=	Stmt	                            }	
   The	sequences	in	L(G)	are	usually	called	sentences	or	strings	
                                                                   20	

L03.pdf:Deriva@ons	
            21	

L03.pdf:                        Deriva@on	step	
If	we	have	a	sequence	of	terminals	and	nonterminals,	e.g.,		
	
			X	a	Y	Y	b	
	
we	can	replace	one	of	the	nonterminals,	applying	a	produc@on	
rule.	This	is	called	a	deriva'on	step.		
(Swedish:	Härledningssteg)	
Suppose	there	is	a	produc@on	
	
			Y	–>	X	a	
	
and	we	apply	it	for	the	ﬁrst	Y	in	the	sequence.	We	write	the	
deriva@on	step	as	follows:	
	
		X	a	Y	Y	b	=>	X	a	X	a	Y	b	
                                                              22	

L03.pdf:                                  Deriva@on	
A	deriva'on,	is	simply	a	sequence	of	deriva@on	steps,	e.g.:		
	
			γ0	=>	γ1	=>	…	=>	γn										(n	≥	0)		
	
where	each	γi	is	a	sequence	of	terminals	and	nonterminals	
If	there	is	a	deriva@on	from	γ0	to	γn,	we	can	write	this	as	
	
			γ0	=>*	γn	
	
So	this	means	it	is	possible	to	get	from	the	sequence	γ0	to	the	
sequence	γn	by	following	the	produc@on	rules.	
                                                                 23	

L03.pdf:          Deﬁni@on	of	the	language	L(G)	
Recall	that:	
	
				G	=	(N,	T,	P,	S)	
	
				T*	is	the	set	of	all	possible	sequences	of	T	symbols.	
	
				L(G)	is	the	subset	of	T*	that	can	be	derived	from	the		
				start	symbol	S,	by	following	the	produc@on	rules	P.	
Using	the	concept	of	deriva@ons,	we	can	formally	deﬁne	L(G)	as	follows:	
	
		L(G)	=	{	w	∈	T*	|	S	=>*	w	}	


                                                                         24	

L03.pdf:                           Exercise:	
      Prove	that	a	sentence	belongs	to	a	language	
Prove	that	                     belongs	to	the	language	of	the	
	                               following	grammar:	
			INT	+	INT	*	INT	             	
                                p1: 	Exp	–>	Exp	"+"	Exp	
                                p2: 	Exp	–>	Exp	"*"	Exp	
                                p3: 	Exp	–>	INT	
Proof	(by	showing	all	the	deriva@on	steps	from	the	start	symbol	
Exp):	
	
Exp	
=>	








                                                                 25	

L03.pdf:                           Solu@on:	
      Prove	that	a	sentence	belongs	to	a	language	
Prove	that	                     belongs	to	the	language	of	the	
	                               following	grammar:	
			INT	+	INT	*	INT	             	
                                p1: 	Exp	–>	Exp	"+"	Exp	
                                p2: 	Exp	–>	Exp	"*"	Exp	
                                p3: 	Exp	–>	INT	
Proof	(by	showing	all	the	deriva@on	steps	from	the	start	symbol	
Exp):	
	
Exp	
=>	Exp	"+"	Exp                           	(p1)	
=>	INT	"+"	Exp	                          	(p3)	
=>	INT	"+"	Exp	"*"	Exp                   	(p2)	
=>	INT	"+"	INT	"*"	Exp                   	(p3)	
=>	INT	"+"	INT	"*"	INT                   	(p3)	
                                                                 26	

L03.pdf:       Le]most	and	rightmost	deriva@ons	
In	a	le:most	deriva@on,	the	              In	a	rightmost	deriva@on,	the	
le]most	nonterminal	is	replaced	          rightmost	nonterminal	is	replaced	in	
in	each	deriva@on	step,	e.g.,:	           each	deriva@on	step,	e.g.,:	
	                                         	
Exp	=>	                                   Exp	=>	
Exp	"+"	Exp	=>	                           Exp	"+"	Exp	=>	
INT	"+"	Exp	=>	                           Exp	"+"	Exp	"*"	Exp	=>	
INT	"+"	Exp	"*"	Exp	=>	                   Exp	"+"	Exp	"*"	INT	=>	
INT	"+"	INT	"*"	Exp	=>	                   Exp	"+"	INT	"*"	INT	=>	
INT	"+"	INT	"*"	INT	                      INT	"+"	INT	"*"	INT	
LL	parsing	algorithms	use	le]most	deriva@on.	
LR	parsing	algorithms	use	rightmost	deriva@on.	
Will	be	discussed	in	later	lectures.	
                                                                                27	

L03.pdf:A	deriva@on	corresponds	to	building	a	parse	tree	
   Grammar:	               Exercise:	build	the	parse	tree	
   			Exp	–>	Exp	"+"	Exp	  (also	called	deriva@on	tree).	
   			Exp	–>	Exp	"*"	Exp	
   			Exp	–>	INT	
   Example	deriva@on:	
   	
   Exp	=>	
   Exp	"+"	Exp	=>	
   INT	"+"	Exp	=>	
   INT	"+"	Exp	"*"	Exp	=>	
   INT	"+"	INT	"*"	Exp	=>	
   INT	"+"	INT	"*"	INT	
                                                           28	

L03.pdf:A	deriva@on	corresponds	to	building	a	parse	tree	
   Grammar:	               Parse	tree	(deriva@on	tree):	
   			Exp	–>	Exp	"+"	Exp	
   			Exp	–>	Exp	"*"	Exp	
   			Exp	–>	INT	
                                     Exp		
   Example	deriva@on:	
   	                       Exp		     "+"	     Exp		
   Exp	=>	
   Exp	"+"	Exp	=>	         INT	
   INT	"+"	Exp	=>	                      Exp		 "*"	 Exp		
   INT	"+"	Exp	"*"	Exp	=>	
   INT	"+"	INT	"*"	Exp	=>	
                                        INT	        INT	
   INT	"+"	INT	"*"	INT	
                                                         29	

L03.pdf:Ambigui@es	
            30	

L03.pdf:                            Exercise:	
    Can	we	do	another	deriva@on	of	the	same	sentence,	
                 that	gives	a	diﬀerent	parse	tree?	
Grammar:	                                   Parse	tree:	
			Exp	–>	Exp	"+"	Exp	
			Exp	–>	Exp	"*"	Exp	
			Exp	–>	INT	
Another	deriva@on:	
	
Exp	=>	
	
	
	
	
	
                                                         31	

L03.pdf:                            Solu@on:	
    Can	we	do	another	deriva@on	of	the	same	sentence,	
                 that	gives	a	diﬀerent	parse	tree?	
Grammar:	                                     Parse	tree:	
			Exp	–>	Exp	"+"	Exp	
			Exp	–>	Exp	"*"	Exp	
                                                  Exp		
			Exp	–>	INT	
Another	deriva@on:	                         Exp		 "*"	     Exp		
	
Exp	=>	                                                    INT	
Exp	"*"	Exp	=>	                       Exp		 "+"	 Exp		
Exp	"+"	Exp	"*"	Exp	=>	
INT	"+"	Exp	"*"	Exp	=>	               INT	        INT	
INT	"+"	INT	"*"	Exp	=>	
INT	"+"	INT	"*"	INT	
               Which	parse	tree	would	we	prefer?	
                                                                 32	

L03.pdf:       Ambiguous	context-free	grammars	
A	CFG	is	ambiguous	if	a	sentence	in	the	language	can	be	
derived	by	two	(or	more)	diﬀerent	parse	trees.	
	
A	CFG	is	unambiguous	if	each	sentence	in	the	language	can	
be	derived	by	only	one	parse	tree.	
	
(Swedish:	tvetydig,	otvetydig)	
	
Note!	There	can	be	many	diﬀerent	deriva@ons	that	give	the	
same	parse	tree.	
                                                           33	

L03.pdf:    How	can	we	know	if	a	CFG	is	ambiguous?	
If	we	ﬁnd	an	example	of	an	ambiguity,	we	know	the	
grammar	is	ambiguous.	
	
There	are	algorithms	for	deciding	if	a	CFG	belongs	to	
certain	subsets	of	CFGs,	e.g.	LL,	LR,	etc.	(See	later	lectures.)	
These	grammars	are	unambiguous.	
	
But	in	the	general	case,	the	problem	is	undecidable:	it	is	not	
possible	to	construct	a	general	algorithm	that	decides	
ambiguity	for	an	arbitrary	CFG.	
Strategies	for	elimina@ng	ambigui@es,	next	lecture.	
                                                                  34	

L03.pdf:Parsing	
         35	

L03.pdf:                Diﬀerent	parsing	algorithms	
                          Unambiguous	
                           LR	
                            LL	                 Ambiguous	
                      All	context-free	grammars	
LL:	                                       LR:	
Le]-to-right	scan	                         Le]-to-right	scan	
Le]most	deriva@on	                         Rightmost	deriva@on	
Builds	tree	top-down	                      Builds	tree	boRom-up	
Simple	to	understand	                      More	powerful	
                                                                 36	

L03.pdf:    CompoundStmt	
                                  LL	and	LR	parsers:	
           IfStmt	
                                         main	idea	
         Id	         Assign	                                 Id	        Assign	
                                                                         Id	 Id	
...	if			ID		then		ID		=		ID		;		ID	...	            ...	if			ID		then		ID		=		ID		;		ID	...	
     LL(1):	decides	to	build	Assign	a]er	          LR(1):	decides	to	build	Assign	a]er	seeing	
     seeing	the	ﬁrst	token	of	its	subtree.	        the	ﬁrst	token	following	its	subtree.	
     The	tree	is	built	top	down.	                  The	tree	is	built	boRom	up.	
                                  The	token	is	called	lookahead.	
                             LL(k)	and	LR(k)	use	k	lookahead	tokens.		
                                                                                              37	

L03.pdf:                    Recursive-descent	parsing	
   A	way	of	programming	an	LL(1)	parser	by	recursive	method	calls	
Assume	a	BNF	grammar	with	exactly	one	produc@on	rule	for	each	nonterminal.	
(Can	easily	be	generalized	to	EBNF.)	
	
Each	produc@on	rule	RHS	is	either	
1.  a	sequence	of	token/nonterminal	symbols,	or	
2.  a	set	of	nonterminal	symbol	alterna@ves	
	
For	each		nonterminal,	a	method	is	constructed.	The	method	
1.  matches	tokens	and	calls	nonterminal	methods,	or	
2.  calls	one	of	the	nonterminal	methods	–	which	one	depends	on	the	
     lookahead	token.	
	
If	the	lookahead	token	does	not	match,	a	parsing	error	is	reported.	
                                 A	–>	B	|	C	|	D	
                                 B	–>	e	C	f	D	
                                 C	–>	...	
                                 D	–>	...	                                  38	

L03.pdf:Example	Java	implementa@on:	overview	
         statement	–>	assignment	|	compoundStmt	
         assignment–>	ID	ASSIGN	expr	SEMICOLON	
         compoundStmt	–>	LBRACE	statement*	RBRACE	
         ...	
  class	Parser	{	
  		private	int	token;           	//	current	lookahead	token	
  		void	accept(int	t)	{...}     	//	accept	t	and	read	in	next	token		
  		void	error(String	str)	{...} 	//	generate	error	message	
  		void	statement()	{...}	
  		void	assignment	()	{...}	
  		void	compoundStmt	()	{...}	
  		...	
  

  

  

  

  

  

  

  }

                                                                       39	

L03.pdf:Example:	recursive	descent	methods	
         statement	–>	assignment	|	compoundStmt	
         assignment–>	ID	ASSIGN	expr	SEMICOLON	
         compoundStmt	–>	LBRACE	statement*	RBRACE	
class	Parser	{	
		void	statement()	{	
				switch(token)	{	
						case	ID:	assignment();	break;	
						case	LBRACE:	compoundStmt();	break;	
						default:	error("Expec@ng	statement,	found:	"	+	token);	
				}	
		}	
		void	assignment()	{	
				accept(ID);	accept(ASSIGN);	expr();	accept(SEMICOLON);	
		}		
		void	compoundStmt()	{	
				accept(LBRACE);	
				while	(token!=RBRACE)	{	statement();	}	
				accept(RBRACE);	
		}		
		...	
}	                                                            40	

L03.pdf:      Example:	Parser	skeleton	details	
         statement	–>	assignment	|	compoundStmt	
         assignment–>	ID	ASSIGN	expr	SEMICOLON	
         compoundStmt	–>	LBRACE	statement*	RBRACE	
         expr	–>	...	
class	Parser	{	
		ﬁnal	sta@c	int	ID=1,	WHILE=2,	DO=3,	ASSIGN=4,	...;	
		private	int	token;               	//	current	lookahead	token	
		void	accept(int	t)	{             	//	accept	t	and	read	in	next	token	
				if	(token==t)	{	
						token	=	nextToken();	
				}	else	{	
						error("Expected	"	+	t	+	"	,	but	found	"	+	token);	
				}	
		}		
		void	error(String	str)	{...}     	//	generate	error	message	
		private	int	nextToken()	{...}	//	read	next	token	from	scanner	
		void	statement()	...	
		...	
	
}	
                                                                        41	

L03.pdf:        Are	these	grammars	LL(1)?	
 expr	–>	name	params	|	name	   Common	preﬁx	
 expr	–>	expr	"+"	term	        Le]	recursion	
What	would	happen	in	a	recursive-descent	parser?	
            Could	they	be	LL(2)?					LL(k)?	
                                                  42	

L03.pdf:Dealing	with	common	preﬁx	of	limited	length:	
                         Local	lookahead	
       LL(2)	grammar:	
       statement	–>	assignment	|	compoundStmt	|	callStmt	
       assignment–>	ID	ASSIGN	expr	SEMICOLON	
       compoundStmt	–>	LBRACE	statement*	RBRACE	
       callStmt	–>	ID	LPAR	expr	RPAR	SEMICOLON	
   void	statement()	...	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
   	
                                                          43	

L03.pdf:Dealing	with	common	preﬁx	of	limited	length:	
                              Local	lookahead	
            LL(2)	grammar:	
            statement	–>	assignment	|	compoundStmt	|	callStmt	
            assignment–>	ID	ASSIGN	expr	SEMICOLON	
            compoundStmt	–>	LBRACE	statement*	RBRACE	
            callStmt	–>	ID	LPAR	expr	RPAR	SEMICOLON	
   void	statement()	{	
   		switch(token)	{	
   				case	ID:		
   						if	(lookahead(2)	==	ASSIGN)	{	
   								assignment();	
   						}	else	{	
   								callStmt();	
   						}	
   						break;	
   				case	LBRACE:	compoundStmt();	break;	
   				default:	error("Expec@ng	statement,	found:	"	+	token);	
   		}	
   }	
                                                               44	

L03.pdf:  Genera@ng	the	parser:	
                                                   tokens	
Context-free	                   Syntac@c	analyzer	
              Parser	generator	
 grammar
                            (parser)	
                                                   tree	
                                                           45	

L03.pdf:   Beaver:	an	LR-based	parser	generator	
                                             tokens	
 Context-free	
  grammar,	
                 Beaver	     Parser	in	Java	
with	seman@c	
ac@ons	in	Java
                              tree	
                                                     46	

L03.pdf:                  Example	beaver	speciﬁca@on	
        %class	"LangParser";	
        %package	"lang";	
        ...	
        %terminals	LET,	IN,	END,	ASSIGN,	MUL,	ID,	NUMERAL;	
        	
        %goal	program;	//	The	start	symbol	
        	
        //	Context-free	grammar	
        program	=	exp;	
        exp	=	factor	|	exp	MUL	factor;	
        factor	=	let	|	numeral	|	id;	
        let	=	LET	id	ASSIGN	exp	IN	exp	END;	
        numeral	=	NUMERAL;	
        id	=	ID;	
Later	on,	we	will	extend	this	speciﬁca@on	with	seman@c	ac@ons	to	build	the	syntax	tree.	
                                                                                      47	

L03.pdf:Regular	Expressions	vs	Context-Free	Grammars	
                      RE	               CFG	
Typical	         characters	     terminal	symbols		
Alphabet	                             (tokens)	
Language	is	        strings	        sentences	
a	set	of	...	 (char	sequences)	 (token	sequences)	
Used	for...	       tokens	          parse	trees	
Power	            itera@on	          recursion	
Recognizer	          DFA	         DFA	with	stack	
                                                    48	

L03.pdf:    The	Chomsky	hierarchy	of	formal	grammars	
       Grammar	                        Rule	paLerns	           Type	
         regular	             X	–>	aY		or		X	–>	a		or		X	–>	ε	   3	
     context	free	                         X	–>	γ	               2	
  context	sensi@ve	                    α	X	β	–>	α γ β	           1	
        arbitrary	                         γ	–>	δ	               0	
a	–	terminal	symbol	
α, β, γ, δ	–	sequences	of	(terminal	or	nonterminal)	symbols	
	
Type(3)	⊂	Type	(2)	⊂	Type(1)	⊂	Type(0)	
	
Regular	grammars	have	the	same	power	as	regular	expressions	
(tail	recursion	=	itera@on).	
	
Type	2	and	3	are	of	prac@cal	use	in	compiler	construc@on.	
Type	0	and	1	are	only	of	theore@cal	interest.	                       49	

L03.pdf:   Course	overview	
                                                     source	code	(text)	
           Regular	               Lexical	analyzer	
         expressions
                (scanner)	
                                                     tokens	
         Context-free	           Syntac@c	analyzer	
          grammar
                    (parser)	
                                                     AST	(Abstract	syntax	tree)	
          ARribute	
                                 Seman@c	analyzer	
          grammar

What	we	have	covered:	
    	Context-free	grammars,	derivaOons,	parse	trees	
    	Ambiguous	grammars	
    	IntroducOon	to	parsing,	recursive-descent	
	
You	can	now	ﬁnish	assignment	1	
                                                                                 50	

L03.pdf:                        Summary	ques@ons	
•  Construct	a	CFG	for	a	simple	part	of	a	programming	language.	
•  What	is	a	nonterminal	symbol?	A	terminal	symbol?	A	produc@on?	A	start	
   symbol?	A	parse	tree?	
•  What	is	a	le]-hand	side	of	a	produc@on?	A	right-hand	side?	
•  Given	a	grammar	G,	what	is	meant	by	the	language	L(G)?	
•  What	is	a	deriva@on	step?	A	deriva@on?	A	le]most	deriva@on?	A	righmost	
   deriva@on?	
•  How	does	a	deriva@on	correspond	to	a	parse	tree?	
•  What	does	it	mean	for	a	grammar	to	be	ambiguous?	Unambiguous?	
•  Give	an	example	an	ambiguous	CFG.	
•  What	is	the	diﬀerence	between	an	LL	and	an	LR	parser?	
•  What	is	the	diﬀerence	between	LL(1)	and	LL(2)?	Or	between	LR(1)	and	LR(2)?	
•  Construct	a	recursive	descent	parser	for	a	simple	language.	
•  Give	typical	examples	of	grammars	that	cannot	be	handled	by	a	recursive-
   descent	parser.	
•  Explain	why	context-free	grammars	are	more	powerful	than	regular	
   expressions.	
•  In	what	sense	are	context-free	grammars	"context-free"?	
                                                                             51	

L04.pdf:        EDAN65:	Compilers,	Lecture	04	
      Grammar	transforma=ons:	
Elimina=ng	ambigui=es,	adap=ng	to	LL	parsing	
                Görel	Hedin	
               Revised:	2016-09-05	

L04.pdf:     This	lecture	
                                                           runtime system	
                                  source	code	(text)	
  Regular	      Lexical	analyzer	                             activation
                                                                            stack	
expressions
       (scanner)	                                   records	
                                  tokens	
Context-free	  Syntac=c	analyzer	
                                                                           garbage
 grammar
           (parser)	
                                                                           collection	
                                  AST	(Abstract	syntax	tree)	
 ARribute	                                                                  heap	
               Seman=c	analyzer	
 grammar
                                                       objects	
                                  ARributed	AST	
                 Intermediate	
                                                              Interpreter

                code	generator	
                                  intermediate	code	                         code
                                                                 Virtual	     and
                   Op=mizer	                                    machine
     data	
                                  intermediate	code	
                  Target	code	
                                                               machine
                   generator	
                                    target	code	
                                                                                   2	

L04.pdf:          Space	of	context-free	grammars	
                        Unambiguous	
                         LR	
                          LL	                Ambiguous	
                    All	context-free	grammars	
LL:	                                     LR:	
Builds	tree	top-down	                    Builds	tree	boRom-up	
Simple	to	understand	                    More	powerful	
                                                               3	

L04.pdf:Ambiguous	grammars	
                    4	

L04.pdf:         Recall:	the	deﬁni=on	of	ambiguity	
Grammar:	                        A	CFG	is	ambiguous	if	there	is	a	sentence	
			Exp	->	Exp	"+"	Exp	           in	the	language	that	can	be	derived	by	
			Exp	->	Exp	"*"	Exp	           two	(or	more)	diﬀerent	parse	trees.	
			Exp	->	INT	
             Exp		                                Exp		
     Exp		   "+"	     Exp		                 Exp		 "*"	   Exp		
     INT	                                                INT	
                Exp		 "*"	 Exp		      Exp		 "+"	 Exp		
                INT	        INT	      INT	        INT	
                                                                            5	

L04.pdf:       Strategies	for	dealing	with	ambigui=es	
First,	decide	which	parse	tree	is	the	desired	one.	
	
Eliminate	the	ambiguity:	
Create	an	equivalent	unambiguous	grammar.	
Usually	possible,	but	there	exists	grammars	for	which	it	cannot	be	done.		
Unambiguous:	Only	one	parse	tree	can	be	derived	for	any	string.	
However,	the	parse	tree	will	be	diﬀerent	from	the	original	desired	one.	
	
Alterna=vely,	use	extra	rules:	
Use	the	ambiguous	grammar.	
Add	priority	and	associa=vity	rules	to	instruct	the	parser	to	select	the	
desired	parse	tree.	
Works	for	some	ambigui=es.	
Supported	by	some	parser	generators.	
                                                                           6	

L04.pdf:       Elimina=ng	ambiguity	
               Unambiguous	
                                  Ambiguous	
Goal:	transform	an	ambiguous	grammar	to	an	
equivalent	unambiguous	grammar.	
                                             7	

L04.pdf:                          Equivalent	grammars	
Two	grammars,	G1	and	G2,	are	equivalent	if	they	generate	
the	same	language.	
	
I.e.,	a	sentence	can	be	derived	from	one	of	the	grammars,	
iﬀ	it	can	be	derived	also	from	the	other	grammar:	
	
																						L(G1)	=	L(G2)	
	
                                                           8	

L04.pdf:     Common	kinds	of	ambigui=es	
•  Operators	with	diﬀerent	priori=es:	
   					a	+	b	*	c	==	d,	...	
•  Associa=vity	of	operators	of	the	same	priority:	
   					a	+	b	–	c	+	d,	...	
•  Dangling	else:	
   					if	(a)	
   					if	(b)	c	=	d;	
   					else	e	=	f;	
                                                    9	

L04.pdf:   Example	ambiguity:	                               			Exp	->	Exp	"+"	Exp	
                                                     			Exp	->	Exp	"*"	Exp	
Priority	(also	called	precedence)	                   			Exp	->	INT	
                Two	parse	trees	for	INT	"+"	INT	"*"	INT	
                 Exp		                                        Exp		
         Exp		   "+"	    Exp		                          Exp		 "*"	    Exp		
         INT	                                                          INT	
                  Exp		 "*"	 Exp		               Exp		 "+"	 Exp		
                   INT	         INT	             INT	         INT	
          prio("*")	>	prio("+")	                      prio("+")	>	prio("*")	
        (according	to	tradi=on)	             (would	be	unexpected	and	confusing)	
                                                                                  10	

L04.pdf:Example	ambiguity:	                               			Exp	->	Exp	"+"	Exp	
                                                  			Exp	->	Exp	"-"	Exp	
         Associa7vity	                            			Exp	->	Exp	"**"	Exp	
                                                  			Exp	->	INT	
              For	operators	with	the	same	priority,	
              how	do	several	in	a	sequence	associate?	
            Exp		                                         Exp		
      Exp		 "+"	   Exp		                         Exp		    "**"	   Exp		
                    INT	                         INT	
Exp		 "-"	 Exp		                                            Exp		 "**"	 Exp		
INT	        INT	                                            INT	         INT	
       Le<-associa7ve	                               Right-associa7ve	
 (usual	for	most	operators)	                (usual	for	the	power	operator)	
                                                                              11	

L04.pdf:Example	ambiguity:	                               			Exp	->	Exp	"<"	Exp	
                                                  			Exp	->	INT	
    Non-associa7vity	
        For	some	operators,	it	does	not	make	sense	to	have	
        several	in	a	sequence	at	all.	They	are	non-associa7ve.	
                                                   Exp		
              Exp		
                                           Exp		   "<"	     Exp		
        Exp		 "<"	     Exp		
                                           INT	
                        INT	                         Exp		 "<"	 Exp		
  Exp		 "<"	 Exp		
                                                     INT	         INT	
  INT	        INT	
                     We	would	like	to	forbid	both	trees.	
              I.e.,	rule	out	the	sentence	from	the	langauge.	
                                                                         12	

L04.pdf:       Disambigua=ng	expression	grammars	
How	can	we	change	the	grammar	so	that	only	the	desired	trees	can	be	
derived?	
	
Idea:	Restrict	certain	subtrees	by	introducing	new	nonterminals.	
Priority:	Introduce	a	new	nonterminal	for	each	priority	level:	
Term,	Factor,	Primary,	...	
	
Lek	associa=vity:	Restrict	the	right	operand	so	it	only	can	contain	
expressions	of	higher	priority	
	
Right	associa=vity:	Restrict	the	lek	operand	...	
	
Non-associa=vity:	Restrict	both	operands	
                                                                     13	

L04.pdf:                       Exercise	
Ambiguous	grammar:	      Equivalent	unambiguous	grammar:	
	                        	
Expr	->	Expr	"+"	Expr	   	
Expr	->	Expr	"*"	Expr	   	
Expr	->	INT	             	
Expr	->	"("	Expr	")"	    	
	                        	
                         	
                         	
                                                          14	

L04.pdf:                                    Solu=on	
                                                You	will	do	this	in	Assignment	2!	
  Ambiguous	grammar:	                     Equivalent	unambiguous	grammar:	
  	                                       	
  Expr	->	Expr	"+"	Expr	                  Expr	->	Expr	"+"	Term	
  Expr	->	Expr	"*"	Expr	                  Expr	->	Term	
  Expr	->	INT	                            Term	->	Term	"*"	Factor	
  Expr	->	"("	Expr	")"	                   Term	->	Factor	
  	                                       Factor	->	INT	
                                          Factor	->	"("	Expr	")"	
                                          	
Here,	we	introduce	a	new	nonterminal,	Term,	that	is	more	restricted	than	Expr.	
That	is,	from	Term,	we	can	not	derive	any	new	addi=ons.	
	
For	the	addi=on	produc=on,	we	use	Term	as	the	right	operand,	to	make	sure	no	new	
addi=ons	will	appear	to	the	right.	This	gives	lek-associa=vity.	
	
For	the	mul=plica=on	produc=on,	we	use	Term,	and	the	even	more	restricted	
nonterminal	Factor	to	make	sure	no	addi=ons	can	appear	as	children	(without	using	
parentheses).	This	gives	mul=plica=on	higher	priority	than	addi=on.		
                                                                                   15	

L04.pdf:Real-world	example:	The	Java	expression	grammar	
  Expression	->	LambdaExpression	|	AssignmentExpression	
  AssignmentExpression	->	Condi=onalExpression	|	Assignment	
  Condi=onalExpression	->	...	
  	
  Addi=veExpression	->	
  				Mul=plica=veExpression	
  		|	Addi=veExpression	+	Mul=plica=veExpression	
  		|	Addi=veExpression	–	Mul=plica=veExpression	
  	
  Mul=plica=veExpression	->	
  				UnaryExpression	
  		|	Mul=plica=veExpression	*	UnaryExpression	
  		|	...	
  	
  UnaryExpression	->	...	
  ...	
  Primary	->	PrimaryNoNewArray	|	ArrayCrea=onExpression	
  PrimaryNoNewArray	->	Literal	|	this	|	(	Expression	)	|	FieldAccess	...	
       More	than	15	priority	levels.	
       See	the	Java	Language	Speciﬁca=on,	Java	SE	8,	Chapter	19,	Syntax	
       hRp://docs.oracle.com/javase/specs/jls/se8/html/jls-19.html	       16	

L04.pdf:                               The	"dangling	else"	problem	
                 S	->	"if"	"("	E	")"	S	["else"	S]	
                 S	->	ID	"="	E	";"	
                 E	->	ID	
                 Construct	a	parse	 if	(a)	
                 tree	for:	               if	(b)	c	=	d;	
                                          else	e	=	f;	
 The	desired	tree	             S	           Two	possible	parse	trees!	                  S	
                                                   The	grammar	is	
                                                     ambiguous!	
if	(a)	                                                                                            if	(a)	
		if	(b)	                                                                                          		if	(b)	
				c	=	d;	                    S	                                              S	                  				c	=	d;	
		else	                                                                                            else	
				e	=	f;	                                                                                        		e	=	f;	
   if		(	a	)		if		(	b	)		c		=		d;		else		e		=		f;	          if		(	a	)		if		(	b	)		c		=		d;		else		e		=		f;	
                                                                                                               17	

L04.pdf:          Solu=ons	to	the	"dangling	else"	problem	
  Rewrite	to	equivalent	unambiguous	grammar	
  -		possible,	but	results	in	more	complex	grammar	
  	
  	
  Use	the	ambiguous	grammar	
  -  use	"rule	priority",	the	parser	can	select	the	correct	rule.	
  -  works	for	the	dangling	else	problem,	but	not	for	ambiguous	grammars	in	general	
  -  not	all	parser	generators	support	it	well	
  	
  	
  Change	the	language	
  -  e.g.,	add	a	keyword	"ﬁ"	that	closes	the	"if"-statement	
  -  restrict	the	"then"	part	to	be	a	block:	"{	...	}".	
  -  only	an	op=on	if	you	are	designing	the	language	yourself.	
The	Java	Language	Speciﬁca=on	rewrites	the	grammar	to	be	unambiguous.	
                                                                                     18	

L04.pdf:                   Finding	ambigui=es	in	prac=ce	
You	try	to	run	a	CFG	through	an	LL	or	LR	parser	generator	
-  If	it	is	accepted	by	the	parser	generator,	the	grammar	is	unambiguous	
-  If	not,	the	grammar	could	be	ambiguous,	or	unambiguous,	but	outside	of	the	
   parser	generator	grammar	class.	In	any	case,	you	need	to	analyze	that	par=cular	
   problem.	This	can	be	quite	tricky,	especially	for	large	grammars.	Perhaps	you	can	
   ﬁnd	an	ambiguity,	or	some	other	known	LL/LR	diﬃculty.		
                                                                                      19	

L04.pdf:EBNF,	BNF,	Canonical	form	
                           20	

L04.pdf:       Recall:	diﬀerent	nota=ons	for	CFGs	
A	->	B	d	e	C	f	                Canonical	form	
A	->	g	A	                      •  sequence	of	terminals	and	nonterminals	
                               BNF	(Backus-Naur	Form)	
C	->	D	a	b	|	b	E	F	|	a	C		     •  alterna=ve	produc=ons	(	...	|	...	|	...	)	
G	->	H*	i	|	(d	E)+	F	|	[d	C]		 EBNF	(Extended	Backus-Naur	Form)	
                               •  repe77on	(*	and	+)	
                               •  op7onals	[...]	
                               •  parentheses	(...)	
                                                                             21	

L04.pdf:    Wri=ng	the	grammar	in	diﬀerent	nota=ons	
                         Equivalent	BNF	(Backus-Naur	Form):	
                         	
                         	
Canonical	form:	         	
	                        	
Expr	->	Expr	"+"	Term	   	
Expr	->	Term	            Use	alterna7ves	instead	of	several	
Term	->	Term	"*"	Factor	 produc=ons	per	nonterminal.	
Term	->	Factor	
Factor	->	INT	
Factor	->	"("	Expr	")"	  Equivalent	EBNF	(Extended	BNF):	
	                        	
                         	
                         	
                         	
                         	
                         Use	repe77on	instead	of	recursion,	
                         where	possible.	
                                                             22	

L04.pdf:    Wri=ng	the	grammar	in	diﬀerent	nota=ons	
                         Equivalent	BNF	(Backus-Naur	Form):	
                         	
                         Expr	->	Expr	"+"	Term	|	Term	
Canonical	form:	         Term	->	Term	"*"	Factor	|	Factor	
	                        Factor	->	INT	|	"("	Expr	")"	
Expr	->	Expr	"+"	Term	   	
Expr	->	Term	            Use	alterna7ves	instead	of	several	
Term	->	Term	"*"	Factor	 produc=ons	per	nonterminal.	
Term	->	Factor	
Factor	->	INT	
Factor	->	"("	Expr	")"	  Equivalent	EBNF	(Extended	BNF):	
	                        	
                         Expr	->	Term	("+"	Term)*	
                         Term	->	Factor	("*"	Factor)*	
                         Factor	->	INT	|	"("	Expr	")"	
                         	
                         Use	repe77on	instead	of	recursion,	
                         where	possible.	
                                                             23	

L04.pdf:          Transla=ng	EBNF	to	Canonical	form	
EBNF	                          Equivalent	canonical	form	
Top	level	repe==on	             

X	->	γ1 γ2* γ3	                 

                                

Top	level	alterna=ve	           

X	->	γ1 | γ2	                   

Top	level	parentheses	          

X	->	γ1 (...) γ2	               

Where	γk	is	a	sequence	of	terminals	and	nonterminals	
                                                          24	

L04.pdf:          Transla=ng	EBNF	to	Canonical	form	
EBNF	                     Equivalent	canonical	form	
Top	level	repe==on	        X	->	γ1	N	γ3	
X	->	γ1 γ2* γ3	            N	->	ε	
                           N	->	γ2	N	
Top	level	alterna=ve	      X	->	γ1	
X	->	γ1 | γ2	              X	->	γ2	
Top	level	parentheses	     X	->	γ1	N	γ2	
X	->	γ1 (...) γ2	          N	->	...	
                                                     25	

L04.pdf:                          Exercise:	
        Translate	from	EBNF	to	Canonical	form	
EBNF:	                      Equivalent	Canonical	Form	
	                           	
Expr	->	Term	("+"	Term)*	   	
                            	
                            	
                            	
                                                       26	

L04.pdf:                          Solu=on:	
        Translate	from	EBNF	to	Canonical	form	
EBNF:	                      Equivalent	Canonical	Form	
	                           	
Expr	->	Term	("+"	Term)*	   Expr	->	Term	N	
                            N	->	ε	
                            N	->	"+"	Term	N		
                                                       27	

L04.pdf:       Can	we	prove	that	these	are	equivalent?	
                            Equivalent	Canonical	Form	
                            	
                   trivial	 Expr	->	Term	N	
                            N	->	ε	
                            N	->	"+"	Term	N		
                            	
EBNF:	
	
Expr	->	Term	("+"	Term)*	
                            Alterna=ve	Equivalent	Canonical	Form	
                            	
              non-trivial	  Expr	->	Expr	"+"	Term	
                            Expr	->	Term	
                                                                  28	

L04.pdf:    Example	proof	
1.	We	start	with	this:	   2.	We	can	move	the	repe==on:	
Expr	->	Term	("+"	Term)*	 Expr	->	(Term	"+")*	Term	
                          3.	Eliminate	the	repe==on:	
                          Expr	->	N	Term	
                          N	->	ε	
                          N	->	N	Term	"+"	
                          4.	Replace	N	Term	by	Expr	in	the	
                          third	produc=on:	
                          Expr	->	N	Term	
                          N	->	ε	
                          N	->	Expr	"+"	
We	would	like	this:	      5.	Eliminate	N:	
Expr	->	Expr	"+"	Term	    Expr	->	Expr	"+"	Term	
Expr	->	Term	             Expr	->	Term	
                          Done!	
                                                            29	

L04.pdf:       Equivalence	of	grammars	
  Given	two	context-free	grammars,	G1	and	G2.	
              Are	they	equivalent?	
	
               I.e.,	is	L(G1)	=	L(G2)?	
              Undecidable	problem:	
   a	general	algorithm	cannot	be	constructed.	
                           	
  We	need	to	rely	on	our	ingenuity	to	ﬁnd	out.	
              (In	the	general	case.)	
                                                30	

L04.pdf:Adap=ng	grammars	to	LL	parsing	
                                31	

L04.pdf:        Create	equivalent	LL	grammar	
                       Unambiguous	
                         LL	               Ambiguous	
Typically,	need	to	eliminate	Lek	Recursion	and	Common	Preﬁxes.	
(But	this	may	not	be	enough.)	
The	parse	trees	will	be	diﬀerent	from	the	original	desired	ones.	
Try	to	build	the	desired	ASTs	anyway.	
EBNF	helps:	rela=vely	easy	to	build	the	desired	AST.	
                                                                  32	

L04.pdf:                           Recall:	LL(1)	parsing	
 Assign	
                                              Assign	->	ID	=	Exp	;	
                                              Exp	->	Name	Params	|	Name	|	...	
         Exp	                                 Name	->	ID	(	.	ID	)*	
          ?	     What	node	should	be	built?	
                                              Common	preﬁx!	
  ID		=		ID.ID;		ID		=		ID.ID	(	ID	);	        Cannot	be	handled	by	LL(1).	
                                              This	grammar	is	not	even	LL(k).	
LL(1):	decides	to	build	the	node	aker	seeing	
the	ﬁrst	token	of	its	subtree.	
The	tree	is	built	top	down.	
                                                                               33	

L04.pdf:            Elimina=ng	the	common	preﬁx	
Rewrite	to	an	equivalent	grammar	without	the	common	preﬁx		
  Exp	->	Name	Params	|	Name	
  With	common	preﬁx	-	not	LL(1)	
                                                            34	

L04.pdf:            Elimina=ng	the	common	preﬁx	
Rewrite	to	an	equivalent	grammar	without	the	common	preﬁx		
  Exp	->	Name	Params	|	Name	                   Exp	->	Name	OptParams	
                                               OptParams	->	Params	|	ε		
  With	common	preﬁx	-	not	LL(1)	              Without	common	preﬁx	-	LL(1)	
                 Elimina=ng	a	common	preﬁx	this	way	is	
                          called	le<	factoring.	
                                                                            35	

L04.pdf:                           Exercise	
If	two	produc=ons	of	the	same	nonterminal	can	derive	a	sentence	
      star=ng	in	the	same	way,	they	share	a	common	preﬁx.	
       A	->	s	B	
       A	->	s	C	
       B	->	t	
       C	->	u	
       A	->	B	s	
       A	->	B	t	
       B	->	u	v	
       A	->	s	B	
       B	->	s	C	
       B	->	t	C	
       C	->	u	
      Which	nonterminals	have	common	preﬁx	produc=ons?	
    What	is	the	common	preﬁx?	Is	the	grammar	LL(1),	LL(2),	...?	
                                                                 36	

L04.pdf:                               Solu=on	
If	two	produc=ons	of	a	nonterminal	can	derive	a	sentence	
   star=ng	in	the	same	way,	they	share	a	common	preﬁx.	
   A	->	s	B	 A	has	two	rules	that	can	derive	the	preﬁx	s	
   A	->	s	C	 The	grammar	is	LL(2)	
   B	->	t	
   C	->	u	
   A	->	B	s	 A	has	two	rules	that	can	derive	the	preﬁx	u	v	
   A	->	B	t	 The	grammar	is	LL(3)	
   B	->	u	v	
   A	->	s	B	  This	is	not	a	common	preﬁx	problem.	The	two	
   B	->	s	C	  rules	that	start	the	same	cannot	be	derived	from	
   B	->	t	C	  the	same	nonterminal.	
   C	->	u	    The	grammar	is	LL(1)	
  Which	nonterminals	have	common	preﬁx	produc=ons?	
What	is	the	common	preﬁx?	Is	the	grammar	LL(1),	LL(2),	...?	
                                                                37	

L04.pdf:       The	common	preﬁx	can	be	indirect	
A	->	B	    A	has	two	rules	that	can	derive	the	preﬁx	t	
A	->	C	    The	grammar	is	LL(2)	
A	->	D	
B	->	t	s	
C	->	t	v	
D	->	x	
A	->	B	s	  A	has	two	rules	that	can	derive	the	preﬁx	v	u*	
A	->	B	t	  So,	the	preﬁx	can	become	arbitrarily	long.	
B	->	B	u	  The	grammar	is	not	LL(k),	no	maRer	what	k	we	use.	
B	->	v	    We	need	to	rewrite	the	grammar,	or	use	another	parsing	method	
           than	LL.	(For	example,	LR	has	no	problem	with	common	preﬁxes)	
Which	nonterminals	have	common	preﬁx	produc=ons?	
               What	is	the	common	preﬁx?	
             Is	the	grammar	LL(1),	LL(2),	...?	
                                                                          38	

L04.pdf:           Elimina=ng	the	common	preﬁx	
Rewrite	to	an	equivalent	grammar	without	the	common	preﬁx		
A	->	B	
A	->	C	
B	->	t	s	
B	->	x	D	
B	->	y	
C	->	t	v	
D	->	B	C	
	
 Indirect	
common	
  preﬁx	
                                                            39	

L04.pdf:             Elimina=ng	the	common	preﬁx	
Rewrite	to	an	equivalent	grammar	without	the	common	preﬁx		
                                                                 A	->	t	s	
A	->	B	            First,	make	the	common	preﬁx	directly	
                                                                 A	->	x	D	
A	->	C	            visible:	
                                                                 A	->	y	
B	->	t	s	          	
                                                                 B	->	t	s	
B	->	x	D	          Subs=tute	all	B	right-hand	sides	into	the	
                                                                 B	->	x	D	
B	->	y	            A	->	B	rule	
                                                                 B	->	y	
C	->	t	v	          	
                                                                 A	->	t	v	
D	->	B	C	          We	can't	remove	the	B	rules	since	B	is	
                                                                 C	->	t	v	
	                  used	in	other	places.	
                                                                 D	->	B	C	
                   	
                                                                 	
 Indirect	         Similarly	for	the	A	->	C	rule	
common	                                                             Direct	
  preﬁx	                                                          common	
                                                                    preﬁx	
           Then,	eliminate	the	direct	common	preﬁx,	as	previously.	
                                                                            40	

L04.pdf:                            Lek	recursion	
assign	
                                                  assign	->	ID	"="	expr	";"	
                                                  expr	->	expr	"+"	term	|	term	
      expr	                                       term	->	ID	
        ?	    What	node	should	be	built?	
ID		=		ID		+		ID		+		ID		;	
                            The	grammar	is	le<	recursive.	
                            The	grammar	is	not	LL(k).	
                            An	LL	parser	would	go	into	endless	recursion.	
                            	
                            (LR	parsers	can	handle	lek	recursion.)	
                                                                                41	

L04.pdf:         Dealing	with	lek	recursion	in	LL	parsers	
                   Method	1:	Eliminate	the	lek	recursion	
                                 (A	bit	cumbersome)		
 Lek-recursive	grammar.	Not	                E	->	E	"+"	T	
 LL(k)	                                     E	->	T	
                                            T	->	ID	
 Rewrite	to	right-recursion!	But	           E	->	T	"+"	E	
 there	is	now	a	common	                     E	->	T	
 preﬁx!	S=ll	not	LL(k).	                    T	->	ID	
 Eliminate	the	common	preﬁx.	               E	->	T	E'	
 The	grammar	is	now	LL(1)	                  E'	->	"+"	E	
                                            E'	->	ε	
                                            T	->	ID	
With	a	liRle	work,	it	is	possible	to	write	code	that	builds	a	lek-recursive	AST,	
even	if	the	parse	is	right-recursive.	
                                                                                  42	

L04.pdf:       Dealing	with	lek	recursion	in	LL	parsers	
                   Method	2:	Rewrite	to	EBNF	(Easy!)	
Lek-recursive	grammar.	Not	              E	->	E	"+"	T	
LL(k)	                                   E	->	T	
                                         T	->	ID	
Rewrite	to	EBNF!	                        E	->	T	(	"+"	T	)*	
                                         T	->	ID	
A	lek-recursive	AST	can	easily	be	built	during	the	itera=on.	
                                                              43	

L04.pdf:Advice	when	using	an	LL-based	parser	generator	
If	the	LL	parser	generator	does	not	accept	your	grammar,	the	reason	might	be	
	
•  Ambiguity	–	usually	eliminate	it.	In	some	cases,	rule	priority	can	be	used.	
•  Lek	recursion	–	can	you	use	EBNF	instead?	Otherwise,	eliminate.	
•  Common	preﬁx	–	is	it	limited?	You	can	then	use	a	local	lookahead,	for	example	
    2.	Otherwise,	factor	out	the	common	preﬁx.	
	
You	might	be	able	to	solve	the	problem,	but	the	grammar	might	become	large	
and	less	readable.	
                                                                                  44	

L04.pdf:                Diﬀerent	parsing	algorithms	
                          Unambiguous	
                           LR	
                            LL	                 Ambiguous	
                      All	context-free	grammars	
LL:	                                       LR:	
Lek-to-right	scan	                         Lek-to-right	scan	
Lekmost	deriva=on	                         Rightmost	deriva=on	
Builds	tree	top-down	                      Builds	tree	boRom-up	
Simple	to	understand	                      More	powerful	
                                                                 45	

L04.pdf:                       LL(k)	vs	LR(k)	
                            LL(k)	                            LR(k)	
     Parses	input	                        Lek-to-right	
      Deriva=on	         Lekmost	                          Rightmost	
      Lookahead	                           k	symbols	
    Build	the	tree	      top	down	                         boRom	up	
      Select	rule	  aker	seeing	its	ﬁrst	      aker	seeing	all	its	tokens,	and	an	
                          k	tokens	                  addi=onal	k	tokens	
    Lek	recursion	    Cannot	handle	                      Can	handle!	
 Unlimited	common	    Cannot	handle	                      Can	handle!	
        preﬁx	
  Can	resolve	some	    Dangling	else	            Dangling	else,	associa=vity,	
ambigui=es	through	                                         priority	
     rule	priority	
   Error	recovery	    Trial-and-error	              Good	algorithms	exist	
Implement	by	hand?	       Possible.	                  Too	complicated.	
                    But	beRer	to	use	a	                 Use	a	generator.	
                        generator.	
                                                                                 46	

L04.pdf:                       Summary	ques=ons	
•  What	does	it	mean	for	a	grammar	to	be	ambiguous?	
•  What	does	it	mean	for	two	grammars	to	be	equivalent?	
•  Exemplify	some	common	kinds	of	ambigui=es.	
•  Exemplify	how	expression	grammars	with	can	be	disambiguated.	
•  What	is	the	"dangling	else"-problem,	and	how	can	it	be	solved?	
•  When	should	we	use	canonical	form,	and	when	BNF	or	EBNF?	
•  Translate	an	example	EBNF	grammar	to	canonical	form.	
•  Can	we	write	an	algorithm	to	check	if	two	grammars	are	equivalent?	
•  What	is	a	”common	preﬁx”?	
•  Exemplify	how	a	common	preﬁx	can	be	eliminated.	
•  What	is	”lek	factoring”?	
•  What	is	”lek	recursion”?	
•  Exemplify	how	lek	recursion	can	be	eliminated	in	a	grammar	on	canonical	
   form.	
•  Exemplify	how	lek	recursion	can	be	eliminated	using	EBNF.	
•  Can	LL(k)	parsing	algorithms	handle	common	preﬁxes	and	lek	recursion?	
•  Can	LR(k)	parsing	algorithms	handle	common	preﬁxes	and	lek	recursion?	
                                                                            47	

L05A.pdf:    EDAN65:	Compilers,	Lecture	05	A	
           LL	parsing	
Nullable,	FIRST,	and	FOLLOW	
             Görel	Hedin	
            Revised:	2016-09-12	

L05A.pdf:                                                          runtime system	
                                 source	code	(text)	
  Regular	     Lexical	analyzer	                             activation
                                                                           stack	
expressions
      (scanner)	                                   records	
                                 tokens	
Context-free	 SyntacLc	analyzer	 LL	parsing	
                                                                          garbage
 grammar
          (parser)	     Nullable,	FIRST,	FOLLOW	
                                                                          collection	
                                 AST	(Abstract	syntax	tree)	
 ASribute	                                                                 heap	
              SemanLc	analyzer	
 grammar
                                                      objects	
                                 ASributed	AST	
                Intermediate	
                                                             Interpreter

               code	generator	
                                 intermediate	code	                         code
                                                                Virtual	     and
                  OpLmizer	                                    machine
     data	
                                 intermediate	code	
                 Target	code	
                                                              machine
                  generator	
                                    target	code	
                                                                                  2	

L05A.pdf:   Algorithm	for	construcLng	an	LL(1)	parser	
   Fairly	simple.	
   	
   The	non-trivial	part:	how	to	select	the	correct	producLon	p	
   for	X,	based	on	the	lookahead	token.		
               X	                      p1:	X	->	...	
                                       p2:	X	->	...	
                                       Which	tokens	can	occur	in	the	FIRST	posiLon?	
                                       	
                                       Can	one	of	the	producLons	derive	the	empty	
...				t1					...					tn		tn+1				...	 string?	I.e.,	is	it	"NULLABLE"?	
                                       If	so,	which	tokens	can	occur	in	the	FOLLOW	
                                       posiLon?	
     FIRST	             FOLLOW	
                                                                                     3	

L05A.pdf:    Steps	in	construcLng	an	LL(1)	parser	
1.  Write	the	grammar	on	canonical	form	
2.  Analyze	the	grammar	to	construct	a	table.	
    The	table	shows	what	producLon	to	select,	given	the	
    current	lookahead	token.	
3.  Conﬂicts	in	the	table?	The	grammar	is	not	LL(1).	
4.  No	conﬂicts?	Straight	forward	implementaLon	using	
    table-driven	parser	or	recursive	descent.	
              t1	       t2	       t3	      t4	
    X1	       p1	       p2	
    X2	                 p3	       p3	      p4	
                                                         4	

L05A.pdf:                                      Example:	
                 Construct	the	LL(1)	table	for	this	grammar:	
                       p1:	statement	->	assignment	
                       p2:	statement	->	compoundStmt	
                       p3:	assignment	->	ID	"="	expr	";"	
                       p4:	compoundStmt	->	"{"	statements	"}"	
                       p5:	statements	->	statement	statements	
                       p6:	statements	->	ε	
                                      ID		     "="	    ";"	    "{"	    "}"	
               statement	
               assignment	
               compoundStmt		
               statements		
For	each	producLon	p:	X	->	γ,	we	are	interested	in:	
		FIRST(γ)	–	the	tokens	that	occur	ﬁrst	in	a	sentence	derived	from	γ.	
		NULLABLE(γ)	–	is	it	possible	to	derive	ε	from	γ?	And	if	so:	
		FOLLOW(X)	–	the	tokens	that	can	occur	immediately	aier	an	X-sentence.	
                                                                            5	

L05A.pdf:                                      Example:	
                Construct	the	LL(1)	table	for	this	grammar:	
                      p1:	statement	->	assignment	
                      p2:	statement	->	compoundStmt	
                      p3:	assignment	->	ID	"="	expr	";"	
                      p4:	compoundStmt	->	"{"	statements	"}"	
                      p5:	statements	->	statement	statements	
                      p6:	statements	->	ε	
                                      ID		   "="	     ";"	   "{"	   "}"	
             statement	               p1	                    p2	
             assignment	              p3	
             compoundStmt		                                  p4	
             statements		             p5	                    p5	     p6	
To	construct	the	table,	look	at	each	producLon	p:	X	->	γ.	
Compute	the	token	set	FIRST(γ).	Add	p	to	each	corresponding	entry	for	X.	
Then,	check	if	γ	is	NULLABLE.	If	so,	compute	the	token	set	FOLLOW(X),	
and	add	p	to	each	corresponding	entry	for	X.	
                                                                          6	

L05A.pdf:                         Example:	
               Dealing	with	End	of	File:	
         

         p1:	varDecl	->	type	ID	optInit	
         p2:	type	->	"integer"	
         p3:	type	->	"boolean"	
         p4:	optInit	->	"="	INT	
         p5:	optInit	->	ε

         ID	    integer	     boolean	    "="	 ";"	 INT	
varDecl	
type	
optInit	
                                                        7	

L05A.pdf:                         Example:	
                Dealing	with	End	of	File:	
         p0:	S	->	varDecl	$	
         p1:	varDecl	->	type	ID	optInit	
         p2:	type	->	"integer"	
         p3:	type	->	"boolean"	
         p4:	optInit	->	"="	INT	
         p5:	optInit	->	ε

         ID	    integer	     boolean	    "="	 ";"	 INT	 $	
S	
varDecl	
type	
optInit	
                                                           8	

L05A.pdf:                          Example:	
                 Dealing	with	End	of	File:	
          p0:	S	->	varDecl	$	
          p1:	varDecl	->	type	ID	optInit	
          p2:	type	->	"integer"	
          p3:	type	->	"boolean"	
          p4:	optInit	->	"="	INT	
          p5:	optInit	->	ε

         ID	     integer	     boolean	    "="	 ";"	 INT	 $	
S	                  p0	         p0	
varDecl	            p1	         p1	
type	               p2	         p3	
optInit	                                  p4	            p5	
                                                             9	

L05A.pdf:       Example:	
   Ambiguous	grammar:	
     p1:	E	->	E	"+"	E	
     p2:	E	->	ID	
     p3:	E	->	INT	
         "+"	         ID	 INT	
E	
                               10	

L05A.pdf:             Example:	
       Ambiguous	grammar:	
           p1:	E	->	E	"+"	E	
           p2:	E	->	ID	
           p3:	E	->	INT	
               "+"	       ID	       INT	
E	                      p1,	p2	    p1,	p3	
         Collision	in	a	table	entry!	
         The	grammar	is	not	LL(1)	
                      	
An	ambiguous	grammar	is	not	even	LL(k)	–	
   adding	more	lookahead	does	not	help.	
                                           11	

L05A.pdf:             Example:	
Unambiguous,	but	lei-recursive	grammar:	
           p1:	E	->	E	"*"	F	
           p2:	E	->	F	
           p3:	F	->	ID	
           p4:	F	->	INT	
              "*"	       ID	 INT	
    E	
    F	
                                         12	

L05A.pdf:                  Example:	
Unambiguous,	but	lei-recursive	grammar:	
                p1:	E	->	E	"*"	F	
                p2:	E	->	F	
                p3:	F	->	ID	
                p4:	F	->	INT	
                    "*"	       ID	       INT	
     E	                       p1,p2	    p1,p2	
     F	                        p3	        p4	
              Collision	in	a	table	entry!	
              The	grammar	is	not	LL(1)	
                            	
  A	grammar	with	lei-recursion	is	not	even	LL(k)	–	
        adding	more	lookahead	does	not	help.	
                                                    13	

L05A.pdf:            Example:	
   Grammar	with	common	preﬁx:	
         p1:	E	->	F	"*"	E	
         p2:	E	->	F	
         p3:	F	->	ID	
         p4:	F	->	INT	
         p5:	F	->	"("	E	")"	
       "*"	     ID	       INT	 "("	 ")"	
E	
F	
                                         14	

L05A.pdf:                   Example:	
        Grammar	with	common	preﬁx:	
                p1:	E	->	F	"*"	E	
                p2:	E	->	F	
                p3:	F	->	ID	
                p4:	F	->	INT	
                p5:	F	->	"("	E	")"	
              "*"	      ID	      INT	      "("	 ")"	
    E	                p1,p2	 p1,p2	      p1,p2	
    F	                  p3	       p4	      p5	
               Collision	in	a	table	entry!	
               The	grammar	is	not	LL(1)	
                            	
       A	grammar	with	common	preﬁx	is	not	LL(1).	
Some	grammars	with	common	preﬁx	are	LL(k),	for	some	k,	–	
                    but	not	this	one.	
                                                          15	

L05A.pdf:  Summary:	construcLng	an	LL(1)	parser	
1.  Write	the	grammar	on	canonical	form	
2.  Analyze	the	grammar	using	FIRST,	NULLABLE,	and	
    FOLLOW.	
3.  Use	the	analysis	to	construct	a	table.	
    The	table	shows	what	producLon	to	select,	given	the	
    current	lookahead	token.	
4.  Conﬂicts	in	the	table?	The	grammar	is	not	LL(1).	
5.  No	conﬂicts?	Straight	forward	implementaLon	using	
    table-driven	parser	or	recursive	descent.	
                                                         16	

L05A.pdf:               S	      Recall	main	parsing	ideas	
       A	               X	                               A	               X	
                                                                         B	C	
        t		r		u		v		r		u		r		u		...	                      t		r		u		v		r		u		r		u		...	
LL(1):	decides	to	build	X	aier	seeing	the	         LR(1):	decides	to	build	X	aier	seeing	the	
ﬁrst	token	of	its	subtree.	                        ﬁrst	token	following	its	subtree.	
The	tree	is	built	top	down.	                       The	tree	is	built	boSom	up.	
                       For	each	producLon	X	->	γ	we	need	to	compute	
                  FIRST(γ):	the	tokens	that	can	appear	ﬁrst	in	a	γ	derivaLon	
                    NULLABLE(γ):	can	the	empty	string	be	derived	from	γ?	
                   FOLLOW(X):	the	tokens	that	can	follow	an	X	derivaLon	
                                                                                            17	

L05A.pdf:Algorithm	for	construcLng	an	LL(1)	table	
iniLalize	all	entries	table[Xi,	tj]	to	the	empty	set.	
	
for	each	producLon	p:	X	->	γ		
		for	each	t	∈	FIRST(γ)	
				add	p	to	table[X,	t]	
		if	NULLABLE(γ)	
				for	each	t	∈	FOLLOW(X)	
						add	p	to	table[X,	t]	
                t1	        t2	        t3	      t4	
     X1	        p1	        p2	
     X2	                   p3	        p3	      p4	
If	some	entry	has	more	than	one	element,	then	the	
grammar	is	not	LL(1).	
                                                       18	

L05A.pdf:Exercise:	what	is	NULLABLE(X)?		
Z	->	d	              NULLABLE	
Z	->	X	Y	Z	 X	
Y	->	ε	
Y	->	c	     Y	
X	->	Y	     Z	
X	->	a	
                                 19	

L05A.pdf:SoluLon:	what	is	NULLABLE(X) 	
 Z	->	d	            NULLABLE	
 Z	->	X	Y	Z	 X	     true	
 Y	->	ε	
 Y	->	c	     Y	     true	
 X	->	Y	     Z	     false	
 X	->	a	
                               20	

L05A.pdf:                      DeﬁniLon	of	NULLABLE	
                                         Informally:	
            NULLABLE(γ):	true	if	the	empty	string	can	be	derived	from	γ	
                where	γ	is	a	sequence	of	terminals	and	nonterminals	
                            Formal	deﬁni1on,	given	G=(N,T,P,S)	
NULLABLE(ε)	==	true                                                      	(1)	
	
NULLABLE(t)	==	false                                                     	(2)	
				where	t	∈	T,	i.e.,	t	is	a	terminal	symbol	
	
NULLABLE(X)	==	NULLABLE(γ1)	||	...	||	NULLABLE(γn)                       	(3)	
				where	X	->	γ1,	...	X	->	γn	are	all	the	producLons	for	X	in	P	
	
NULLABLE(sγ)	==	NULLABLE	(s)	&&	NULLABLE	(γ)                             	(4)	
				where	s	∈	N	∪ T,	i.e.,	s	is	a	nonterminal	or	a	terminal	
                       The	equa1ons	for	NULLABLE	are	recursive.	
          How	would	you	write	a	program	that	computes	NULLABLE(X)?	
            Just	using	recursive	func1ons	could	lead	to	nontermina1on!	
                                                                               21	

L05A.pdf:                         Fixed-point	problems	
CompuLng	NULLABLE(X)	is	an	example	of	a	ﬁxed-point	problem.	
	
These	problems	have	the	form:	
	
		x	==	f(x)	
	
Can	we	ﬁnd	a	value	x	for	which	the	equaLon	holds	(i.e.,	a	soluLon)?	
x	is	then	called	a	ﬁxed	point	of	the	funcLon	f.	
Fixed-point	problems	can	(someLmes)	be	solved	using	iteraLon:	
Guess	an	iniLal	value	x0,	then	apply	the	funcLon	iteraLvely,	unLl	the	ﬁxed	point	
is	reached:	
	
x1	:=	f(x0);	
x2	:=	f(x1);	
...	
xn	:=	f(xn-1);	
	
unLl	xn==	xn-1	
	
This	is	called	a	ﬁxed-point	iteraLon,	and	xn	is	the	ﬁxed	point.	
                                                                                  22	

L05A.pdf:Implement	NULLABLE	by	a	ﬁxed-point	iteraLon	
represent	NULLABLE	as	an	array	nlbl[	]	of	boolean	variables	
iniLalize	all	nlbl[X]	to	false	
	
repeat	
		changed	=	false	
		for	each	nonterminal	X	with	producLons	X	->	γ1,	...,	X	->	γn	do	
				newValue	=	nlbl(γ1)	||	...	||	nlbl(γn)	
				if	newValue	!=	nlbl[X]	then	
							nlbl[X]	=	newValue	
							changed	=	true	
				ﬁ	
		do	
unLl	!changed	
	
where	nlbl(γ)	is	computed	using	the	current	values	in	nlbl[	].	
The	computaLon	will	terminate	because	
-	the	variables	are	only	changed	monotonically	(from	false	to	true)	
-	the	number	of	possible	changes	is	ﬁnite	(from	all	false	to	all	true)	
                                                                        23	

L05A.pdf:            Exercise:	compute	NULLABLE(X)		
                     nlbl[	]	
Z	->	d	                              iter0	   iter1	          iter2	 iter3	
Z	->	X	Y	Z	          X	              f	
Y	->	ε	
Y	->	c	              Y	              f	
X	->	Y	              Z	              f	
X	->	a	
In	each	iteraLon,	compute:	
for	each	nonterminal	X	with	producLons	X	->	γ1,	...,	X	->	γn	
				newValue	=	nlbl(γ1)	||	...	||	nlbl(γn)	
where	nlbl(γ)	is	computed	using	the	current	values	in	nlbl[	].	
                                                                            24	

L05A.pdf:            SoluLon:	compute	NULLABLE(X)		
                     nlbl[	]	
Z	->	d	                              iter0	   iter1	          iter2	 iter3	
Z	->	X	Y	Z	          X	              f	       f	              t	     t	
Y	->	ε	
Y	->	c	              Y	              f	       t	              t	     t	
X	->	Y	              Z	              f	       f	              f	     f	
X	->	a	
In	each	iteraLon,	compute:	
for	each	nonterminal	X	with	producLons	X	->	γ1,	...,	X	->	γn	
				newValue	=	nlbl(γ1)	||	...	||	nlbl(γn)	
where	nlbl(γ)	is	computed	using	the	current	values	in	nlbl[	].	
                                                                            25	

L05A.pdf:                            DeﬁniLon	of	FIRST	
                                         Informally:	
 FIRST(γ):	the	tokens	that	can	occur	as	the	ﬁrst	token	in	sentences	derived	from	γ	
                            Formal	deﬁni1on,	given	G=(N,T,P,S)	
FIRST(ε)	==	∅                                                                	(1)	
	
FIRST(t)	==	{	t	}                                                            	(2)	
				where	t	∈	T,	i.e.,	t	is	a	terminal	symbol	
	
FIRST(X)	==	FIRST(γ1)	∪	...	∪	FIRST(γn)                                      	(3)	
				where	X	->	γ1,	...	X	->	γn	are	all	the	producLons	for	X	in	P	
	
FIRST(sγ)	==	FIRST(s)	∪	(if	NULLABLE(s)	then	FIRST(γ)	else	∅	ﬁ)              	(4)	
				where	s	∈	N	∪	T,	i.e.,	s	is	a	nonterminal	or	a	terminal	
                          The	equa1ons	for	FIRST	are	recursive.	
                           Compute	using	ﬁxed-point	itera1on.	
                                                                                    26	

L05A.pdf:        Implement	FIRST	by	a	ﬁxed-point	iteraLon	
represent	FIRST	as	an	array	FIRST[	]	of	token	sets	
iniLalize	all	FIRST[X]	to	the	empty	set	
	
repeat	
		changed	=	false	
		for	each	nonterminal	X	with	producLons	X	->	γ1,	...,	X	->	γn	do	
				newValue	=	FIRST(γ1)	∪	...	∪	FIRST(γn)	
				if	newValue	!=	FIRST[X]	then	
							FIRST[X]	=	newValue	
							changed	=	true	
				ﬁ	
		do	
unLl	!changed	
	
where	FIRST(γ)	is	computed	using	the	current	values	in	FIRST[	].	
The	computaLon	will	terminate	because	
-	the	variables	are	changed	monotonically	(using	set	union)	
-	the	largest	possible	set	is	ﬁnite:	T,	the	set	of	all	tokens	
-	the	number	of	possible	changes	is	therefore	ﬁnite	               27	

L05A.pdf:                SoluLon:	compute	FIRST(X)		
Z	->	d	                            NULLABLE	
Z	->	X	Y	Z	          X	            t

Y	->	ε	
Y	->	c	              Y	            t

X	->	Y	              Z	            f

X	->	a	
                     FIRST[	]	
                                   iter0	     iter1	          iter2	 iter3	
                     X	            ∅	
                     Y	            ∅	
                     Z	            ∅	
In	each	iteraLon,	compute:	
for	each	nonterminal	X	with	producLons	X	->	γ1,	...,	X	->	γn	
				newValue	=	FIRST(γ1)	∪	...	∪	FIRST(γn)	
where	FIRST(γ)	is	computed	using	the	current	values	in	FIRST[	].	
                                                                            28	

L05A.pdf:                Exercise:	compute	FIRST(X)		
Z	->	d	                            NULLABLE	
Z	->	X	Y	Z	          X	            t	
Y	->	ε	
Y	->	c	              Y	            t	
X	->	Y	              Z	            f	
X	->	a	
                     FIRST[	]	
                                   iter0	     iter1	          iter2	     iter3	
                     X	            ∅	         {a}	            {a,	c}	    {a,	c}	
                     Y	            ∅	         {c}	            {c}	       {c}	
                     Z	            ∅	         {a,	c,	d}	      {a,	c,	d}	 {a,	c,	d}	
In	each	iteraLon,	compute:	
for	each	nonterminal	X	with	producLons	X	->	γ1,	...,	X	->	γn	
				newValue	=	FIRST(γ1)	∪	...	∪	FIRST(γn)	
where	FIRST(γ)	is	computed	using	the	current	values	in	FIRST[	].	
                                                                                    29	

L05A.pdf:                      DeﬁniLon	of	FOLLOW	
                                      Informally:	
     FOLLOW(X):	the	tokens	that	can	occur	as	the	ﬁrst	token	following	X,	in	any	
                   sentenLal	form	derived	from	the	start	symbol	S.	
                         Formal	deﬁni1on,	given	G=(N,T,P,S)	
The	nonterminal	X	occurs	in	the	right-hand	side	of	a	number	of	producLons.	
	
Let	Y	->	γ	X	δ	denote	such	an	occurrence,	where	γ	and	δ	are	arbitrary	sequences	
of	terminals	and	nonterminals.	
	
		FOLLOW(X)	==	∪ FOLLOW(Y	->	γ	X	δ	),                                        	(1)	
				over	all	occurrences	Y	->	γ	X	δ		
	
		and	where	
		FOLLOW(Y	->	γ	X	δ	)	==                                                     	(2)	
				FIRST(δ)	∪	(if	NULLABLE(δ)	then	FOLLOW(Y)	else	∅	ﬁ)	
                      The	equa1ons	for	FOLLOW	are	recursive.	
                        Compute	using	ﬁxed-point	itera1on.	
sentenLal	form	—	sequence	of	terminal	and	nonterminal	symbols		                    30	

L05A.pdf:   Implement	FOLLOW	by	a	ﬁxed-point	iteraLon	
represent	FOLLOW	as	an	array	FOLLOW[	]	of	token	sets	
iniLalize	all	FOLLOW[X]	to	the	empty	set	
	
repeat	
		changed	=	false	
		for	each	nonterminal	X	do	
				newValue	==	∪	FOLLOW(Y	->	γ	X	δ	),	for	each	occurrence	Y	->	γ	X	δ		
				if	newValue	!=	FOLLOW[X]	then	
							FOLLOW[X]	=	newValue	
							changed	=	true	
				ﬁ	
		do	
unLl	!changed	
	
where	FOLLOW(Y	->	γ	X	δ	)	is	computed	using	the	current	values	in	FOLLOW[	].	
Again,	the	computaLon	will	terminate	because	
-	the	variables	are	changed	monotonically	(using	set	union)	
-	the	largest	possible	set	is	ﬁnite:	T	                                       31	

L05A.pdf:                   Exercise:	compute	FOLLOW(X)		
      S	->	Z	$	                    NULLABLE	    FIRST	
      Z	->	d	             X	       t	           {a,	c}	
      Z	->	X	Y	Z	
      Y	->	ε	             Y	       t	           {c}	
      Y	->	c	             Z	       f	           {a,	c,	d}	
      X	->	Y	
      X	->	a	             FOLLOW[ ]	
The	grammar	has	                      iter0	       iter1	       iter2	       iter3	
been	extended	with	       X	          ∅	
end	of	ﬁle,	$.	
                          Y	          ∅	
                          Z	          ∅	
      In	each	iteraLon,	compute:	
      newValue	==	∪	FOLLOW(Y	->	γ	X	δ	),	for	each	occurrence	Y	->	γ	X	δ		
      where	FOLLOW(Y	->	γ	X	δ	)	is	computed	using	the	current	values	in	FOLLOW[	].	
                                                                                    32	

L05A.pdf:                   SoluLon:	compute	FOLLOW(X)		
      S	->	Z	$	                    NULLABLE	    FIRST	
      Z	->	d	             X	       t	           {a,	c}	
      Z	->	X	Y	Z	
      Y	->	ε	             Y	       t	           {c}	
      Y	->	c	             Z	       f	           {a,	c,	d}	
      X	->	Y	
      X	->	a	             FOLLOW[	]	
The	grammar	has	                      iter0	       iter1	       iter2	       iter3	
been	extended	with	       X	          ∅	           {c}	         {a,	c,	d}	   {a,	c,	d}	
end	of	ﬁle,	$.	
                          Y	          ∅	           {a,	c,	d}	   {a,	c,	d}	   {a,	c,	d}	
                          Z	          ∅	           {$}	         {$}	         {$}	
      In	each	iteraLon,	compute:	
      newValue	==	U	FOLLOW(Y	->	γ	X	δ	),	for	each	occurrence	Y	->	γ	X	δ		
      where	FOLLOW(Y	->	γ	X	δ	)	is	computed	using	the	current	values	in	FOLLOW[	].	
                                                                                        33	

L05A.pdf:                          Summary	quesLons	
•  Construct	an	LL(1)	table	for	a	grammar.	
•  What	does	it	mean	if	there	is	a	collision	in	an	LL(1)	table?	
•  Why	can	it	be	useful	to	add	an	end-of-ﬁle	rule	to	some	grammars?	
•  How	can	we	decide	if	a	grammar	is	LL(1)	or	not?	
•  What	is	the	deﬁniLon	of	NULLABLE,	FIRST,	and	FOLLOW?	
•  What	is	a	ﬁxed-point	problem?	
•  How	can	it	be	solved	using	iteraLon?	
•  How	can	we	know	that	the	computaLon	terminates?	
                                                                     34	

L05B.pdf:EDAN65:	Compilers,	Lecture	05	B	
 Abstract	grammars	
                 	
         Görel	Hedin	
        Revised:	2016-09-12	

L05B.pdf:     This	lecture	
                                                          runtime system	
                                  source	code	(text)	
  Regular	      Lexical	analyzer	                             activation
                                                                            stack	
expressions
       (scanner)	                                   records	
                                  tokens	
Context-free	  Syntac'c	analyzer	 LR	parsing	                              garbage
 grammar
           (parser)	
                                                                           collection	
                                  AST	(Abstract	syntax	tree)	
 ARribute	                                                                  heap	
               SemanJc	analyzer	
 grammar
                                                       objects	
                                  ARributed	AST	
                 Intermediate	
                                                              Interpreter

                code	generator	
                                  intermediate	code	                         code
                                                                 Virtual	     and
                   OpJmizer	                                    machine
     data	
                                  intermediate	code	
                  Target	code	
                                                               machine
                   generator	
                                    target	code	

L05B.pdf:Abstract	grammars	
L05B.pdf:   Parse	tree	                           Abstract	tree	
       Stmt		                             AssignStmt		
                  Includes	all	tokens	                  Includes	important	tokens	
                                                         Simple	natural	structure	
   AssignStmt	                                                   Typed	nodes	
             Exp	
                Add	                                     Add	
             Exp	 Exp	
                                       IdExp	      IdExp	 IdExp	
sum				=				sum				+				k				;	         sum										sum										k			

L05B.pdf:                   Example:	Concrete	vs	Abstract	
    Concrete	grammar	                          Abstract	grammar	
    Exp	->	Exp	"+"	Term	                       Add:	Exp	->	Exp	Exp	
    Exp	->	Term	                               IdExp:	Exp	->	ID	
    Term	->	ID	
                                      ProducJons	are	named!	
                Exp	                                     Add	
           Exp	                                   IdExp	 IdExp	
                                                   ID	         ID	
       Term	          Term	
         ID	     +	      ID	
                                             An	abstract	grammar	cannot	
Note!	Term,	Factor,	are	needed	to	make	      be	ambiguous.	Term	and	
the	concrete	grammar	unambiguous.	           Factor	are	irrelevant	here.	

L05B.pdf:               Concrete	vs	Abstract	grammar	
                          Concrete	Grammar	         Abstract	Grammar	
What	does	it	describe?	   Describes	the	concrete	   Describes	the	abstract	
                          text	representaJon	of	    structure	of	programs	
                          programs	
Main	use	                 Parsing	text	to	trees	    Model	represenJng	the	
                                                    program	inside	compiler.	
Underlying	formalism	     Context-free	grammar	     Recursive	data	types	
What	is	named?	           Only	nonterminals	        Both	nonterminals	and	
                          (producJons	are	usually	  producJons.	
                          anonymous)	
What	tokens	occur	in	the	 all	tokens	corresponding	 usually	only	tokens	with	
grammar?	                 to	"words"	in	the	text	   values	(idenJﬁers,	literals)	
                          Independent	of	abstract	  Independent	of	parser	and	
                          structure	                parser	algorithm	

L05B.pdf:               Abstract	grammar	vs.	OO	model	
  Abstract	grammar	            OO	model	               Other	terminology	used	
                                                         (algebraic	datatypes)	
    nonterminal	               superclass	                      type,	sort	
     producJon	                 subclass	                constructor,	operator	
                                                     Exp		
Abstract	grammar	
Add:	Exp	->	Exp	Exp	
IdExp:	Exp	->	ID	
                                            Add	                IdExp	
  A	canonical	abstract	grammar	corresponds	to	a	two-level	class	hierarchy!	

L05B.pdf:             Example	Java	implementaJon	
Abstract	grammar	
Add:	Exp	->	Exp	Exp	
IdExp:	Exp	->	ID	
                            abstract	class	Exp	{	
               Exp		        }	
                            class	Add	extends	Exp	{	
                            		Exp	exp1,	exp2;	
                            }	
                            class	IdExp	extends	Exp	{	
    Add	             IdExp	
                            		String	ID;	
                            }	

L05B.pdf:                                  JastAdd	
  •  A	compiler	generaJon	tool.	Generates	Java	code.	
  •  Supports	ASTs	and	modular	computaJons	on	ASTs.	
  •  JastAdd:	"Just	add	computaJons	to	the	ast"	
  •  Independent	of	the	parser	used.	
  •  Developed	at	LTH,	see	hRp://jastadd.org	
Parser	speciﬁcaJon	                                    Parser	
   L.beaver	                       Beaver	              *.ast	
                                                         *.java	
Abstract	grammar	                                           creates	objects	
     *.ast	
       *.ast	
                                  JastAdd	              *.ast	
                                                         *.java	
     *.ast	                                           AST	classes	
       *.jrag	
ComputaJons	

L05B.pdf:                 JastAdd	abstract	grammars	
           (compared	to		canonical	abstract	grammars)	
Program	::=	Stmt*;	
abstract	Stmt;	
Assignment	:	Stmt	::=	IdExpr	Expr;	
IfStmt	:	Stmt	::=	Expr	Then:Stmt	[Else:Stmt];	
abstract	Expr;	
IdExpr	:	Expr	::=	<ID:String>;	
IntExpr	:	Expr	::=	<INT:String>;	
BinExpr	:	Expr	::=	Lel:Expr	Right:Expr;	
Add	:	BinExpr;	
•  Classes	instead	of	nonterminals	and	producJons	
•  Classes	can	be	abstract	(like	in	Java)	
•  Arbitrarily	deep	inheritance	hierarchy	(not	just	two	levels)	
•  Support	for	op9onal,	list,	and	token	components	
•  Components	can	be	named	
•  Right-hand	side	can	be	inherited	from	superclass	(see	BinExpr).	
•  No	parentheses!	You	need	to	name	all	node	classes	in	the	AST.	

L05B.pdf:       Generated	Java	API,	ordinary	components	
abstract	Stmt;	
WhileStmt	:	Stmt	::=	Cond:Expr	Stmt;	                         WhileStmt	
                                                       getCond()	     getStmt()	
abstract	class	Stmt	extends	ASTNode	{}	                     Expr	    Stmt	
	
                                                             Example	AST	
class	WhileStmt	extends	Stmt	{	
		Expr	getCond();	
		Stmt	getStmt();	
}	
•  A	general	class	ASTNode	is	used	as	implicit	superclass.	
•  A	traversal	API	with	get	methods	is	generated.	
•  If	component	names	are	given,	they	are	used	in	the	API	(getCond).	
•  Otherwise	the	type	names	are	used	(getStmt).	

L05B.pdf:                        Generated	Java	API,	lists	
 Program	::=	Stmt*;	
                                                                   Program	
                                                                         getStmts()	
 class	Program	extends	ASTNode	{	                                 List<Stmt>	
 		int	getNumStmt();			//	0	if	empty	
 		Stmt	getStmt(int	i);	//	numbered	from	0	
 		List<Stmt>	getStmts();	//	iterator	                    Stmt	      Stmt	           Stmt	
 }	
                                                                Example	AST	
The	list	is	represented	by	a	List	object	that	can	
be	used	as	an	iterator:	                           Or	access	a	speciﬁc	statement:	
 Program	p	=	...;	                                 Program	p	=	...;	
 for	(Stmt	s	:	p.getStmts())	{	                    if	(p.getNumStmt()	>=	1)	{	
 		...	                                            		Stmt	s	=	p.getStmt(0);	
 }	                                                		...	
                                                   }	

L05B.pdf:                     Generated	Java	API,	opJonals	
A	::=	B	[C];	
                                                                 A	
class	A	extends	ASTNode	{	                                  B	         Opt<C>	
		B	getB();	
		boolean	hasC();	
		C	getC();							//Excep9on	if	not	hasC()	                               C	
}	
                                                             Example	AST	
•  The	traversal	API	includes	a	has	method	for	the	opJonal	component.	

L05B.pdf:                               General	traversal	
                                                    ASTNode	
  Abstract	grammar	
       A	::=	B	[C];	
       B	::=	...;	                       A	    B	      C	  Opt	 List	
       C	::=	...;	
       D	:	A	::=	...;	
                                         D	
Will	stop	also	at	Opt	and	List	nodes.	
Can	be	used	for	general	traversal	of	the	children	of	a	node.	
class	ASTNode	{	
		Iterable	astChildren();	//Iterator	for	the	children	
}	
ASTNode	n	=	...;	
for	(ASTNode	child	:	n.astChildren())	{	
		...	
}	

L05B.pdf:                        Low-level	traversal	API	
                                                ASTNode	
 Abstract	grammar	
      A	::=	B	[C];	
      B	::=	...;	                      A	    B	   C	    Opt	    List	
      C	::=	...;	
      D	:	A	::=	...;	
                                       D	
Will	stop	also	at	Opt	and	List	nodes.	
Not	recommended.	Use	iterator	or	high-level	API	instead	–	much	more	readable.	
class	ASTNode	{	
		int	getNumChild();	
		ASTNode	getChild(int	i);	
		ASTNode	getParent();	//	null	for	the	root	
}	

L05B.pdf:ConnecJon	to	Beaver	
                                      Beaver	
  Beaver	spec	
  a	=	b	[c]; 	{:	return	new	A...	:}	
                                       LangParser	          beaver.Symbol	
  b	=	...	; 	{:	return	new	B...	:}	
  c	=	...	; 	{:	return	new	C...	:}	
                                                <<create>>	
  JastAdd	abstract	grammar	
                                                              ASTNode	
    A	::=	B	[C];	
    B	::=	...;	
    C	::=	...;	
                                                    A	    B	    C	    Opt	 List	
                                     JastAdd	

L05B.pdf:               Deﬁning	an	abstract	grammar	
This	is	object-oriented	modeling!	
•  What	kinds	of	objects	are	there	in	the	AST?	
   E.g.,	Program,	WhileStmt,	Assignment,	Add,	...	
•  What	are	the	generalized	concepts	(abstract	classes)?	
   E.g.,	Statement,	Expression,	...	
•  What	are	the	components	of	an	object?	
   E.g.,	an	Assignment	has	an	IdenJﬁer	and	an	Expression...	
Program	::=	...;	
abstract	Statement;	
abstract	Expression;	
WhileStmt	:	Statement	::=	...;	
Assignment	:	Statement	::=	IdenJﬁer	Expression;	
...	

L05B.pdf:                            Use	good	names!	
when	you	write...	       ...the	following	should	make	sense	
A	:	B	::=	...	           An	A	is	a	special	kind	of	B	
C	::=	D	E	F	             A	C	has	a	D,	an	E,	and	an	F	
D	::=	X:E	Y:E	           A	D	has	one	E	called	X	and	another	E	called	Y	
G	::=	[H]	               A	G	may	have	an	H	
J	::=	<K:T>	             A	J	has	a	K	token	of	type	T	
L	::=	M*	                An	L	has	zero	or	more	Ms	
Examples	of	bad	naming	               Good	naming	
(from	inexperienced	
programmers)	
A	::=	[OptParam];	                    A	::=	[Param];	
OptParam	::=	Name	Type;	              Param	::=	Name	Type;	
A	::=	Stmts*;	                        A	::=	Stmt*:	
abstract	Stmts;	                      abstract	Stmt;	
While	:	Stmts	::=	Exp	Stmt;	          While	:	Stmt	::=	Exp	Stmt;	

L05B.pdf:              Design	simple	abstract	grammars!	
•  Abstract	grammars	should	be	clear	and	simple	
•  Don't	let	parsing	details	creep	into	the	abstract	grammar	
Bad	abstract	grammar	                       Good	abstract	grammar	
(parsing	inspired)	                         (simple,	conceptual)	
A	::=	First:B	Rest:B*	                      A	::=	B*	
Add	:	Exp	::=	Lel:Exp	Right:Term	           Add	:	Exp	::=	Lel:Exp	Right:Exp	
•  "At	least	one	child"	can	easily	be	checked	by	a	semanJc	check.	Don't	impose	a	
   more	complex	structure	just	to	check	this.	
•  Term,	Factor,	etc.	is	a	parsing	issue,	not	an	abstract	grammar	issue.	

L05B.pdf:                     Design	a	parsing	grammar	
•  Design	the	abstract	grammar	ﬁrst.	
•  Then	design	a	high-level	concrete	grammar,	making	it	as	similar	as	possible	to	the	
   abstract	grammar.	
      •  Replace	inheritance	with	alternaJve	producJons	
      •  The	grammar	will	probably	be	ambiguous	
•  Then	design	a	low-level	concrete	grammar,	suitable	for	a	parJcular	parsing	
   algorithm/tool.	
   For	Beaver:	
      •  Eliminate	ambiguiJes	
      •  Eliminate	repeJJon	and	opJonals	(will	make	it	easier	to	construct	the	AST)	

L05B.pdf:                    SemanJc	acJons	in	parsers	
•  Code	that	is	added	to	a	parser,	to	perform	acJons	during	parsing.	
•  Usually,	to	build	the	AST.	
•  Old-style	1-pass	compilers	did	the	whole	compilaJon	as	semanJc	acJons.	
•  Parser	generators	support	semanJc	acJons	in	the	parser	speciﬁcaJon.	

L05B.pdf:                                Beaver	example	
Abstract	grammar	                                      High-level	CFG	
abstract	Stmt;	                                        stmt	->	ifStmt	|	assignment	
IfStmt	:	Stmt	::=	Expr	Stmt;	                          ifStmt	->	IF	"("	expr	")"	stmt	
Assignment	:	Stmt	::=	IdExpr	Expr;	                    assignment	->	ID	ASSIGN	expr	
IdExpr	:	Expr	::=	<ID:String>;	
                 beaver	spec	without	seman'c	ac'ons:	
                 %class	"LangParser";	
                 %package	"lang";	
                 ...	
                 %terminals	IF,	LPAREN,	RPAREN,	ID,	ASSIGN;	
                 	
                 %goal	stmt;	//	The	start	symbol	
                 	
                 //	Context-free	grammar	
                 stmt	=	ifStmt	|	assignment;	
                 ifStmt	=	IF	LPAREN	expr	RPAREN	stmt;	
                 assignment	=	ID	ASSIGN	expr;	

L05B.pdf:                Beaver	example	                     Abstract	grammar	
                                                    abstract	Stmt;	
beaver	spec	with	seman'c	ac'ons:	                   IfStmt	:	Stmt	::=	Expr	Stmt;	
%class	"LangParser";	                               Assignment	:	Stmt	::=	IdExpr	Expr;	
%package	"lang";	                                   IdExpr	:	Expr	::=	<ID:String>;	
...	
%terminals	IF,	LPAREN,	RPAREN,	ID,	ASSIGN;	
	
%goal	stmt;	//	The	start	symbol	
	
%typeof	stmt	=	"Stmt";	
%typeof	ifStmt	=	"IfStmt";	
%typeof	assignment	=	"Assignment";	
	
//	Context-free	grammar	
stmt	=	ifStmt	|	assignment;	
ifStmt	=	IF	LPAREN	expr.e	RPAREN	stmt.s;	{:	return	new	IfStmt(e,	s);	:}	
assignment	=	
				ID.id	ASSIGN	expr.e;	{:	return	new	Assignment(new	IdExpr(id),e);	:}	
seman9c	ac9ons	build	the	trees	
variables	capture	token	strings	and	subtrees	for	nonterminals	
the	nonterminals	return	objects	of	the	abstract	grammar	classes	

L05B.pdf:      Summary	quesJons:	Abstract	syntax	trees	
•  What	is	the	diﬀerence	between	an	abstract	and	a	concrete	syntax	tree?	
•  What	is	the	diﬀerence	between	an	abstract	and	a	concrete	grammar?	
•  What	is	the	correspondence	between	an	abstract	grammar	and	an	object-
   oriented	model?	
•  OrientaJon	about	JastAdd	abstract	grammars,	traversal	API,	and	connecJon	to	
   Beaver.	
•  What	are	properJes	of	a	good	abstract	grammar?	
•  What	is	a	"semanJc	acJon"?	
•  How	can	Beaver	be	used	for	building	ASTs?	

L06A.pdf:EDAN65:	Compilers,	Lecture	06	A	
       LR	parsing	
         Görel	Hedin	
        Revised:	2016-09-12	

L06A.pdf:     This	lecture	
                                                           runtime system	
                                  source	code	(text)	
  Regular	      Lexical	analyzer	                             activation
                                                                            stack	
expressions
       (scanner)	                                   records	
                                  tokens	
Context-free	  Syntac'c	analyzer	 LR	parsing	                              garbage
 grammar
           (parser)	
                                                                           collection	
                                  AST	(Abstract	syntax	tree)	
 APribute	                                                                  heap	
               SemanHc	analyzer	
 grammar
                                                       objects	
                                  APributed	AST	
                 Intermediate	
                                                              Interpreter

                code	generator	
                                  intermediate	code	                         code
                                                                 Virtual	     and
                   OpHmizer	                                    machine
     data	
                                  intermediate	code	
                  Target	code	
                                                               machine
                   generator	
                                    target	code	
                                                                                   2	

L06A.pdf:LR	parsing	
            3	

L06A.pdf:                     Recall	main	parsing	ideas	
           S	
  A	                  X	                  A	                  X	
                                                             B	C	
  t			r			u			v			r			u			r			u		...	     t			r			u			v			r			u			r			u		...	
LL(1):	decides	to	build	X	aVer	seeing	 LR(1):	decides	to	build	X	aVer	seeing	
the	ﬁrst	token	of	its	subtree.	        the	ﬁrst	token	following	its	subtree.	
The	tree	is	built	top	down.	           The	tree	is	built	boPom	up.	
                                                                              4	

L06A.pdf:          Recall	diﬀerent	parsing	algorithms	
                        Unambiguous	
                         LR	
                          LL	                 Ambiguous	
                    All	context-free	grammars	                This	lecture	
LL:	                                     LR:	
LeV-to-right	scan	                       LeV-to-right	scan	
LeVmost	derivaHon	                       Rightmost	derivaHon	
Builds	tree	top-down	                    Builds	tree	boPom-up	
Simple	to	understand	                    More	powerful	
                                                                            5	

L06A.pdf:                       Recall:	LL(k)	vs	LR(k)	
                                 LL(k)	                            LR(k)	
     Parses	input	                             LeV-to-right	
      DerivaHon	              LeVmost	                          Rightmost	
      Lookahead	                                k	symbols	
    Build	the	tree	           top	down	                        boPom	up	
      Select	rule	       aVer	seeing	its	ﬁrst	      aVer	seeing	all	its	tokens,	and	an	
                               k	tokens	                  addiHonal	k	tokens	
    LeV	recursion	                No	                               Yes	
 Unlimited	common	                No	                               Yes	
        preﬁx	
 Resolve	ambiguiHes	        Dangling	else	            Dangling	else,	associaHvity,	
through	rule	priority	                                           priority	
   Error	recovery	         Trial-and-error	              Good	algorithms	exist	
Implement	by	hand?	            Possible.	                  Too	complicated.	
                                                             Use	a	generator.	
                                                                                        6	

L06A.pdf:                                 LR	parsing	
Add	the	EOF	token	($)	and	an	extra	start	rule.	
	
The	parser	uses	a	stack	of	symbols	(terminals	and	nonterminals).	
	
The	parser	looks	at	the	current	input	token	and	decides	to	do	one	of	
the	following	acHons:	
	
		shiV	–	Push	the	input	token	onto	the	stack.	Read	the	next	token.	
		reduce	–		
				Match	the	top	symbols	on	the	stack	with	a	producHon	right-hand	side.	
				Pop	those	symbols	and	push	the	leV-hand	side	nonterminal.	
				At	the	same	Hme,	build	this	part	of	the	tree.	
		accept	–	when	the	parser	is	about	to	shiV	$,	the	parse	is	complete.				
	
The	parses	uses	a	ﬁnite	state	automaton	(encoded	in	a	table)	to	decide	
which	acHon	to	take	and	which	state	to	go	to	aVer	each	a	shiV	acHon.	
                                                                          7	

L06A.pdf:                                          Grammar:	
                                          p0:	S	->	Stmt	$	
   Stack•Input	   LR	parsing	example	     p1:	Stmt	->	ID	"="	Exp	
•	ID	=	ID	+	ID	$	                         p2:	Exp	->	ID	
                                          p3:	Exp	->	Exp	"+"	ID	
                                      shi?:	push	input	to	stack,	
                                      read	next	token		
                                      reduce:	pop	rhs,	push	lhs,	
                                      build	part	of	tree	
                                      accept:	the	tree	is	ready	
                                                                 8	

L06A.pdf:                                                                   Grammar:	
                                                                   p0:	S	->	Stmt	$	
   Stack•Input	             LR	parsing	example	                    p1:	Stmt	->	ID	"="	Exp	
•	ID	=	ID	+	ID	$	                                                  p2:	Exp	->	ID	
           shiV	              reduce	Exp	->	Exp	"+"	ID	            p3:	Exp	->	Exp	"+"	ID	
ID	•	=	ID	+	ID	$	
           shiV	                                             shi?:	push	input	to	stack,	
                                   ID	=			Exp				•	$	        read	next	token		
ID	=	•	ID	+	ID	$	                  					Exp	+	ID		           reduce:	pop	rhs,	push	lhs,	
           shiV	                   					ID	                  build	part	of	tree	
                                  reduce	Stmt	->	ID	"="	Exp	 accept:	the	tree	is	ready	
ID	=	ID	•	+	ID	$	
          reduce	Exp	->	ID	        			Stmt							•	$	
ID	=	Exp	•	+	ID	$	                 ID	=			Exp	               Follow	the	reducHon	steps	in	
                                                             reverse	order.	They	correspond	
					ID	                           					Exp	+	ID		
                                                             to	a	rightmost	derivaHon.	
              shiV	                					ID	                  	
                                                             Stmt	=>	
ID	=	Exp	+	•	ID	$	                                           ID	"="	Exp	=>	
                                                             ID	"="	Exp	"+"	ID		=>	
					ID	
                                             accept	         ID	"="	ID	"+"	ID		
              shiV	                                          		
                                                             	
ID	=	Exp	+	ID	•	$	
					ID	
                                                                                             9	

L06A.pdf:                             LR(1)	items	
The	parser	uses	a	DFA	(a	determinisHc	ﬁnite	automaton)	to	decide	
whether	to	shiV	or	reduce.	
	
The	states	in	the	DFA	are	sets	of	LR	items.	
               LR(1)	item:	
               X	->	α	•	β	           	t,s	
An	LR(1)	item	is	a	producHon	extended	with:	
•  A	dot	(•),	corresponding	to	the	posiHon	in	the	input	sentence.	
•  One	or	more	possible	lookahead	terminal	symbols,	t,s	
   (we	will	use	?	when	the	lookahead	doesn't	maPer)	
The	LR(1)	item	corresponds	to	a	state	where:	
•  The	topmost	part	of	the	stack	is	α.	
•  The	ﬁrst	part	of	the	remaining	input	is	expected	to	match	β(t|s)		
                                                                      10	

L06A.pdf:Grammar:	
p0:	S	->	E	$	
                                               ConstrucHng	state	1	
p1:	E	->	T	"+"	E	
p2:	E	->	T	                      First,	take	the	start	producHon	and	place	the	dot	
p3:	T	->	ID	                     in	the	beginning...	
                                 Note	that	there	is	a	nonterminal	E	right	aVer	the	dot,	
    S	->	•	E	$        	?	        and	it	is	followed	by	a	terminal	$.	Add	the	
                                 producHons	for	E,	with	$	as	the	lookahead.	
    S	->	•	E	$        	?	        Note	that	there	is	a	nonterminal	T	right	aVer	the	dot,	
    E	->	•	T	"+"	E    	$	        and	which	is	followed	by	either	"+"	or	$.	Add	the	
    E	->	•	T          	$	        producHons	for	T,	with	"+"	and	$	as	the	lookahead.	
                                 (We	write	them	on	the	same	line	as	a	shorthand.)	
 1	 S	->	•	E	$        	?	        We	have	already	added	producHons	for	all	
    E	->	•	T	"+"	E    	$	        nonterminals	that	are	right	aVer	the	dot.	Nothing	
    E	->	•	T          	$	        more	can	be	added.	
    T	->	•	ID         	+,$	      We	are	ﬁnished	construcHng	state	1.	
    Adding	new	producHons	for	nonterminals	following	the	dot,	unHl	no	more	
    producHons	can	be	added,	is	called	taking	the	closure	of	the	LR	item	set.	
                                                                                         11	

L06A.pdf:                     ConstrucHng	the	next	states	
Grammar:	
p0:	S	->	E	$	
p1:	E	->	T	"+"	E	
p2:	E	->	T	                         2	
p3:	T	->	ID	             E	             S	->	E	•	$        	?	
 1	 S	->	•	E	$           	?	        3	
                                 T	
    E	->	•	T	"+"	E       	$	            E	->	T	•	"+"	E      	$	
    E	->	•	T             	$	            E	->	T	•            	$	
    T	->	•	ID            	+,$	
                             ID	    4	
                                        T	->	ID	•         	+,$	
 Note	that	the	dot	is	followed	by	E,	T,	and	ID	in	state	1.	For	each	of	these	
 symbols,	create	a	new	set	of	LR	items,	by	advancing	the	dot	passed	that	
 symbol.	Then	complete	the	states	by	taking	the	closure.	
 (Nothing	had	to	be	added	for	these	states.)	                                 12	

L06A.pdf:                          CompleHng	the	LR	DFA	
Grammar:	
p0:	S	->	E	$	
p1:	E	->	T	"+"	E	
p2:	E	->	T	                          2	                                6	
p3:	T	->	ID	            E	              S	->	E	•	$       	?	              E	->	T	"+"	E	•  	$	
                                                                                       E	
                                                                      5	
 1	 S	->	•	E	$          	?	          3	                            T	    E	->	T	"+"	•	E   	$	
    E	->	•	T	"+"	E      	$	       T	    E	->	T	•	"+"	E     	$	           E	->	•	T	"+"	E   	$	
    E	->	•	T            	$	             E	->	T	•           	$	  "+"	     E	->	•	T         	$	
    T	->	•	ID           	+,$	                                            T	->	•	ID        	+,$	
                            ID	      4	                                   ID	
                                        T	->	ID	•        	+,$	
 Complete	the	DFA	by	advancing	the	dot,	creaHng	new	states,	compleHng	
 them	by	taking	the	closure.	If	there	is	already	a	state	with	the	same	items,	
 we	use	that	state	instead.	
                                                                                            13	

L06A.pdf:                       ConstrucHng	the	LR	table	
• For	each	token	edge	t,	from	state	j	to	state	k,	
  add	a	shi?	ac'on	"s	k"	                          state	 "+"	 ID	 $	 E	 T	
  (shiV	and	goto	state	k)	to	table[j,t].	
                                                     1	
• For	each	nonterminal	edge	X,	from	state	j	to	
                                                     2	
  state	k,	add	a	goto	ac'on	"g	k"	(goto	state	k)	
  to	table[j,X].	                                    3	
• For	a	state	j	containing	an	LR	item	with	the	      4	
  dot	to	the	le?	of	$,	add	an	accept	ac'on	"a"	      5	
  to	table[j,$]	
                                                     6	
• For	each	state	j	that	contains	an	LR	item	
  where	the	dot	is	at	the	end,	add	a	reduce	
  ac'on	"r	p"	(reduce	p)	to	table[j,t],	where	p	
  is	the	producHon	and	t	is	the	lookahead	
  token.	
                                                                          14	

L06A.pdf:                       ConstrucHng	the	LR	table	
• For	each	token	edge	t,	from	state	j	to	state	k,	
  add	a	shi?	ac'on	"s	k"	                          state	 "+"	  ID	    $	   E	   T	
  (shiV	and	goto	state	k)	to	table[j,t].	
                                                     1	         s	4	       g	2	 g	3	
• For	each	nonterminal	edge	X,	from	state	j	to	
                                                     2	                a	
  state	k,	add	a	goto	ac'on	"g	k"	(goto	state	k)	
  to	table[j,X].	                                    3	    s	5	      r	p2	
• For	a	state	j	containing	an	LR	item	with	the	      4	   r	p3	      r	p3	
  dot	to	the	le?	of	$,	add	an	accept	ac'on	"a"	      5	         s	4	       g	6	 g	3	
  to	table[j,$]	
                                                     6	              r	p1	
• For	each	state	j	that	contains	an	LR	item	
  where	the	dot	is	at	the	end,	add	a	reduce	
  ac'on	"r	p"	(reduce	p)	to	table[j,t],	where	p	
  is	the	producHon	and	t	is	the	lookahead	
  token.	
                                                                                  15	

L06A.pdf:                    Using	the	LR	table	for	parsing	
• Use	a	symbol	stack	and	a	state	stack	
• The	current	state	is	the	state	stack	top.	 state	 "+"	  ID	    $	   E	   T	
• Push	state	1	to	the	state	stack	
• Perform	an	acHon	for	each	token:		           1	         s	4	       g	2	 g	3	
• Case	ShiV	s:	                                2	                a	
   • Push	the	token	to	the	symbol	stack	       3	    s	5	      r	p2	
   • Push	s	to	the	state	stack	
   • The	current	state	is	now	s.	              4	   r	p3	      r	p3	
• Case	Reduce	p:	                              5	         s	4	       g	6	 g	3	
   • Pop	symbols	for	the	rhs	of	p	             6	              r	p1	
   • Push	the	lhs	symbol	X	of	p	
   • Pop	the	same	number	of	states	
   • Let	s1	=	the	top	of	the	state	stack	
   • Let	s2	=	table[s1,X]	
   • Push	s2	to	the	state	stack	
   • The	current	state	is	now	s2.	
• Case	Accept:	Report	successful	parse	
                                                                            16	

L06A.pdf:                      Example	of	LR	parsing	
 Grammar:	
 p0:	S	->	E	$	
 p1:	E	->	T	"+"	E	                    Parsing	ID	+	ID	$	
 p2:	E	->	T	
                                       State	     Symbol	   Input	   ac'on	
 p3:	T	->	ID	
                                       stack	      stack	
Parse	table:	                         1	                  ID	+	ID	$	
state	   "+"	    ID	    $	   E	   T	
  1	             s	4	       g	2	 g	3	
  2	                    a	
  3	      s	5	        r	p2	
  4	     r	p3	        r	p3	
  5	             s	4	       g	6	 g	3	
  6	                  r	p1	
                                                                          17	

L06A.pdf:                      Example	of	LR	parsing	
 Grammar:	
 p0:	S	->	E	$	
 p1:	E	->	T	"+"	E	                    Parsing	ID	+	ID	$	
 p2:	E	->	T	
                                        State	    Symbol	   Input	     ac'on	
 p3:	T	->	ID	
                                        stack	     stack	
Parse	table:	                         1	                  ID	+	ID	$	 shiV	4	
state	   "+"	    ID	    $	   E	   T	  1	4	       ID	      			+	ID	$	 reduce	p3	
  1	             s	4	       g	2	 g	3	 1	3	       T	       			+	ID	$	 shiV	5	
  2	                    a	            1	3	5	     T	+	     					ID	$	 shiV	4	
  3	      s	5	        r	p2	           1	3	5	4	   T	+	ID	  								$	 reduce	p3	
  4	     r	p3	        r	p3	           1	3	5	3	   T	+	T	   								$	 reduce	p2	
  5	             s	4	       g	6	 g	3	 1	3	5	6	   T	+	E	   								$	 reduce	p1	
  6	                  r	p1	           1	2	       E	       								$	 accept	
                                                                             18	

L06A.pdf:                        Conﬂict	in	an	LR	table	
Grammar:	
                                    Parts	of	the	parse	table:	
p0:	S	->	E	$	
p1:	E	->	E	"+"	E	                   state	 ...	      "+"	     ...	 ...	 ...	
p2:	E	->	E	"*"	E	
p3:	E	->	ID	
                                      ...	
                                       3	
Parts	of	the	DFA:	                    ...	
   3	 E	->	E	•	"+"	E        	?	
        E	->	E	"*"	E	•      	"+"	
                       "+"	         Fill	in	the	parse	table.	
   5	 		
        	                            What	is	the	problem?	
                                                                             19	

L06A.pdf:                       Conﬂict	in	an	LR	table	
   Grammar:	                       Parts	of	the	parse	table:	
  p0:	S	->	E	$	                     state	 ...	     "+"	    ...	      ...	   ...	
  p1:	E	->	E	"+"	E	
  p2:	E	->	E	"*"	E	
  p3:	E	->	ID	                        ...	
                                      3	         s	5,	r	p2	
Parts	of	the	DFA:	                    ...	
   3	 E	->	E	•	"+"	E       	?	
       E	->	E	"*"	E	•      	"+"	
                                   There	is	a	shiV-reduce	conﬂict.	
                      "+"	         The	grammar	is	ambiguous.	
                                   In	this	case,	we	can	resolve	the	conﬂict	by	
   5	 		                           selecHng	one	of	the	acHons.	
       	                           	
                                   To	understand	which	one,	think	about	what	
                                   the	top	of	the	stack	looks	like.	Think	about	
                                   what	will	happen	later	if	we	take	the	shiV	rule	
                                   or	the	reduce	rule.	
                                                                                    20	

L06A.pdf:                     Analyzing	LR	conﬂicts	...	
Example	output	from	parser	generator	(CUP):	
...	                                             Note!	The	dot	is	wriPen	as	"(*)".	
***	ShiV/Reduce	conﬂict	found	in	state	#5	       	
		between	expr	::=	expr	PLUS	expr	(*)	           Note!	The	parser	generator	
		and							expr	::=	expr	(*)	PLUS	expr	         automaHcally	resolves	the	conﬂict	
		under	symbol	PLUS	                             by	shiVing.	
		Resolved	in	favor	of	shiVing.	                 	
...	                                             Is	this	what	we	want???	
Line	up	the	dots	in	the	state:	
expr	->	expr	PLUS	expr	•                      		
expr	->											expr	•	PLUS	expr 		
The	top	of	stack	and	input	may	look	like:	
...	expr	PLUS	expr	•	PLUS	expr	...		
   top	of	stack		            remaining	input	
                                                                                    21	

L06A.pdf:                     ...	Analyzing	LR	conﬂicts	
   Line	up	the	dots	in	the	state:	
   expr	->	expr	PLUS	expr	•                             	PLUS	
   expr	->											expr	•	PLUS	expr                   	?	
             expr	                                                  expr	
                         expr	                               expr	
...	expr	PLUS	expr	•	PLUS	expr	...		              ...	expr	PLUS	expr	•	PLUS	expr	...		
            If	we	shiV	                                         If	we	reduce	
                                 Which	rule	should	we	choose?	
                                                                                       22	

L06A.pdf:               Diﬀerent	kinds	of	conﬂicts	
   E	->	E	•	"+"	E     	?	           A	shiV-reduce	conﬂict.	
   E	->	E	"*"	E	•     	"+"	
   A	->	B	C	•	        	t	           A	reduce-reduce	conﬂict.	
   D	->	C	•           	t	
ShiV-reduce	conﬂicts	can	someHmes	be	solved	with	precedence	rules.	In	
parHcular	for	binary	expressions	with	priority	and	associaHvity.	
	
For	other	cases,	you	need	to	carefully	analyze	the	shiV-reduce	conﬂicts	to	see	if	
precedence	rules	are	applicable,	or	if	you	need	to	change	the	grammar.	
	
For	reduce-reduce	conﬂicts,	it	is	advisable	to	think	through	the	problems,	and	
change	the	grammar.	
                                                                                   23	

L06A.pdf:Typical	precedence	rules	for	an	LALR	parser	generator	
  E	->	E	"=="	E	
  E	->	E	"**"	E	
  E	->	E	"*"	E	               ShiV-reduce	conﬂicts	are	automaHcally	resolved	
  E	->	E	"/"	E	               using	the	precedence	rules.	
  E	->	E	"+"	E	               	
  E	->	E	"-"	E	               Operators	in	the	same	rule	have	the	same	priority	
  E	->	ID	                    (e.g.,	PLUS,	MINUS).	
  E	->	INT	                   	
  	                           Operators	in	a	later	rule	have	higher	priority	(e.g.	
  precedence	nonassoc	EQ	     TIMES	has	higher	prio	than	PLUS.)	
  precedence	leV	PLUS,	MINUS	
  precedence	leV	TIMES,	DIV	
  precedence	right	POWER	
                                                                                    24	

L06A.pdf:                   How	the	precedence	rules	work	
    A	rule	is	given	the	priority	and	associaHvity	of	its	rightmost	token.	
    For	two	conﬂicHng	rules	with	diﬀerent	priority,	the	rule	with	the	highest	priority	is	
    chosen:		
      E	->	E	•	+	E        	?	                      E	->	E	•	*	E        	?	
      E	->	E	*	E	•        	+	                      E	->	E	+	E	•        	*	
         Reduce	is	chosen	                               ShiV	is	chosen	
 Two	conﬂicHng	rules	with	the	same	priority	have	the	same	associaHvity.	
 LeV-associaHvity	favors	reduce.	
 Right-associaHvity	favors	shiV.	
 Non-associaHvity	removes	both	rules	from	the	table	(input	following	that	paPern	will	
 cause	a	parse	error).			
E	->	E	+	E	•        	+	             E	->	E	**	E	•       	**	            E	->	E	==	E	•     	==	
E	->	E	•	+	E        	?	             E	->	E	•	**	E       	?	             E	->	E	•	==	E     	?	
 Reduce	is	chosen	                        ShiV	is	chosen	                  No	rule	is	chosen	
                                                                                               25	

L06A.pdf:         Diﬀerent	variants	of	LR(k)	parsers	
     Type	                            Characteris'cs	
     LR(0)	                    LR	items	without	lookahead.	
                                Not	very	useful	in	pracHce.	
      SLR	       Look	at	the	FOLLOW	set	to	decide	where	to	put	reduce	
   Simple	LR	                            acHons.	
                           Can	parse	some	useful	grammars.	
    LALR(1)	          Merges	states	that	have	the	same	LR	items,	
       	                      but	diﬀerent	lookaheads	(LA).	
used	in	pracHce	        Leads	to	much	smaller	tables	than	LR(1).	
                             Used	by	most	well	known	tools:	
                              Yacc,	CUP,	Beaver,	SableCC,	...	
                     Suﬃcient	for	most	pracHcal	parsing	problems.	
     LR(1)	               Slightly	more	powerful	than	LALR(1).	
                  Not	used	in	pracHce	–	the	tables	become	very	large.	
     LR(k)	                   Much	too	large	tables	for	k>1	
                                                                       26	

L06A.pdf:Diﬀerent	variants	of	LR	parsers	
              Unambiguous	
                               LR(k)	
                        LR(1)	
                                        Ambiguous	
                 LALR(1)	
       SLR	
LR(0)	
                                      GLR	
           All	context-free	grammars	
                                                   27	

L06A.pdf:              Universal	parsing	algorithms	
GLR	–	Generalized	LR	
	
Can	parse	any	context	free	grammar.	
	
Including	ambiguous	grammars!	
	
Returns	a	parse	forest	(all	possible	parse	trees).	
AddiHonal	mechanism	needed	to	select	which	of	the	trees	to	use.	
	
Can	parse	grammars	with	shiV-reduce	and	reduce-reduce	conﬂicts	(spawns	
parallel	parsers).	
	
Has	cubic	worst-case	complexity	(in	the	length	of	the	input).	
	
Is	oVen	much	bePer	than	that	in	pracHce.	But	sHll	slower	than	LALR.	
	
Used	in	several	research	systems.	
                                                                        28	

L06A.pdf:        Some	well-known	parser	generators	
    Name	                                Type,	host	language	
   JavaCC	                                      LL,	Java	
    ANTLR	                   LL,	Java	(also	earlier	versions	for	C,	C#,	...)	
     yacc	                   LALR,	C,	"yet	another	compiler	compiler"	
                                  Developed	for	AT&T	Unix	in	1970.	
    bison	                               LALR,	C++,	GNU	GPL	
     CUP	                                     LALR,	Java	
   beaver	                                    LALR,	Java	
  SDF/SGLR	                            Scannerless	GLR,	C,	Java	
For	more	examples,	see	
hPp://en.wikipedia.org/wiki/Comparison_of_parser_generators	
                                                                              29	

L06A.pdf:               Summary	quesHons:	LR	parsing	
•  How	does	LR	diﬀer	from	LL	parsers?	
•  What	does	it	mean	to	shiV?	
•  What	does	it	mean	to	reduce?	
•  Explain	how	LR	parsing	works	on	an	example.	
•  What	is	an	LR	item?	
•  What	does	an	LR	state	consist	of?	
•  What	does	it	mean	to	take	the	closure	of	a	set	of	LR	items?	
•  What	do	the	edges	in	an	LR	DFA	represent?	
•  How	can	an	LR	table	be	constructed	from	an	LR	DFA?	
•  How	is	the	LR	table	used	for	parsing?	
•  What	is	meant	by	a	shiV-reduce	conﬂict	and	a	reduce-reduce	conﬂict?	
•  How	can	such	a	conﬂict	be	analyzed?	
•  How	can	precedence	rules	be	used	in	an	LR	parser?	
•  What	is	LR(0)	and	SLR	parsing?	
•  What	is	the	diﬀerence	between	LALR(1)	and	LR(1)?	
•  Explain	why	the	LALR(1)	algorithm	is	most	commonly	used	in	parser	generators.	
•  What	is	a	GLR	parser?	
                                                                                  30	

L06B.pdf:EDAN65:	Compilers,	Lecture	06	B	
         Visitors	
         Görel	Hedin	
        Revised:	2016-09-13	

L06B.pdf:     This	lecture	
                                                             runtime system	
                                    source	code	(text)	
  Regular	      Lexical	analyzer	                               activation
                                                                              stack	
expressions
       (scanner)	                                     records	
                                    tokens	
Context-free	  SyntacLc	analyzer	
                                                                             garbage
 grammar
           (parser)	
                                                                             collection	
                                    AST	(Abstract	syntax	tree)	
                                  Visitors	                                   heap	
 ATribute	                        StaLc	aspects	
               Seman&c	analyzer	
 grammar
                         ATribute	grammars	              objects	
                                    ATributed	AST	
                 Intermediate	
                                                                Interpreter

                code	generator	
                                    intermediate	code	                         code
                                                                   Virtual	     and
                   OpLmizer	                                      machine
     data	
                                    intermediate	code	
                  Target	code	
                                                                 machine
                   generator	
                                       target	code	
                                                                                     2	

L06B.pdf:   Example	computaLons	on	an	AST	
                                                 Name	analysis:	ﬁnd	the	
     ...	
                                               declaraLon	of	an	idenLﬁer	
              Mul	
                                            Type	analysis:	compute	the	
                                               type	of	an	expression	
       Div	        IdExpr	
                                      Expression	evaluaLon:	compute	the	
IdExpr	     IdExpr	                     value	of	a	constant	expression	
                           Code	generaLon:	compute	an	intermediate	
                              code	representaLon	of	the	program	
           Unparsing:	compute	a	text	
         representaLon	of	the	program	
                                                                          3	

L06B.pdf:Abstract	grammar		
                                   Exercise:	expression	evaluaLon	
abstract	Expr;	
BinExpr	:	Expr	::=	Le]:Expr	Right:Expr;	
Add	:	BinExpr;	
Sub	:	BinExpr;	
IntExpr	:	Expr	::=	<INT:String>;	
Generated	AST	classes	
abstract	class	Expr	extends	ASTNode	{	
			
}	
class	BinExpr	extends	Expr	{	Expr	getLe]()	{...}	Expr	getRight	{...}	}	
class	Add	extends	BinExpr	{	
			
}	
class	Sub	extends	BinExpr	{	
			
}	
class	IntExpr	extends	Expr	{	
		String	getINT()	{...}	
			
}	                                                                      4	

L06B.pdf:Abstract	grammar		
                                     SoluLon:	expression	evaluaLon	
abstract	Expr;	
                                                     Problem	1:	NEVER	EDIT	GENERATED	CODE!!	
BinExpr	:	Expr	::=	Le]:Expr	Right:Expr;	
                                                     Problem	2:	The	code	is	not	modular!	
Add	:	BinExpr;	                                      We	have	to	edit	every	AST	class!	
Sub	:	BinExpr;	                                      The	computaLon	of	value()	is	a	cross-cugng	
IntExpr	:	Expr	::=	<INT:String>;	                    concern,	leading	to	tangled	code.	
Edited	AST	classes	
abstract	class	Expr	extends	ASTNode	{	
		abstract	int	value();	
}	
class	BinExpr	extends	Expr	{	Expr	getLe]()	{...}	Expr	getRight	{...}	}	
class	Add	extends	BinExpr	{	
		int	value()	{	return	getLe]().value()	+	getRight().value();	}	
}	
class	Sub	extends	BinExpr	{	
		int	value()	{	return	getLe]().value()	-	getRight().value();	}	
}	
class	IntExpr	extends	Expr	{	
		String	getINT()	{...}	
		int	value()	{	return	String.parseInt(getINT());	}	
}	                                                                                               5	

L06B.pdf:                   The	Expression	Problem	
•  We	would	like	to	
     •  deﬁne	language	constructs	in	a	modular	way.	
     •  deﬁne	computaLons	in	a	modular	way	
     •  compose	these	modules	as	we	like	
     •  preferrably,	with	separate	compilaLon	of	the	modules	
     •  and	with	full	type	safety	(without	need	for	casts)	
                                   Expr	
Unparsing	                                                  Value	computaLon	
for	Add,	Sub	                                               for	Add,	Sub	
                          Add	            Sub	
                                    Let	
                   Unparsing	                  Value	computaLon	
                   for	Let	                    for	Let	
                                                                              6	

L06B.pdf:                  The	simplest	soluLon:	StaLc	aspects	
abstract	class	Exp	extends	ASTNode	{	
		abstract	int	value();	
}	
class	Add	extends	Exp	{	
		int	value()	{	
				return	getLe]().value()	+	
																getRight().value();	
		}	
}	
class	IntExp	extends	Exp{	
		String	getINT()	{...}	
		int	value()	{	
				return	String.parseInt(getINT());	
		}	
}	
Factor	out	the	tangled	code	into	an	aspect.	
Requires	the	language	to	support	staLc	aspects.	
Not	supported	in	Java.	Requires	another	language	like	AspectJ,	or	JastAdd.	
                                                                            7	

L06B.pdf:             The	simplest	soluLon:	StaLc	aspects	
abstract	class	Exp	extends	ASTNode	{	        aspect	ValueComputaLon{	
	                                            		abstract	int	Exp.value();	
}	                                           	
class	Add	extends	Exp	{	                     	
			                                          		int	Add.value()	{	
	                                            				return	getLe]().value()	+	
	                                            																getRight().value();	
	                                            		}	
}	                                           	
class	IntExp	extends	Exp{	                   	
		String	getINT()	{...}	                     	
		                                           		int	IntExp.value()	{	
	                                            				return	String.parseInt(getINT());	
	                                            		}	
}	                                           }	
Factor	out	the	tangled	code	into	an	aspect.	
Requires	the	language	to	support	staLc	aspects.	
Not	supported	in	Java.	Requires	another	language	like	AspectJ,	or	JastAdd.	
                                                                                    8	

L06B.pdf:         Dealing	with	the	expression	problem	
•  Edit	the	AST	classes	(i.e.,	actually	not	solving	the	problem)	
      •  Non-modular,	non-composiLonal.	
      •  It	is	always	a	VERY	BAD	IDEA	to	edit	generated	code!	
      •  SomeLmes	used	anyway	in	industry.	
•  Visitors:	an	OO	design	paTern.	
      •  Modularize	through	clever	indirect	calls.	
      •  Not	full	modularizaLon,	not	composiLon.	
      •  Supported	by	many	parser	generators.	
      •  Reasonably	useful,	commonly	used	in	industry.	
•  StaLc	Aspect-Oriented	Programming	(AOP)	
      •  Also	known	as	inter-type	declara.ons	(ITDs)	
      •  Use	new	language	constructs	(aspects)	to	factor	out	code.	
      •  Solves	the	expression	problem	in	a	nice	simple	way.	
      •  The	drawback:	you	need	a	new	language:	AspectJ,	JastAdd,	...	
•  Advanced	language	constructs	
      •  Use	more	advanced	language	constructs:	virtual	classes	in	gbeta,	traits	in	
         Scala,	typeclasses	in	Haskell,	...	
      •  Drawbacks:	More	complex	than	staLc	AOP.	You	need	an	advanced	
         language.	Not	much	pracLcal	experience	(so	far).	
                  This	lecture:	Visitors	
                                                                                     9	

L06B.pdf:                                Visitors	
                    How	to	modularize	compilers	in	Java	
           (or	any	other	OO	language	without	AOP	mechanisms).	
The	Visitor	design	pa5ern	lets	you	deﬁne	a	new	opera.on	without	changing	
                     the	elements	on	which	it	operates.	
                  [Gamma,	Helm,	Johnson,	Vlissides,	1994]	
                                                                          10	

L06B.pdf:                            A	simple	example	
Original	code	                              A]er	adding	the	print	method	
class	Add	extends	Exp	{	                    class	Add	extends	Exp	{	
		Exp	e1,	e2;	                              		Exp	e1,	e2;	
}	                                          		void	print()	{	
class	IntExp	extends	Exp	{	                 				e1.print();	
		int	value;	                               				System.out.print("+");	
}	                                          				e2.print();	
                                            		}	
                                            }	
                                            class	IntExp	extends	Exp	{	
                                            		int	value;	
                                            		void	print()	{	
                                            					System.out.print(value);	
                                            		}	
                                            }	
Could	we	add	the	print	methods,	without	changing	the	original	code?	
                                                                           11	

L06B.pdf:Instead	of:	
                            Main	idea	of	visitors	
                print()	                                                 method	call	
                                Add	
                      IntExp	         IntExp	
Add	some	boilerplate	code	that	allows	
delegaLon	to	a	Visitor	object:	
accept(new	PrintVisitor())	                   visitAdd(this)	
                                Add	
                                                                         PrintVisitor	
                      IntExp	         IntExp	
                                                      visitIntExp(this)	
                                                                                       12	

L06B.pdf:                           Example	implementaLon	
 Original	code	                         General	visitor	
 class	Add	extends	Exp	{	               interface	Visitor	{	
 		Exp	e1,	e2;	                         		void	visitAdd(Add	n);	
 		void	accept(Visitor	v)	{	            		void	visitIntExp(IntExp	n);	
 				v.visitAdd(this);	                 }	
 		}	
 }	                                     Modular	addiLon	of	print	
 class	IntExp	extends	Exp	{	            class	Print	implements	Visitor	{	
 		int	value;	                          		void	visitAdd(Add	n)	{	
 		void	accept(Visitor	v)	{	            				n.e1.accept(this);	
 				v.visitIntExp(this);	              				System.out.print("+");	
 		}	                                   				n.e2.accept(this);	
 }	                                     		}	
                                        		void	visitIntExp(IntExp	n)	{	
                                        				System.out.print(n.value);	
General	boilerplate	code	for	visitors,	 		}	
can	be	generated	from	the	grammar.	     }	
                                                                          13	

L06B.pdf:          Many	implementaLons	use	Java	overloading	
                                 for	the	visit	methods	
    Original	code	                              General	visitor	
    class	Add	extends	Exp	{	                    interface	Visitor	{	
    		Exp	e1,	e2;	                              		void	visit(Add	n);	
    		void	accept(Visitor	v)	{	                 		void	visit(IntExp	n);	
    				v.visit(this);	                         }	
    		}	                                        Modular	addiLon	of	print	
    }	
    class	IntExp	extends	Exp	{	                 class	Print	implements	Visitor	{	
    		int	value;	                               		void	visit(Add	n)	{	
    		void	accept(Visitor	v)	{	                 				n.e1.accept(this);	
    				v.visit(this);	                         				System.out.print("+");	
    		}	                                        				n.e2.accept(this);	
    }	                                          		}	
                                                		void	visit(IntExp	n)	{	
                                                				System.out.print(n.value);	
                                                		}	
Tricky	quesLon:	The	accept	methods	all	look	    }	
the	same!	Why	can't	we	deﬁne	just	one	
accept	method	in	the	superclass,	and	let	all	  Answer:	Because	the	calls	go	to	diﬀerent	visit	methods:	
                                               "this"	has	diﬀerent	types	for	the	diﬀerent	calls.	The	visit	
classes	inherit	it???		                        methods	are	overloaded	(same	name	but	diﬀerent	
                                               argument	types).	                                         14	

L06B.pdf:                           Typical	Visitor	interface	
                       has	return	value	and	data	parameter	
 The	Visitor	interface	
 interface	Visitor	{	
 		Object	visit(Add	node,	Object	data);	
 		Object	visit(IntExp	node,	Object	data);	
 }	
The	AST	classes	
class	Add	extends	Exp	{	
		...	
		Object	accept(Visitor	v,	Object	data)	{	
				return	v.visit(this,	data);	
		}	
}	
class	IntExp	extends	Exp	{	
		...	
		Object	accept(Visitor	v,	Object	data)	{	
				return	v.visit(this,	data);	
		}	
}	
                                                            15	

L06B.pdf:              Example	visitor:	expression	evaluaLon	
Tangled	crosscugng	code	
class	Exp{	                       class	Add	extends	Exp{	           class	Sub	extends	Exp{	
		abstract	int	value();	          		int	value()	{	                  		int	value()	{	...	}	
}	                                				return	getLe]().value()	+		   }	
                                  						getRight().value();	}	
                                  }	                                class	IntExp	extends	Exp{	
                                                                    		int	value()	{	...	}	
                                                                    }	
Corresponding	Visitor	
class	Evaluator	implements	Visitor	{	
		Object	visit(Add	node,	Object	data)	{	
				return	
						(Integer)	node.getLe]().accept(this,	data)	+	               quite	a	lot	of	boilerplate	
						(Integer)	node.getRight().accept(this,	data);	
                                                                  extra	type	casts	
		}	
		Object	visit(Sub	node,	Object	data)	{	...	}	
		Object	visit(IntExp	node,	Object	data	{	...}	
}	
Casts	needed	to	access	return	and	data	values.	
(Could	be	solved	by	type	parameters	on	the	visitor	interface.)	                                16	

L06B.pdf:                  Making	the	client	code	simple	
             add	a	staLc	convenience	method	to	the	Visitor	
The	client	code	we	want	to	write:	
Exp	e	=	...;	
int	result	=	Evaluator.result(e);	
Visitor	
class	Evaluator	implements	Visitor	{	
		staLc	int	result(Exp	node)	{	
				return	(Integer)	node.accept(new	Evaluator(),	null);	
		}	
		Object	visit(Add	node,	Object	data)	{	
				int	n1	=	(Integer)	node.getLe]().accept(this,	data);	
				int	n2	=	(Integer)	node.getRight().accept(this,	data);	
				return	new	Integer(n1+n2);	
		}	
		Object	visit(Sub	node,	Object	data)	{	...	}	
		Object	visit(IntExp	node,	Object	data	{	...}	
}	
                                                            17	

L06B.pdf:                             Example:	unparser	
Tangled	crosscugng	code	
                                            class	Add	...	{	                      class	Sub	...{	
class	Exp{	                                 		void	unparse(Stream	s)	{	           		...	
		abstract	void	unparse(Stream	s);	         				getLe]().unparse(s);	             }	
}	                                          				s.print("+");	
Pass	the	stream	as	a	parameter	             				getRight().unparse(s);	          class	IntExp	...	{	
                                            		}	                                 		...	
                                            }	                                   }	
   Corresponding	Visitor	
   class	Unparser	implements	Visitor	{	
   		Unparser(Stream	s)	{	this.s	=	s;	}	
                                                        No	need	for	stream	parameter.	
   		Stream	s;	
                                                        Keep	it	in	the	visitor.	
   		Object	visit(Add	node,	Object	data)	{	
                                                        Nice!	
   				node.getLe]().accept(this,	data);	
   				s.print("+");	
   				node.getRight().accept(this,	data);	
   				return	null;	
   		}	
   		...	
   }	                                                                                             18	

L06B.pdf:          Adding	a	convenience	method	for	clients	
Client	code	
Exp	e	=	...;	
Stream	s	=	...;	
Unparser.doit(e,	s);	
Visitor	
class	Unparser	implements	Visitor	{	
		staLc	void	doit(Exp	e,	Stream	s)	{	
				e.accept(new	Unparser(s),	null);	
		}	
		Unparser(Stream	s)	{	this.s	=	s;	}	
		Stream	s;	
		Object	visit(Add	node,	Object	data)	{	
				node.getLe]().accept(this,	data);	
				s.print("+");	
				node.getRight().accept(this,	data);	
				return	null;	
		}	
		...	
}	
                                                   19	

L06B.pdf:                             One	more	example	
               Count	the	number	of	idenLﬁers	in	a	program	
Abstract	grammar		
abstract	Stmt;	
IfStmt	:	Stmt	::=	Cond:Exp	Then:Stmt	[Else:Stmt]	
...	
abstract	Expr;	
BinExpr	:	Expr	::=	Le]:Expr	Right:Expr;	
Add	:	BinExpr;	
Sub	:	BinExpr;	
IntExpr	:	Expr	::=	<INT:String>;	
IdExpr	:	Expr	::=	<ID:String>	
...	
How	can	we	implement	the	visitor?	
Problem:	We	need	to	write	lots	of	boring	traversal	code...	
                                                            20	

L06B.pdf:                                     SoluLon:	
                   Introduce	a	general	traversing	Visitor	
                               Visitor	      Interface,	as	before	
                         TraversingVisitor	 Default	implementaLons	that	just	traverse	
                                            the	AST.	
                                            Could	be	generated	from	the	grammar.	
                                             Override	default	traversal	when	
                          CountIdenLﬁers	
                                             needed.	
Some	parser	generators	generate	several	diﬀerent	kinds	of	visitors,	for	
diﬀerent	kinds	of	traversals.	
                                                                                    21	

L06B.pdf:           ImplementaLon	of	TraversingVisitor	
class	TraversingVisitor	implements	Visitor	{	
	
	private	Object	visitChildren(ASTNode	node,	Object	data)	{	
				for	(ASTNode	child	:	node.astChildren())	{	
								child.accept(this,	data);	
				}	
				return	data;	
		}	
	
		Object	visit(IfStmt	node,	Object	data)	{	
				return	visitChildren(node,	data);	
		}	
		Object	visit(Add	node,	Object	data)	{	
				return	visitChildren(node,	data);			
		}	
		Object	visit(Sub	node,	Object	data)	{	
				return	visitChildren(node,	data);			
		}	
		...	
}	
                                                            22	

L06B.pdf:       CountIdenLﬁers	as	a	traversing	visitor	
Example	use:	
Program	p	=	...	
System.out.print("The	number	of	idenLﬁers	is:	");	
System.out.println(CountIdenLﬁers.result(p));	
Visitor	
class	CountIdenLﬁers	extends	TraversingVisitor	{	  Only	one	visit	
		int	count	=	0;	                                  method	needed.	
		staLc	int	result(Program	root)	{	                	
				root.accept(new	CountIdenLﬁers());	            Nice!	
				return	count;	
		}	
		Object	visit(IdExpr	node,	Object	data)	{	
				count++;	
				return	null;	
		}	
}	
                                                                   23	

L06B.pdf:  RepresenLng	name	bindings	in	an	AST	
  {	                                                 Block	
  		int	a;	
  		a	=	3;	
  }	                                    VarDecl	                   Assign	
                                  IntType	  IdDecl	         IdUse	       IntExp	
                                             ID="a"	        ID="a"	      INT="3"	
                                                             decl	
Diﬀer	between	declaraLons	and	uses!	
	
IdDecl	for	declared	names	
IdUse	for	used	names	
	
An	aTribute	decl	represents	the	name	binding.	
                                                                                  24	

L06B.pdf: CompuLng	name	bindings	imperaLvely	
                                               Block	
 {	
 		int	a	=	3;	
 		int	b	=	4;	
                                                                           Block	
 		{	                       IdDecl	   IdDecl	
 				int	a;	                 ID="a"	   ID="b"	
 				a	=	b;	                                              IdDecl	
 		}	                                                      ID="a"	
 }	
                                                                   IdUse	      IdUse	
Use	a	symbol	table	data	structure:	                                ID="a"	     ID="b"	
For	each	block,	a	map	from	visible	names	to	declaraLons.	           decl	       decl	
Use	a	stack	of	maps	to	handle	nested	blocks.	
Algorithm:	
Traverse	the	AST	
push/pop	symbol	table	when	entering/leaving	a	block	
add/lookup	idenLﬁers	when	encountering	IdDecls/IdUses	
                                                                                       25	

L06B.pdf:       Example	API	for	block	structured	symbol	table	
class	SymbolTable<M>	{	
         void	add(String	symbol,	M	meaning);	//	add	to	top	table	
        	void	enterBlock();	//	push	new	table	
        	void	exitBlock();		//	pops	top	table	
        	M	lookup(String	symbol);	//	returns	the	meaning	of	the	symbol	
}	
Could	be	used,	for	example,	in	a	visitor:	
class	NameAnalysis	extends	TraversingVisitor	{	
				SymbolTable<IdDecl>	st	=	new	SymbolTable<IdDecl>();	
				void	visit(Block	node)	{	
								st.enterBlock();	
								visitChildren(node);	
								st.exitBlock();	
				}	
				void	visit(IdDecl	node)	{	
								st.add(node.getID(),	node);	
				}	
				void	visit(IdUse	node)	{	
								node.decl	=	st.lookup(node.getID());	
				}	
}	                                                                      26	

L06B.pdf:                          Summary	quesLons	
•  What	is	the	Expression	Problem?	
•  Why	is	solving	the	Expression	Problem	desirable	for	implemenLng	compilers?	
•  Why	is	it	a	bad	idea	to	edit	generated	code?	
•  Explain	how	the	Visitor	paTern	can	be	implemented.	
•  Implement	a	computaLon	over	the	AST	using	visitors.	
•  Add	a	convenience	method	to	the	visitor	to	make	it	easier	to	call	from	client	
   code.	
•  Why	can	traversing	visitors	be	useful?	
•  What	is	a	symbol	table?	
•  Why	use	both	IdDecl	and	IdUse	instead	of	just	one	AST	type?	
	
                                                                                  27	

L07A.pdf:       EDAN65:	Compilers,	Lecture	07	A	
Sta;c	Aspect-Oriented	Programming	
                Görel	Hedin	
               Revised:	2016-09-19	

L07A.pdf:     This	lecture	
                                                             runtime system	
                                    source	code	(text)	
  Regular	      Lexical	analyzer	                               activation
                                                                              stack	
expressions
       (scanner)	                                     records	
                                    tokens	
Context-free	  Syntac;c	analyzer	
                                                                             garbage
 grammar
           (parser)	
                                                                             collection	
                                    AST	(Abstract	syntax	tree)	
                                  Visitors	                                   heap	
 ASribute	                        Sta&c	aspects	
               Seman&c	analyzer	
 grammar
                         ASribute	grammars	              objects	
                                    ASributed	AST	
                 Intermediate	
                                                                Interpreter

                code	generator	
                                    intermediate	code	                         code
                                                                   Virtual	     and
                   Op;mizer	                                      machine
     data	
                                    intermediate	code	
                  Target	code	
                                                                 machine
                   generator	
                                       target	code	
                                                                                     2	

L07A.pdf:                            Recall	
                      Seman&c	analysis	
computa;ons	on	the	AST:	name	analysis,	type	analysis,	error	checking,	...	
                                  	
                                  	
                                  	
                     Expression	problem	
How	can	we	add	both	computa;ons	and	language	constructs	modularly?	
                                  	
                                  	
                                  	
          Solu&ons	to	the	expression	problem	
              •  Solu;on	1:	Visitors	(previous	lecture)	
               •  Solu;on	2:	Sta;c	AOP	(this	lecture)	
                                                                           3	

L07A.pdf:                 Example:	Prin;ng	an	AST	
                              Ordinary	programming	
class	Exp	{	
		abstract	void	print();	            Pros:	Straighaorward	code	
}	                                   	
class	Add	extends	Exp	{	             Cons:	
		Exp	e1,	e2;	                       •  If	we	add	a	new	opera;on,	like	compu;ng	
		void	print()	{	                       the	value,	all	classes	need	to	be	modiﬁed.	
				e1.print();	                     •  We	get	tangled	code	–	many	diﬀerent	
				System.out.print("+");		            concerns	in	the	same	class.	
				e2.print();	
		}	
}	
class	IntExp	extends	Exp	{	
		int	value;	
		void	print()	{	
				System.out.print(value);	
		}	
}	
...	
                                                                                    4	

L07A.pdf:                 Example:	Prin;ng	an	AST	
                            Visitor	solu;on	
class	Exp	{	                          class	Unparser	implements	Visitor	{	
}	                                    		void	visit(Add	node)	{	
class	Add	extends	Exp	{	              				node.e1.accept(this);	
		Exp	e1,	e2;	                        				System.out.print("+");	
		void	accept(Visitor	v)	{	           				node.e2.accept(this);	
				v.visit(this);	                   		}	
		}	                                  		void	visit(IntExpr	node)	{	
}	                                    				System.out.print(node.value);	
class	IntExp	extends	Exp	{	           		}	
		int	value;	                         }	
		void	accept(Visitor	v)	{	
				v.visit(this);	
		}	                             Pros:	Modular	addi;on	of	new	opera;on.	
}	                               Separately	compiled.	
...	                             	
                                 Cons:	Clumsy	code	with	lots	of	boilerplate	
                                 (accept	and	visit	methods).	Cannot	extend	
                                 visitors	easily	if	the	language	is	extended.	
                                                                               5	

L07A.pdf:               Example:	Prin;ng	an	AST	
                     Sta;c	Aspect-Oriented	Programming	
class	Exp	{	                            aspect	Unparser	{	
}	                                      		abstract	void	Exp.print();	
class	Add	extends	Exp	{	                		void	Add.print()	{	
		Exp	e1,	e2;	                          				e1.print();	
}	                                      				System.out.print("+");		
class	IntExp	extends	Exp	{	             				e2.print();	
		int	value;	                           		}	
}	                                      		void	IntExp.print()	{	
...	                                    				System.out.print(value);	
                                        		}	
                                        }	
Pros:	Straighaorward	code.	Modular	addi;on	of	new	opera;on.	No	problem	to	extend	the	
language	–	addi;onal	methods	can	be	added	in	other	aspect.	
	
Cons:	Cannot	use	Java.	Need	more	advanced	language	like	AspectJ	or	JastAdd.	Not	
separately	compiled.	
                                                                                   6	

L07A.pdf:            Inter-type	declara;ons	
                     The	key	construct	in	sta;c	AOP	
class	C	{	          aspect	A	{	
}	                  		T	C.m()	{	                inter-type	declared	method	
                    				...	
class	D	{	          		}	
}	                  		int	D.f	=	3;	             inter-type	declared	ﬁeld	
                    }	
         is	equivalent	to:	
class	C	{	
	T	m()	{	
				...	
		}	
}	
class	D	{	
	int	f	=	3;	
}	
                                                                            7	

L07A.pdf:Recall:	Dealing	with	the	expression	problem	
•  Edit	the	AST	classes	(i.e.,	actually	not	solving	the	problem)	
      •  Non-modular,	non-composi;onal.	
      •  It	is	always	a	VERY	BAD	IDEA	to	edit	generated	code!	
      •  Some;mes	used	anyway	in	industry.	
•  Visitors:	an	OO	design	paSern.	
      •  Modularize	through	clever	indirect	calls.	
      •  Not	full	modulariza;on,	not	composi;on.	
      •  Supported	by	many	parser	generators.	
      •  Reasonably	useful,	commonly	used	in	industry.	
•  Sta;c	Aspect-Oriented	Programming	(AOP)	
      •  Also	known	as	inter-type	declara.ons	(ITDs)	or	introduc.on	
      •  Use	new	language	constructs	(aspects)	to	factor	out	code.	
      •  Solves	the	expression	problem	in	a	nice	simple	way.	
      •  The	drawback:	you	need	a	new	language:	AspectJ,	JastAdd,	...	
•  Advanced	language	constructs	
      •  Use	more	advanced	language	constructs:	virtual	classes	in	gbeta,	traits	in	
         Scala,	typeclasses	in	Haskell,	...	
      •  Drawbacks:	More	complex	than	sta;c	AOP.	You	need	an	advanced	
         language.	Not	much	prac;cal	experience	(so	far).	
                  This	lecture:	Sta;c	AOP	
                                                                                     8	

L07A.pdf:                    Sta;c	AOP	in	JastAdd	
  Abstract	grammar	
         *.ast	
           *.ast	
                               JastAdd	          *.ast	
                                                  *.java	
         *.ast	                                 Generated	
           *.jrag	           Generates	AST	      tangled		
Computa;on	aspects	      classes	and	weaves	in	
                                                AST	classes	
	                             aspect	code	
                         	
                                                             9	

L07A.pdf:           Example	aspect:	expression	evalua;on	
Abstract	grammar		
abstract	Expr;	
abstract	BinExpr	:	Expr	::=	Lep:Expr	Right:Expr;	
Add	:	BinExpr;	
Sub	:	BinExpr;	
IntExpr	:	Expr	::=	<INT:String>;	
Aspect	
aspect	Evaluator	{	
		abstract	int	Expr.value();	
		int	Add.value()	{	return	getLep().value()	+	getRight().value();	}	
		int	Sub.value()	{	return	getLep().value()	–	getRight().value();	}	
		int	IntExpr.value()	{	return	String.parseInt(getINT());	}	
}	
Inter-type	declara.ons:	The	value	methods	will	be	woven	into	the	
classes	(Expr,	Add,	Sub,	IntExpr).	
Also	known	as	introduc.on.	
                                                                     10	

L07A.pdf:                     Another	example:	unparsing	
Abstract	grammar		
abstract	Expr;	
abstract	BinExpr	:	Expr	::=	Lep:Expr	Right:Expr;	
Add	:	BinExpr;	
Sub	:	BinExpr;	
IntExpr	:	Expr	::=	<INT:String>;	
Aspect	
aspect	Unparser	{	
		abstract	void	Expr.unparse(Stream	s,	String	indent);	
		void	BinExp.unparse(Stream	s,	String	indent)	{	
				getLep().unparse(s,indent);	
				s.print(operatorString());	
				getRight().unparse(s,indent);	
		}	
		abstract	String	BinExp.operatorString();	
		String	Add.operatorString()	{	return	"+";	}	
		String	Sub.operatorString()	{	return	"-";	}	
		void	IntExpr.unparse(Stream	s,	String	indent)	{	s.print(getINT());	}	
}	
                                                                        11	

L07A.pdf:                                     Weaving	the	classes	in	JastAdd	
toy.ast	
 abstract	Expr;	
 abstract	BinExpr	:	Expr	::=	Lep:Expr	Right:Expr;	
 Add	:	BinExpr;	
 Sub	:	BinExpr;	
 IntExpr	:	Expr	::=	<INT:String>;	
 Evaluator.jrag	                                                                  class	Expr	extends	
                                                                                     class	BinExpr	extends	
                                                                                  ASTNode	{	
 aspect	Evaluator	{	                                                              	 Expr	{	
                                                                                          class	Add	extends	
 		abstract	int	Expr.value();	                                                    	 			void	unparse(...)	{	
                                                                                          BinExpr	{	
                                                                                              class	Sub	extends	
 		int	Add.value()	{	return	getLep().value()	+	getRight().value();	}	
 		int	Sub.value()	{	return	getLep().value()	–	getRight().value();	}	
                                                                         JastAdd	 	 	 		int	value()	{	return	
                                                                                              BinExpr	{	
                                                                                  	 	 getLep().value()	+	
                                                                                              		int	value()	{	return	
 		int	IntExpr.value()	{	return	String.parseInt(getINT());	}	                     	 	 getRight().value();	}	
                                                                                              getLep().value()	-	
 }	                                                                               }	 		}	 		String	operatorString()	
                                                                                              getRight().value();	}	
                                                                                  	 	 {	return	"+";	}	
                                                                                              		String	operatorString()	
                                                                                     }	 }	 {	return	"-";	}	
                                                                                              }	
 Unparser.jrag	
 aspect	Unparser	{	
 		abstract	void	Expr.unparse(Stream	s,	String	indent);	
 		void	BinExp.unparse(Stream	s,	String	indent)	{	                                 Tangled	generated	
 				getLep().unparse(s,ind);	
 				s.print(operatorString());	
                                                                                                    code	
 				getRight().unparse(s,ind);	
 		}	
 		abstract	BinExp.operatorString();	
 		String	Add.operatorString()	{	return	"+";	}	
 		String	Sub.operatorString()	{	return	"-"}	
 		void	IntExpr.unparse(Stream	s,	String	indent)	{	s.print(getINT());	}	
 }	
           Untangled	source	code	                                                                                     12	

L07A.pdf: Features	that	can	be	inter-type	declared	or	
            factored	out	to	JastAdd	aspects	
•  Methods	
•  Instance	variables	
•  "implements"	clauses	
•  "import"	clauses	
•  aSribute	grammars	(see	later	lecture)	
                                              13	

L07A.pdf:                 Sta;c	aspects	vs	Visitors	
                    Sta&c	aspects	        Visitors	
What	can	be	        instance	variables	   only	methods	
factored	out	from	  methods	
AST	classes?	       implements	clauses	
Type	safety?	       full	type	precision	  Casts	may	be	needed,	
                                          depending	on	framework	
Method	parameters	  any	number	           only	one	
Ease	of	use?	       Very	simple	          Clumsy,	boilerplate	code	
                                          needed.	
Arbitrary	          Yes	                  No	–	you	can	extend	a	visitor,	
composi&on	of	                            but	then	you	need	factories	to	
modules?	                                 create	them.	And	you	cannot	
                                          not	combine	two	extensions.	
Separate	           Not	for	JastAdd	or	   Yes	
compila&on?	        AspectJ.	
Mainstream	OO	      No	–	you	need	        Yes,	use	Java	or	any	other	OO	
language?	          JastAdd,	AspectJ,	or	 language.	
                    similar	
                                                                          14	

L07A.pdf:                       Recall:	The	expression	problem	
       How	add	both	classes	and	computa;ons	in	a	modular	way?	
                                   Aspects	with	
   Ordinary	OO		             inter-type	declara;ons	          The	Visitor	design	paSern	
           A	                       A	       A.comp1	         A	                      Visitor	
                                             B.comp1	
         comp1	                              C.comp1	       accept	                visit(A)	
         comp2	                                                                    visit(B)	
                                                                                   visit(C)	
                                             A.comp2	
                                             B.comp2	
                                             C.comp2	
    B	            C	           B	        C	             B	          C	     Comp1	             Comp2	
  comp1	        comp1	                                accept	     accept	 visit(A)	          visit(A)	
  comp2	        comp2	                                                    visit(B)	          visit(B)	
                                                                          visit(C)	          visit(C)	
Classes	can	be	added	             Fully	modular.	      Computa;ons	can	be	added,	but	non-
 modularly,	but	not	                                     modular	changes	needed	if	classes	
    computa;ons.	                                              are	added.	Complex	code.	
                                                                                                       15	

L07A.pdf:        Full	Aspect-Oriented	Programming	
Full	AOP	    =	     Sta;c	AOP	        +	   Dynamic	AOP	
                                             advice	
               inter-type	declara;ons		      pointcuts	
                                             joinpoints	
                   Modular	code.	        Modular	instrumenta;on.	
                                                                  16	

L07A.pdf:           Full	Aspect-Oriented	Programming	
•  JastAdd	supports	only	a	small	part	of	AOP,	namely	sta.c	AOP	with	inter-
   type	declara;ons.	
•  Aspect-oriented	programming	is	a	wider	concept	that	usually	focuses	on	
   dynamic	behavior:	a	general	code	instrumenta;on	technique:	
      •  A	joinpoint	is	a	point	during	execu;on	where	advice	code	can	be	
         added.	
      •  A	pointcut	is	a	set	of	joinpoints	that	can	be	described	in	a	simple	
         way,	e.g.,	
            •  all	calls	to	a	method	m()	
            •  all	accesses	of	a	variable	v	
      •  Advice	is	code	you	can	specify	in	an	aspect	and	that	can	be	added	at	
         joinpoints,	either	aper,	before,	or	around	the	joinpoint.	
      •  Example	applica;ons:	
            •  Add	logging	of	method	calls	in	an	aspect	(instead	of	adding	print	
               statements	all	over	your	code)	
            •  Add	synchroniza;on	code	to	basic	code	that	is	unsynchronized	
                                                                                  17	

L07A.pdf:                    The	interpreter	design	paSern	
                    Commonly	used	for	many	computa;ons	in	a	compiler.	
            Here	explained	using	Ordinary	OO.	Modularize	using	AOP	or	Visitors.	
Intent:	Given	a	language,	deﬁne	a	representa.on	for	its	grammar	along	with	an	interpreter	
            that	uses	the	representa.on	to	interpret	sentences	in	the	language.	
                           [Gamma,	Helm,	Johnson,	Vlissides,	1994]	
                                                                *	
                                    AbstractExpression	
                                interpret(Context)	
            TerminalExpression	                           NonterminalExpression	
         interpret(Context)	                          interpret(Context)	{	
                                                      			child.interpret(...);	
                                                      }	
     AbstractExpression,	TerminalExpression,	NonterminalExpression,	interpret,	and	
                             Context	are	just	ROLES	in	the	paSern.	
                        In	our	programs,	we	will	use	our	own	names.	
                                                                                        18	

L07A.pdf:  abstract	Stmt;	
                                                 Example	use	of	Interpreter	
  Block	:	Stmt	::=	Stmt*;	                       PaSern	roles:	
  Assign	:	Stmt	::=	<ID>	Expr;	                  			context:	vars	
  abstract	Expr;	                                			interpret:	execute,		value	
  Add	:	Expr	::=	Lep:Expr	Right:Expr;	
  IdExpr	:	Expr	::=	<ID>;	
  IntExpr	:	Expr	::=	<INT>;	
               Stmt	                                                    Expr	
         execute(vars)	                                             value(vars)	
     Block	                 Assign	                    Add	            IdExpr	         IntExpr	
execute(vars)	          execute(vars)	            value(vars)	      value(vars)	     value(vars)	
  vars          	a	map	String	->	Value,	keeping	track	of	the	current	values	of	variables	
  execute       	executes	a	Stmt,	changing	and	using	the	vars	map	
  value         	executes	an	Expr	and	returns	its	value,	making	use	of	the	vars	map	
                                                                                               19	

L07A.pdf:        Example	implementa;on	using	JastAdd	aspects	
abstract	Stmt;	                      aspect	Interpreter	{	
                                     		abstract	void	Stmt.execute(Map<String,	Integer>	vars);	
Block	:	Stmt	::=	Stmt*;	             	
Assign	:	Stmt	::=	<ID>	Expr;	        		void	Block.execute(Map<String,	Integer>	vars)	{	
abstract	Expr;	                      				for	(Stmt	s	:	getStmts())	{	s.execute(vars);	}	
Add	:	Expr	::=	Lep:Expr	Right:Expr;	 		}	
                                     		void	Assign.execute(Map<String,	Integer>	vars)	{	
IdExpr	:	Expr	::=	<ID>;	             				int	value	=	getExpr().value(vars);	
IntExpr	:	Expr	::=	<INT>;	           				vars.put(getID(),	value);	
                                     		}		
                                     	
                                     		abstract	int	Expr.value(Map<String,	Integer>	vars);	
                                     	
                                     		int	Add.value(Map<String,	Integer>	vars)	{	
                                     				return	getLep().value(vars)	+	getRight().value(vars);	
                                     		}	
                                     		int	IdExpr.value(Map<String,	Integer>	vars)	{	
                                     				return	vars.get(getID());	
                                     		}	
                                     		int	IntExpr.value(Map<String,	Integer>	vars)	{	
                                     				return	String.parseInt(getINT());	
                                     		}	
                                     }	
                                                                                                20	

L07A.pdf:                         Summary	ques;ons	
•  What	are	diﬀerent	ways	of	solving	the	Expression	Problem?	
•  What	is	an	intertype	declara;on?	
•  What	is	aspect-oriented	programming?	
•  How	does	sta;c	AOP	diﬀer	from	dynamic	AOP?	
•  Implement	a	computa;on	over	the	AST	using	sta;c	aspects.	
•  What	are	advantages	and	disadvantages	of	sta;c	AOP	as	compared	to	Visitors?	
                                                                                21	

L07B.pdf:       EDAN65:	Compilers,	Lecture	07	B          	
Introduc=on	to	A>ribute	Grammars	
           synthesized,	inherited,	broadcas=ng	
                  Görel	Hedin	
                 Revised:	2016-09-19	

L07B.pdf:     This	lecture	
                                                             runtime system	
                                    source	code	(text)	
  Regular	      Lexical	analyzer	                               activation
                                                                              stack	
expressions
       (scanner)	                                     records	
                                    tokens	
Context-free	  Syntac=c	analyzer	
                                                                             garbage
 grammar
           (parser)	
                                                                             collection	
                                    AST	(Abstract	syntax	tree)	
                                  Visitors	                                   heap	
 A>ribute	                        Inter-type	declared	methods	
               Seman&c	analyzer	
 grammar
                         A.ribute	grammars	              objects	
                                    A>ributed	AST	
                 Intermediate	
                                                                Interpreter

                code	generator	
                                    intermediate	code	                         code
                                                                   Virtual	     and
                   Op=mizer	                                      machine
     data	
                                    intermediate	code	
                  Target	code	
                                                                 machine
                   generator	
                                       target	code	
                                                                                     2	

L07B.pdf:             Computa=ons	on	the	AST	
IMPERATIVE	COMPUTATIONS	               DECLARATIVE	COMPUTATIONS	
•  Deﬁne	methods	that	"do"	something.	 •  Deﬁne	proper=es	of	nodes	
•  Side-eﬀects	                        •  No	side-eﬀects	
     •  Modify	objects	                •  Useful	for	compu=ng	
     •  Output	to	ﬁles	                     •  Name	bindings	
•  Useful	for	                              •  Types	of	expressions	
     •  Execu=on/Interpreta=on	             •  Error	informa=on	
     •  Unparsing	                     •  Technique	
     •  Prin=ng	error	messages	             •  A>ribute	grammars	
•  Technique	
     •  Inter-type	declared	methods	   	
     •  Visitors	
	
                                                                     3	

L07B.pdf:                   Example	proper=es	
                    Does	this	method	have	any	compile-=me	errors?	
    int	gcd2(int	a,	int	b)	{	                   What	is	the	type	of	this	expression?	
    		if	(b	==	0)	{	
    				return	a;	
    		}		
    		return	gcd2(b,	a	%	b);	
    }		
What	is	the	declara=on	of	this	b?	
                            A.ribute	grammars:	
                            Express	these	proper=es	as	a#ributes	of	AST	nodes.	
                            Deﬁne	the	a>ributes	by	simple	directed	equa,ons.	
                            The	equa=ons	can	be	solved	automa=cally.	                 4	

L07B.pdf:                             Simple	example	
                             a>ributes	and	equa=ons	
          AST	node	                        eq	z=b.x+1	
                                                           	     z	
                                           eq	c.y=z+c.v	
               	
                                                      b	        c	
          a>ribute	
               z	
                                        eq	x=2	    	                	  eq	v=5	
                                                   x	               y	
         equa=on:	
                                                                    v	
     eq	a0	=	f(a1,	...,	an)	
                                                What	is	the	value	of	y?	
                                             Solve	the	equa=on	system!	
deﬁned	a>ribute	
                                            (Easy!	Just	use	subs=tu=on.)	
            func=on	of	other	a>ributes	
                                                                               5	

L07B.pdf:                              Simple	example	
                       synthesized	and	inherited	a>ributes	
deﬁnes	a>ribute	in	the	node	–	the	a>ribute	is	synthesized	
                                                  eq	z=b.x+1	
                                                                  	  syn	z	
                                                  eq	c.y=z+c.v	
deﬁnes	a>ribute	in	the	child	–	the	a>ribute	is	inherited	      b	      c	
                                               eq	x=2	    	               	    eq	v=5	
                                                        syn	x	          inh	y	
                                                                        syn	v	
Donald	Knuth	introduced	a>ribute	grammars	in	1968.	
The	term	"inherited"	is	not	related	to	inheritance	in	object-orienta=on.	
Both	terms	originated	during	the	1960s.	
                                                                                       6	

L07B.pdf:                          Simple	example	
       declaring	a>ributes	and	equa=ons	in	a	(JastAdd)	grammar	
Abstract	grammar:	
                                                    eq	z=b.x+1	
                                                                    A	  syn	z	
A	::=	B	C;	                                         eq	c.y=z+c.v	
B;	
C;	
                                                            getB	        getC	
A>ribute	grammar	module:	
 aspect	SomeAttributes	{	
 		syn	int	A.z();	
 		syn	int	B.x();	
 		syn	int	C.v();	                               eq	x=2	 B	                   C	 eq	v=5	
 		inh	int	C.y();	                                        syn	x	            inh	y	
 		eq		A.z()	=	getB().x()+1;	                                               syn	v	
 		eq		A.getC().v()	=	z()	+	getC().v();	
 		eq		B.x()	=	2;	
 		eq		C.v()	=	5;	            uses	inter-type	declara=ons	for	a>ributes	and	equa=ons	
 }	
 Note!	The	grammar	is	declara=ve.	The	order	of	the	equa=ons	is	irrelevant.	
 JastAdd	solves	the	equa=on	system	automa=cally.	
                                                                                         7	

L07B.pdf:                       Some	shorthands	
These	rules:	
syn	int	A.z();	
eq		A.z()	=	getB().x()+1;	
are	equivalent	to:	
 syn	int	A.z()	=	getB().x()+1;	
 and	we	could	also	use	method	body	syntax:	
 syn	int	A.z()	{	
 		return	getB().x()+1;	
 }	
                                            8	

L07B.pdf:             Equa=ons	must	be	free	from	
            (externally	visible)	side	eﬀects	
While	this	is	formulated	as	a	method,	execu=ng	it	has	no	side-eﬀects,	so	this	is	ﬁne.	
syn	int	A.z()	{	
		return	getB().x()+1;	
}	
It	is	also	ﬁne	to	have	assignments	to	local	
variables,	like	this.	The	eﬀect	of	changing	r	
is	not	visible	amer	execu=ng	the	method.	
syn	int	A.z()	{	
		int	r	=	0;	
		r	=	getB().x()+1;	
		return	r;	
}	
                                                                                       9	

L07B.pdf:           Equa=ons	must	be	free	from	
          (externally	visible)	side	eﬀects	
What	is	wrong	with	this	a>ribute	grammar?	
syn	int	A.x()	=	Globals.variable;	
	
syn	int	B.y()	{	
		Globals.variable++;	
		return	3;	
}	
                                            10	

L07B.pdf:              Equa=ons	must	be	free	from	
           (externally	visible)	side	eﬀects	
What	is	wrong	with	this	a>ribute	grammar?	
 syn	int	A.x()	=	Globals.variable;	
 	
 syn	int	B.y()	{	
 		Globals.variable++;	
 		return	3;	
 }	
Equa=ons	are	not	allowed	to	change	other	than	
local	data.	If	they	do,	they	are	not	equa=ons.	
	
Warning!	JastAdd	cannot	discover	if	you	have	side-
eﬀects	in	your	equa=ons!	If	your	deﬁni=ons	rely	on	
global	data	that	is	changed,	the	wrong	results	will	
be	computed.	
                                                     11	

L07B.pdf:          Well-formed	a>ribute	grammar	
                                      	
Abstract	grammar:	
                                         An	a>ribute	grammar	is	well-formed,	if	
A	::=	B	C;	
                                         there	is	exactly	one	deﬁning	equa=on	
B;	
C;	                                      for	each	a>ribute	in	any	AST.	
                                         	
A>ribute	grammar	module:	                JastAdd	checks	this	at	compile	=me.	
 aspect	SomeAttributes	{	
 		syn	int	A.z();	
 		syn	int	B.x();	
 		syn	int	C.v();	
 		inh	int	C.y();	
 		eq		A.z()	=	getB().x()+1;	
 		eq		A.getC().v()	=	z()	+	getC().v();	
 		eq		B.x()	=	2;	
 		eq		C.v()	=	5;	
 }	
                                                                               12	

L07B.pdf:            Well-deﬁned	a>ribute	grammar	
                                                 	
 An	a>ribute	grammar	is	well-deﬁned,	
 if	it	has	a	computable	unique	solu=on	for	any	AST.	
 	
 An	ordinary	a>ribute	grammar	is	well-deﬁned	
 if	it	is	well-formed	and	non-circular.	
Is	this	a>ribute	grammar	well-deﬁned?	
 aspect	SomeAttributes	{	
 		syn	int	A.c()	=	d();	
 		syn	int	A.d()	=	c();	
 }	
                             Circular	a>ribute	grammar.	Well-formed,	but	not	well-deﬁned.	
 JastAdd	checks	circularity	at	run=me.	
 	
 It	is	possible	to	allow	circular	a>ributes,	but	they	will	then	
 have	to	be	explicitly	declared	as	circular.	See	later	lecture.	                           13	

L07B.pdf:                          Abstract	grammar	
                       deﬁnes	the	structure	of	ASTs	
Abstract	grammar:	                            Example	AST	for	"a	+	b	+	c"	
abstract	Exp;	                          (an	instance	of	the	abstract	grammar)	
Add	:	Exp	::=	Left:Exp	Right:Exp;	
IdUse	:	Exp	::=	<ID>;	                                            Add	
                                                       Lem	            Right	
                                                      Add	              IdUse	
                                                                         ID="c"	
                                               Lem	          Right	
   The	terminal	symbols	(like	ID)	are	
   intrinsic	a>ributes	–		constructed	
   when	building	the	AST.	They	are	not	       IdUse	       IdUse	
   deﬁned	by	equa=ons.	                       ID="a"	       ID="b"	
                                                                                 14	

L07B.pdf:                       A>ribute	grammars	
            extends	abstract	grammars	with	a>ributes	
Abstract	grammar:	                       Example	AST	for	"a	+	b	+	c"	
abstract	Exp;	                     (an	instance	of	the	abstract	grammar)	
Add	:	Exp	::=	Left:Exp	Right:Exp;	
IdUse	:	Exp	::=	<ID>;	                                         Add	 type=...	
A>ribute	grammar	modules:	            type=...	    Add	                IdUse	
                                                                        ID="c"	
 syn	IdDecl	IdUse.decl()	=	...;	
                                                                        decl=...	
                                                                       type=...	
 syn	Type	Exp.type();	                   IdUse	         IdUse	
 eq		Add.type()	=	...;	                   ID="a"	        ID="b"	
 eq		IdUse.type()	=	...;	
                                         decl=...	      decl=...	
                                         type=...	      type=...	
 Each	declared	a>ribute	...	              ...	will	have	instances	in	the	AST	
                                                                                  15	

L07B.pdf:                A>ributes	and	equa=ons	
Abstract	grammar:	                                     Example	AST	for	"a	+	b	+	c"	
abstract	Exp;	                                   (an	instance	of	the	abstract	grammar)	
Add	:	Exp	::=	Left:Exp	Right:Exp;	
IdUse	:	Exp	::=	<ID>;	                                                     Add	
                                                               Add	              IdUse	
                                                                                  ID="c"	
 Think	of	a>ributes	as	"ﬁelds"	in	the	tree	nodes.	
  syn	Type	ASTClass.attribute();	
                                                       IdUse	       IdUse	
                                                       ID="a"	       ID="b"	
 Each	equa=on	deﬁnes	an	a>ribute	in	terms	of	
 other	a>ributes	in	the	tree.	
  eq	definedAttribute	=	function	of	other	attributes;	
 An	evaluator	computes	the	values	of	the	a>ributes	(solves	the	equa=on	system).	
 Think	of	the	equa=ons	as	"methods"	called	by	the	evaluator.	
                                                                                          16	

L07B.pdf:                      A>ribute	mechanisms	
Synthesized*	–	the	equa=on	is	in	the	same	node	as	the	a>ribute	
	
Inherited*	–	the	equa=on	is	in	an	ancestor	
	
Broadcas&ng*	–	the	equa=on	holds	for	a	complete	subtree	
	
Reference	–	the	a>ribute	can	be	a	reference	to	an	AST	node.	
	
Parameterized	–	the	a>ribute	can	have	parameters	
	
NTA	–	the	a>ribute	is	a	"nonterminal"	(a	fresh	node	or	subtree)	
	
Collec&on	–	the	a>ribute	is	deﬁned	by	a	set	of	contribu=ons,	instead	of	by	an	equa=on.	
	
Circular	–	the	a>ribute	may	depend	on	itself	(solved	using	ﬁxed-point	itera=on)	
	
*	Treated	in	this	lecture	
                                                                                        17	

L07B.pdf:                       Synthesized	a>ributes	
Synthesized	a>ribute:	                                                 A	
The	equa=on	is	in	the	same	node	as	the	a>ribute.	
                                                   eq	s()	=	f(...);	   B	
                                                                    s	=	...	
For	compu=ng	proper=es	that	depend	on	informa=on	in	the	node	
or	its	children.	
	
Typically	used	for	propaga=ng	informa=on	upwards	in	the	tree.	
                                                                             18	

L07B.pdf:            Synthesized	a>ributes,	example	1	
A	::=	B;	                        Draw	the	a#ribute	and	its	value!	
B;	
syn	int	B.s()	=	3;	                                A	
                                                   B	
                                                                   19	

L07B.pdf:                Synthesized	a>ributes,	example	1	
A	::=	B;	
B;	
syn	int	B.s()	=	3;	                                                        A	
Or	equivalently,	write	the	declara=on	and	equa=on	separately.	
syn	int	B.s();	                                                            B	
eq		B.s()	=	3;	                                                           s	=	3	
Or	equivalently,	write	the	equa=on	as	a	method	body:	
syn	int	B.s()	{	                             Nota	bene!	
		return	3;	                                 The	method	body	must	be	free	of	
}	                                           externally	visible	side-eﬀects.	
Don't	do	this!	
int	B.counter	=	0;	//	Ordinary	field	 Warning!	
syn	int	B.s()	{	                             Side-eﬀects	are	not	checked	by	JastAdd.	
		counter++;	//	Visible	side-effect	 The	a>ributes	will	get	inconsistent	values.	
		return	counter;	
}	                                                                                    20	

L07B.pdf:              Synthesized	a>ributes,	example	2	
A	::=	B;	                                               Three	diﬀerent	ASTs.	
abstract	B;	                                     Draw	the	a#ributes	and	their	values!	
C	:	B;	
D	:	B;	
E	:	D;	                                                 A	           A	            A	
Diﬀerent	subclasses	can	have	diﬀerent	equa=ons.	
                                                        C	           D	            E	
syn	int	B.s();	
eq	C.s()	=	4;	
eq	D.s()	=	5;	
eq	E.s()	=	6;	
                                                                                       21	

L07B.pdf:                 Synthesized	a>ributes,	example	2	
A	::=	B;	
abstract	B;	
C	:	B;	
D	:	B;	
E	:	D;	                                                      A	            A	          A	
Diﬀerent	subclasses	can	have	diﬀerent	equa=ons.	
                                                             C	            D	          E	
syn	int	B.s();	                                             s	=	4	        s	=	5	      s	=	6	
eq	C.s()	=	4;	
eq	D.s()	=	5;	
eq	E.s()	=	6;	
Note	that	equa=ons	can	override	equa=ons	in	superclasses,	
in	analogy	to	how	methods	can	override	methods	in	OO	languages.	
	
JastAdd	checks	that	each	concrete	class	has	equa=ons	for	all	its	synthesized	a>ributes.	
	
A	synthesized	a>ribute	is	similar	to	a	side-eﬀect	free	method,	but:	
•  its	value	is	cached	(memoized)	
•  circularity	is	checked	at	run=me	(results	in	excep=on)	                                   22	

L07B.pdf:                         Inherited	a>ributes	
Inherited	a>ribute:	                       eq	getB().s()	=	f(...);	   A	
The	equa=on	is	in	an	ancestor	
                                                                      B	
                                                                      C	
                                                                   s	=	...	
For	compu=ng	a	property	that	depends	on	the	context	of	the	node.	
	
Typically	used	for	propaga=ng	informa=on	downwards	in	the	tree.	
                                                                            23	

L07B.pdf:            Inherited	a>ributes,	example	1	
A	::=	B	C;	                     Draw	the	a#ribute	and	its	value!	
B;	
C;	
                                              A	
inh	int	B.i();	
eq	A.getB().i()	=	2;	
                                          B	      C	
                                                                  24	

L07B.pdf:            Inherited	a>ributes,	example	1	
A	::=	B	C;	
B;	
C;	
                                            A	
inh	int	B.i();	
eq	A.getB().i()	=	2;	
                                       B	      C	
                                     i	=	2	
                                                  25	

L07B.pdf:               Inherited	a>ributes,	example	2	
A	::=	Left:B	Right:B;	                    Draw	the	a#ributes	and	their	values!	
B;	
                                                             A	
The	parent	can	specify	diﬀerent	equa=ons	
for	its	diﬀerent	children.	
inh	int	B.i();	
eq	A.getLeft().i()	=	2;	                                 B	      B	
eq	A.getRight().i()	=	3;	
                                                                                26	

L07B.pdf:                 Inherited	a>ributes,	example	2	
 A	::=	Left:B	Right:B;	
 B;	
                                                                          A	
 The	parent	can	specify	diﬀerent	equa=ons	
 for	its	diﬀerent	children.	
 inh	int	B.i();	
 eq	A.getLeft().i()	=	2;	                                            B	          B	
 eq	A.getRight().i()	=	3;	                                         i	=	2	       i	=	3	
                                                                         Dot	
This	is	useful,	for	example,	when	deﬁning	scope	rules	
for	qualiﬁed	access.	The	lookup	a>ributes	should	have	
diﬀerent	values	for	the	diﬀerent	IdUses.	                    IdUse	            IdUse	
                                                             ID="a"	            ID="a"	
                                                       lookup("a")	=	...	     lookup("a")	=	...	
                                                                                                 27	

L07B.pdf:             Inherited	a>ributes,	example	3	
 A	::=	Left:B	Right:B;	                         Draw	the	a#ributes	and	their	values!	
 B	::=	C	D;	
 C;	
 D	::=	E;	
 E;	                                                                   A	
The	equa=ons	hold	for	the	complete	children	subtrees.	
                                                               B	               B	
 eq	A.getLeft().i()	=	2;	
 eq	A.getRight().i()	=	3;	
 inh	int	C.i();	                                           C	      D	       C	      D	
 inh	int	E.i();	
                                                                   E	                E	
                                                                                        28	

L07B.pdf:                 Inherited	a>ributes,	example	3	
 A	::=	Left:B	Right:B;	
 B	::=	C	D;	
 C;	
 D	::=	E;	
 E;	                                                                    A	
The	equa=ons	hold	for	the	complete	children	subtrees.	
                                                              B	                  B	
 eq	A.getLeft().i()	=	2;	
 eq	A.getRight().i()	=	3;	
 inh	int	C.i();	                                         C	        D	        C	        D	
 inh	int	E.i();	                                       i	=	2	              i	=	3	
                                                                   E	                  E	
                                                                 i	=	2	              i	=	3	
 This	is	called	broadcas,ng.	
                                                                                            29	

L07B.pdf:              Inherited	a>ributes,	example	4	
 A	::=	Left:B	Right:B;	                    Draw	the	a#ributes	and	their	values!	
 B	::=	C	D;	
 C;	
 D	::=	E;	
 E;	                                                              A	
An	equa=on	can	be	overruled	in	a	subtree.	
The	nearest	equa=on	holds.	                               B	               B	
 eq	A.getLeft().i()	=	2;	
 eq	A.getRight().i()	=	3;	                            C	      D	       C	      D	
 eq	B.getD().i()	=	i()	+	5;	
 inh	int	B.i();	
 inh	int	C.i();	                                              E	                E	
 inh	int	E.i();	
                                                                                   30	

L07B.pdf:              Inherited	a>ributes,	example	4	
 A	::=	Left:B	Right:B;	
 B	::=	C	D;	
 C;	
 D	::=	E;	
 E;	                                                          A	
An	equa=on	can	be	overruled	in	a	subtree.	
                                           i	=	2	   B	                  B	   i	=	3	
The	nearest	equa=on	holds.	
 eq	A.getLeft().i()	=	2;	
 eq	A.getRight().i()	=	3;	                     C	        D	        C	        D	
 eq	B.getD().i()	=	i()	+	5;	                 i	=	2	              i	=	3	
 inh	int	B.i();	
 inh	int	C.i();	                                         E	                  E	
 inh	int	E.i();	
                                                       i	=	7	              i	=	8	
                                                                                  31	

L07B.pdf:               Inherited	a>ributes,	example	5	
  A	::=	B	C;	
  B	::=	D;	
  C	::=	D;	
                                               Draw	the	a#ributes	and	their	values!	
  D;	
                                                                   A	
There	must	be	an	equa=on	for	each	a>ribute	in	
any	possible	AST.	
	
What	is	the	problem	with	this	grammar?	                     B	              C	
  eq	B.getD().i()	=	6;	
  inh	int	D.i();	                                           D	              D	
                                                                                     32	

L07B.pdf:                 Inherited	a>ributes,	example	5	
  A	::=	B	C;	
  B	::=	D;	
  C	::=	D;	
  D;	
                                                                        A	
There	must	be	an	equa=on	for	each	a>ribute	in	
any	possible	AST.	
	
What	is	the	problem	with	this	grammar?	                          B	              C	
  eq	B.getD().i()	=	6;	
  inh	int	D.i();	                                                D	              D	
                                                               i	=	6	         i	=	???	
Where	can	we	add	an	equa,on	to	solve	the	problem?	
	
In	C	or	A.	Or	in	their	superclass	ASTNode.	
                                                     This	a>ribute	has	no	equa=on!	
                                                JastAdd	will	ﬁnd	this	and	report	an	error.	
                                                                                        33	

L07B.pdf:                Broadcas=ng	of	inherited	a>ributes	
Tradi&onal	AG:	                              JastAdd:	
Equa=on	for	inherited	a>ribute	              Equa=on	for	inherited	a>ribute	
must	be	in	the	immediate	parent.	            is	"broadcasted"	to	complete	subtree.	
Leads	to	"copy	rules".	                      No	"copy	rules"	are	needed.	
syn	b	   A	     eq	c.a=b	                             syn	b	   A	    eq	c.a=b	
     B	         C	       inh	a	                            B	        C	
                        eq	d.a=a	
                D	                                                   D	
                                  copy	rule	
              inh	a	                                               inh	a	
                                                                                    34	

L07B.pdf:              Inherited	a>ributes,	example	6	
 A	::=	B	C;	
 B	::=	D;	
 C	::=	D;	
                                                     Draw	the	a#ributes	and	their	values!	
 D;	
                                                                         A	
The	parent	can	write	an	equa=on	that	holds	for	all	children.	
 eq	A.getChild().i()	=	8;	
 inh	int	D.i();	                                                  B	              C	
                                                                  D	              D	
                                                                                           35	

L07B.pdf:                Inherited	a>ributes,	example	6	
 A	::=	B	C;	
 B	::=	D;	
 C	::=	D;	
 D;	
                                                                     A	
The	parent	can	write	an	equa=on	that	holds	for	all	children.	
 eq	A.getChild().i()	=	8;	
 inh	int	D.i();	                                                B	        C	
This	is	equivalent	to	wri=ng	an	equa=on	for	each	child:	        D	        D	
 eq	A.getB().i()	=	8;	                                        i	=	8	    i	=	8	
 eq	A.getC().i()	=	8;	
 inh	int	D.i();	
                                                                               36	

L07B.pdf:                 Inherited	a>ributes,	example	7	
 A	::=	B*;	                                           Draw	the	a#ributes	and	their	values!	
 B	::=	C;	
 C;	                                                                       A	
For	list	children,	an	index	can	be	used	in	the	equa=on	                   List	
 eq	A.getB(int	index).i()	=	(index+1)	*	(index+1);	
 inh	int	C.i();	
                                                                   B	       B	      B	
                                                                   C	       C	      C	
                                                                                            37	

L07B.pdf:                 Inherited	a>ributes,	example	7	
 A	::=	B*;	
 B	::=	C;	
 C;	                                                                  A	
For	list	children,	an	index	can	be	used	in	the	equa=on	              List	
 eq	A.getB(int	index).i()	=	(index+1)	*	(index+1);	
 inh	int	C.i();	
                                                                B	      B	     B	
                                                                C	      C	     C	
                                                              i	=	1	  i	=	4	 i	=	9	
This	is	useful,	for	example,	when	deﬁning	name	analysis	with	
declare-before-use	seman=cs.	
                                                                                    38	

L07B.pdf:                            Demand	evalua=on	
A>ributes	are	not	evaluated	un=l	demanded.	                  Program	
Simple	recursive	caching	algorithm:	
If	not	cached	
		ﬁnd	the	equa=on	                                                          localLookup("a")	 3	
		compute	its	right-hand	side	                                Block	        localLookup("b")	 6	
		cache	the	value	                                                             lookup("b")	      7	
ﬁ	
Return	the	cached	value	
                                                       List	                   List	
                                               Decl	                          Assign	
Example	program	                         Type	   IdDecl	           IdUse	                 IdUse	
demanding	a>ributes:	                             ID="a"	          ID="a"	                ID="b"	
                                                                    decl	 1	                decl	   4	
Program	p	=	...	
Assign	a	=	p.getBlock().getStmt(0);	                             lookup("a")	 2	       lookup("b")	    5	
System.out.println(a.getTo().decl());	
System.out.println(a.getFrom().decl());	
                                                                                                       39	

L07B.pdf:                          Summary	ques=ons	
•  What	is	an	a>ribute	grammar?	
•  What	is	an	intrinsic	a>ribute?	
•  What	is	an	externally	visible	side-eﬀect?	Why	are	they	not	allowed	in	the	
   equa=ons?	
•  What	is	a	synthesized	a>ribute?	
•  What	is	an	inherited	a>ribute?	
•  What	is	broadcas=ng?	
•  What	is	the	diﬀerence	between	a	declara=ve	and	an	impera=ve	speciﬁca=on?	
•  What	is	demand	evalua=on?	
•  Why	are	a>ributes	cached?	
You	can	now	do	all	of	Assignment	3.	
But	it	is	recommended	to	do	the	7B	quiz	ﬁrst!	
                                                                              40	

